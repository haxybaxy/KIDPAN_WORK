{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = pd.read_csv(\"data_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready[data_ready.select_dtypes(include=['float64']).columns] = data_ready.select_dtypes(include=['float64']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% training data, 15% validation, 15% test\n",
    "train_dev, test = train_test_split(data_ready, test_size=0.15, random_state=42)\n",
    "train, dev = train_test_split(train_dev, test_size=0.176, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors and extract labels\n",
    "\n",
    "train_label = train.pop(\"5YR_SURV\")\n",
    "dev_label = dev.pop(\"5YR_SURV\")\n",
    "test_label = test.pop(\"5YR_SURV\")\n",
    "\n",
    "train_tf = tf.convert_to_tensor(train)\n",
    "dev_tf = tf.convert_to_tensor(dev)\n",
    "test_tf = tf.convert_to_tensor(test)\n",
    "\n",
    "train_label_tf = tf.convert_to_tensor(train_label)\n",
    "dev_label_tf = tf.convert_to_tensor(dev_label)\n",
    "test_label_tf = tf.convert_to_tensor(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3500218250.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[111], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001) name=\"L1\"),\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "       tf.keras.Input(shape=(214,)),\n",
    "       tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001) name=\"L1\"),\n",
    "       tf.keras.layers.Dropout(0.3),\n",
    "       tf.keras.layers.Dense(16, activation=\"relu\", name=\"L3\"),\n",
    "       tf.keras.layers.Dropout(0.3),\n",
    "       tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"L5\") \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    pos_y_true = y_true\n",
    "    pos_y_pred = y_pred\n",
    "    fn = K.sum(pos_y_true * y_pred)\n",
    "    tp = K.sum(pos_y_true * pos_y_pred)\n",
    "    specificity = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    return sensitivity\n",
    "# Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    spec_val = specificity\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adamax(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "    metrics=[\"accuracy\", specificity]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: 0.6029 - specificity: 0.3022 - val_accuracy: 0.7119 - val_loss: 0.5853 - val_specificity: 0.2721\n",
      "Epoch 2/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.5769 - specificity: 0.2833 - val_accuracy: 0.7121 - val_loss: 0.5823 - val_specificity: 0.2799\n",
      "Epoch 3/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5664 - specificity: 0.2767 - val_accuracy: 0.7135 - val_loss: 0.5842 - val_specificity: 0.3095\n",
      "Epoch 4/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5685 - specificity: 0.2823 - val_accuracy: 0.7130 - val_loss: 0.5828 - val_specificity: 0.3109\n",
      "Epoch 5/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5635 - specificity: 0.2822 - val_accuracy: 0.7135 - val_loss: 0.5796 - val_specificity: 0.2812\n",
      "Epoch 6/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.5709 - specificity: 0.2869 - val_accuracy: 0.7135 - val_loss: 0.5794 - val_specificity: 0.2740\n",
      "Epoch 7/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5626 - specificity: 0.2786 - val_accuracy: 0.7110 - val_loss: 0.5783 - val_specificity: 0.2841\n",
      "Epoch 8/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.5664 - specificity: 0.2834 - val_accuracy: 0.7135 - val_loss: 0.5784 - val_specificity: 0.2847\n",
      "Epoch 9/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5602 - specificity: 0.2814 - val_accuracy: 0.7138 - val_loss: 0.5775 - val_specificity: 0.2932\n",
      "Epoch 10/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.5600 - specificity: 0.2822 - val_accuracy: 0.7163 - val_loss: 0.5788 - val_specificity: 0.2621\n",
      "Epoch 11/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5544 - specificity: 0.2787 - val_accuracy: 0.7144 - val_loss: 0.5763 - val_specificity: 0.2854\n",
      "Epoch 12/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5548 - specificity: 0.2798 - val_accuracy: 0.7138 - val_loss: 0.5810 - val_specificity: 0.2485\n",
      "Epoch 13/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.5571 - specificity: 0.2785 - val_accuracy: 0.7138 - val_loss: 0.5763 - val_specificity: 0.3014\n",
      "Epoch 14/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5521 - specificity: 0.2854 - val_accuracy: 0.7130 - val_loss: 0.5768 - val_specificity: 0.2650\n",
      "Epoch 15/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.5549 - specificity: 0.2789 - val_accuracy: 0.7144 - val_loss: 0.5756 - val_specificity: 0.2833\n",
      "Epoch 16/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.5480 - specificity: 0.2800 - val_accuracy: 0.7146 - val_loss: 0.5783 - val_specificity: 0.2629\n",
      "Epoch 17/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5496 - specificity: 0.2755 - val_accuracy: 0.7124 - val_loss: 0.5765 - val_specificity: 0.2866\n",
      "Epoch 18/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5458 - specificity: 0.2796 - val_accuracy: 0.7144 - val_loss: 0.5801 - val_specificity: 0.2534\n",
      "Epoch 19/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.5380 - specificity: 0.2746 - val_accuracy: 0.7141 - val_loss: 0.5768 - val_specificity: 0.2754\n",
      "Epoch 20/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.5386 - specificity: 0.2767 - val_accuracy: 0.7107 - val_loss: 0.5772 - val_specificity: 0.2762\n",
      "Epoch 21/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5428 - specificity: 0.2772 - val_accuracy: 0.7138 - val_loss: 0.5789 - val_specificity: 0.2620\n",
      "Epoch 22/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.5346 - specificity: 0.2719 - val_accuracy: 0.7144 - val_loss: 0.5798 - val_specificity: 0.2599\n",
      "Epoch 23/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.5384 - specificity: 0.2757 - val_accuracy: 0.7160 - val_loss: 0.5797 - val_specificity: 0.2763\n",
      "Epoch 24/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5359 - specificity: 0.2806 - val_accuracy: 0.7158 - val_loss: 0.5812 - val_specificity: 0.2562\n",
      "Epoch 25/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.5268 - specificity: 0.2686 - val_accuracy: 0.7119 - val_loss: 0.5794 - val_specificity: 0.2722\n",
      "Epoch 26/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5304 - specificity: 0.2830 - val_accuracy: 0.7127 - val_loss: 0.5833 - val_specificity: 0.2555\n",
      "Epoch 27/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5313 - specificity: 0.2782 - val_accuracy: 0.7124 - val_loss: 0.5858 - val_specificity: 0.2582\n",
      "Epoch 28/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.5275 - specificity: 0.2755 - val_accuracy: 0.7096 - val_loss: 0.5832 - val_specificity: 0.2772\n",
      "Epoch 29/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.5209 - specificity: 0.2762 - val_accuracy: 0.7068 - val_loss: 0.5880 - val_specificity: 0.2604\n",
      "Epoch 30/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.5233 - specificity: 0.2755 - val_accuracy: 0.7071 - val_loss: 0.5876 - val_specificity: 0.2615\n",
      "Epoch 31/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5281 - specificity: 0.2739 - val_accuracy: 0.7091 - val_loss: 0.5863 - val_specificity: 0.2644\n",
      "Epoch 32/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.5146 - specificity: 0.2759 - val_accuracy: 0.7066 - val_loss: 0.5899 - val_specificity: 0.2635\n",
      "Epoch 33/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7641 - loss: 0.5107 - specificity: 0.2716 - val_accuracy: 0.7144 - val_loss: 0.5913 - val_specificity: 0.2515\n",
      "Epoch 34/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7526 - loss: 0.5205 - specificity: 0.2789 - val_accuracy: 0.7071 - val_loss: 0.5945 - val_specificity: 0.2495\n",
      "Epoch 35/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.5165 - specificity: 0.2766 - val_accuracy: 0.7107 - val_loss: 0.5992 - val_specificity: 0.2468\n",
      "Epoch 36/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.5084 - specificity: 0.2737 - val_accuracy: 0.7018 - val_loss: 0.5909 - val_specificity: 0.2933\n",
      "Epoch 37/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.5119 - specificity: 0.2773 - val_accuracy: 0.7049 - val_loss: 0.5916 - val_specificity: 0.2884\n",
      "Epoch 38/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.5155 - specificity: 0.2835 - val_accuracy: 0.7038 - val_loss: 0.5959 - val_specificity: 0.2705\n",
      "Epoch 39/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.5134 - specificity: 0.2782 - val_accuracy: 0.7096 - val_loss: 0.6004 - val_specificity: 0.2460\n",
      "Epoch 40/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.5042 - specificity: 0.2698 - val_accuracy: 0.7107 - val_loss: 0.5987 - val_specificity: 0.2484\n",
      "Epoch 41/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.4976 - specificity: 0.2705 - val_accuracy: 0.7052 - val_loss: 0.6019 - val_specificity: 0.2547\n",
      "Epoch 42/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7600 - loss: 0.5049 - specificity: 0.2800 - val_accuracy: 0.7060 - val_loss: 0.6037 - val_specificity: 0.2458\n",
      "Epoch 43/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.4993 - specificity: 0.2734 - val_accuracy: 0.7074 - val_loss: 0.6034 - val_specificity: 0.2575\n",
      "Epoch 44/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7779 - loss: 0.4841 - specificity: 0.2677 - val_accuracy: 0.7007 - val_loss: 0.6021 - val_specificity: 0.2738\n",
      "Epoch 45/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7641 - loss: 0.5063 - specificity: 0.2786 - val_accuracy: 0.7085 - val_loss: 0.6060 - val_specificity: 0.2490\n",
      "Epoch 46/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.5019 - specificity: 0.2777 - val_accuracy: 0.7040 - val_loss: 0.6074 - val_specificity: 0.2597\n",
      "Epoch 47/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.4963 - specificity: 0.2740 - val_accuracy: 0.7052 - val_loss: 0.6046 - val_specificity: 0.2703\n",
      "Epoch 48/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.4872 - specificity: 0.2771 - val_accuracy: 0.7052 - val_loss: 0.6108 - val_specificity: 0.2541\n",
      "Epoch 49/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.4913 - specificity: 0.2731 - val_accuracy: 0.7082 - val_loss: 0.6150 - val_specificity: 0.2527\n",
      "Epoch 50/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.4847 - specificity: 0.2776 - val_accuracy: 0.6985 - val_loss: 0.6127 - val_specificity: 0.2820\n",
      "Epoch 51/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7776 - loss: 0.4799 - specificity: 0.2702 - val_accuracy: 0.7018 - val_loss: 0.6138 - val_specificity: 0.2785\n",
      "Epoch 52/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4882 - specificity: 0.2829 - val_accuracy: 0.7024 - val_loss: 0.6169 - val_specificity: 0.2602\n",
      "Epoch 53/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.4857 - specificity: 0.2800 - val_accuracy: 0.7032 - val_loss: 0.6206 - val_specificity: 0.2510\n",
      "Epoch 54/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.4759 - specificity: 0.2719 - val_accuracy: 0.7040 - val_loss: 0.6161 - val_specificity: 0.2601\n",
      "Epoch 55/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.4781 - specificity: 0.2743 - val_accuracy: 0.7007 - val_loss: 0.6220 - val_specificity: 0.2603\n",
      "Epoch 56/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7772 - loss: 0.4806 - specificity: 0.2767 - val_accuracy: 0.6865 - val_loss: 0.6217 - val_specificity: 0.2990\n",
      "Epoch 57/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.4795 - specificity: 0.2784 - val_accuracy: 0.7038 - val_loss: 0.6247 - val_specificity: 0.2428\n",
      "Epoch 58/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.4866 - specificity: 0.2765 - val_accuracy: 0.6965 - val_loss: 0.6284 - val_specificity: 0.2647\n",
      "Epoch 59/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4735 - specificity: 0.2776 - val_accuracy: 0.6960 - val_loss: 0.6375 - val_specificity: 0.2450\n",
      "Epoch 60/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.4650 - specificity: 0.2736 - val_accuracy: 0.6940 - val_loss: 0.6295 - val_specificity: 0.2680\n",
      "Epoch 61/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.4713 - specificity: 0.2765 - val_accuracy: 0.7029 - val_loss: 0.6365 - val_specificity: 0.2418\n",
      "Epoch 62/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.4724 - specificity: 0.2698 - val_accuracy: 0.6971 - val_loss: 0.6336 - val_specificity: 0.2604\n",
      "Epoch 63/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.4674 - specificity: 0.2723 - val_accuracy: 0.7013 - val_loss: 0.6413 - val_specificity: 0.2311\n",
      "Epoch 64/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4697 - specificity: 0.2749 - val_accuracy: 0.6929 - val_loss: 0.6320 - val_specificity: 0.2607\n",
      "Epoch 65/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4706 - specificity: 0.2793 - val_accuracy: 0.6907 - val_loss: 0.6333 - val_specificity: 0.2737\n",
      "Epoch 66/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.4635 - specificity: 0.2738 - val_accuracy: 0.6870 - val_loss: 0.6338 - val_specificity: 0.2779\n",
      "Epoch 67/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4680 - specificity: 0.2746 - val_accuracy: 0.6865 - val_loss: 0.6368 - val_specificity: 0.2716\n",
      "Epoch 68/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4668 - specificity: 0.2811 - val_accuracy: 0.6948 - val_loss: 0.6433 - val_specificity: 0.2455\n",
      "Epoch 69/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.4625 - specificity: 0.2726 - val_accuracy: 0.6901 - val_loss: 0.6436 - val_specificity: 0.2625\n",
      "Epoch 70/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4673 - specificity: 0.2810 - val_accuracy: 0.6962 - val_loss: 0.6457 - val_specificity: 0.2389\n",
      "Epoch 71/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4565 - specificity: 0.2782 - val_accuracy: 0.6893 - val_loss: 0.6444 - val_specificity: 0.2623\n",
      "Epoch 72/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.4621 - specificity: 0.2709 - val_accuracy: 0.6926 - val_loss: 0.6518 - val_specificity: 0.2438\n",
      "Epoch 73/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4622 - specificity: 0.2785 - val_accuracy: 0.6887 - val_loss: 0.6465 - val_specificity: 0.2668\n",
      "Epoch 74/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.4644 - specificity: 0.2777 - val_accuracy: 0.6918 - val_loss: 0.6462 - val_specificity: 0.2589\n",
      "Epoch 75/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4617 - specificity: 0.2744 - val_accuracy: 0.6932 - val_loss: 0.6537 - val_specificity: 0.2411\n",
      "Epoch 76/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7942 - loss: 0.4563 - specificity: 0.2750 - val_accuracy: 0.6923 - val_loss: 0.6494 - val_specificity: 0.2638\n",
      "Epoch 77/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.4533 - specificity: 0.2747 - val_accuracy: 0.6904 - val_loss: 0.6601 - val_specificity: 0.2502\n",
      "Epoch 78/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.4469 - specificity: 0.2770 - val_accuracy: 0.6915 - val_loss: 0.6479 - val_specificity: 0.2663\n",
      "Epoch 79/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.4558 - specificity: 0.2807 - val_accuracy: 0.6948 - val_loss: 0.6513 - val_specificity: 0.2402\n",
      "Epoch 80/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7955 - loss: 0.4512 - specificity: 0.2732 - val_accuracy: 0.6881 - val_loss: 0.6484 - val_specificity: 0.2741\n",
      "Epoch 81/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.4522 - specificity: 0.2792 - val_accuracy: 0.6859 - val_loss: 0.6611 - val_specificity: 0.2599\n",
      "Epoch 82/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.4546 - specificity: 0.2797 - val_accuracy: 0.6859 - val_loss: 0.6514 - val_specificity: 0.2702\n",
      "Epoch 83/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.4517 - specificity: 0.2806 - val_accuracy: 0.6895 - val_loss: 0.6643 - val_specificity: 0.2431\n",
      "Epoch 84/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.4449 - specificity: 0.2735 - val_accuracy: 0.6887 - val_loss: 0.6598 - val_specificity: 0.2661\n",
      "Epoch 85/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4493 - specificity: 0.2803 - val_accuracy: 0.6865 - val_loss: 0.6553 - val_specificity: 0.2732\n",
      "Epoch 86/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4537 - specificity: 0.2787 - val_accuracy: 0.6815 - val_loss: 0.6597 - val_specificity: 0.2894\n",
      "Epoch 87/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4494 - specificity: 0.2855 - val_accuracy: 0.6840 - val_loss: 0.6672 - val_specificity: 0.2740\n",
      "Epoch 88/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4372 - specificity: 0.2709 - val_accuracy: 0.6948 - val_loss: 0.6714 - val_specificity: 0.2351\n",
      "Epoch 89/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4430 - specificity: 0.2690 - val_accuracy: 0.6898 - val_loss: 0.6657 - val_specificity: 0.2566\n",
      "Epoch 90/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4374 - specificity: 0.2759 - val_accuracy: 0.6912 - val_loss: 0.6670 - val_specificity: 0.2593\n",
      "Epoch 91/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4423 - specificity: 0.2733 - val_accuracy: 0.6909 - val_loss: 0.6646 - val_specificity: 0.2592\n",
      "Epoch 92/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4404 - specificity: 0.2814 - val_accuracy: 0.6884 - val_loss: 0.6681 - val_specificity: 0.2526\n",
      "Epoch 93/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4379 - specificity: 0.2765 - val_accuracy: 0.6817 - val_loss: 0.6690 - val_specificity: 0.2699\n",
      "Epoch 94/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.4354 - specificity: 0.2780 - val_accuracy: 0.6848 - val_loss: 0.6674 - val_specificity: 0.2663\n",
      "Epoch 95/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.4401 - specificity: 0.2784 - val_accuracy: 0.6907 - val_loss: 0.6715 - val_specificity: 0.2565\n",
      "Epoch 96/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.4356 - specificity: 0.2706 - val_accuracy: 0.6870 - val_loss: 0.6793 - val_specificity: 0.2595\n",
      "Epoch 97/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4384 - specificity: 0.2750 - val_accuracy: 0.6921 - val_loss: 0.6794 - val_specificity: 0.2308\n",
      "Epoch 98/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.4439 - specificity: 0.2765 - val_accuracy: 0.6937 - val_loss: 0.6899 - val_specificity: 0.2370\n",
      "Epoch 99/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.4433 - specificity: 0.2768 - val_accuracy: 0.6934 - val_loss: 0.6909 - val_specificity: 0.2507\n",
      "Epoch 100/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4270 - specificity: 0.2711 - val_accuracy: 0.6929 - val_loss: 0.6828 - val_specificity: 0.2486\n",
      "Epoch 101/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4485 - specificity: 0.2775 - val_accuracy: 0.6876 - val_loss: 0.6815 - val_specificity: 0.2607\n",
      "Epoch 102/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4309 - specificity: 0.2750 - val_accuracy: 0.6957 - val_loss: 0.6782 - val_specificity: 0.2434\n",
      "Epoch 103/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4253 - specificity: 0.2709 - val_accuracy: 0.6845 - val_loss: 0.6907 - val_specificity: 0.2520\n",
      "Epoch 104/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4352 - specificity: 0.2763 - val_accuracy: 0.6901 - val_loss: 0.6793 - val_specificity: 0.2576\n",
      "Epoch 105/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.4242 - specificity: 0.2751 - val_accuracy: 0.6895 - val_loss: 0.6772 - val_specificity: 0.2466\n",
      "Epoch 106/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4289 - specificity: 0.2741 - val_accuracy: 0.6876 - val_loss: 0.6809 - val_specificity: 0.2733\n",
      "Epoch 107/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4332 - specificity: 0.2786 - val_accuracy: 0.6828 - val_loss: 0.6799 - val_specificity: 0.2813\n",
      "Epoch 108/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4282 - specificity: 0.2787 - val_accuracy: 0.6926 - val_loss: 0.6856 - val_specificity: 0.2459\n",
      "Epoch 109/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4244 - specificity: 0.2742 - val_accuracy: 0.6842 - val_loss: 0.6918 - val_specificity: 0.2554\n",
      "Epoch 110/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4168 - specificity: 0.2717 - val_accuracy: 0.6929 - val_loss: 0.6934 - val_specificity: 0.2458\n",
      "Epoch 111/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4272 - specificity: 0.2767 - val_accuracy: 0.6929 - val_loss: 0.6855 - val_specificity: 0.2481\n",
      "Epoch 112/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.4336 - specificity: 0.2734 - val_accuracy: 0.6907 - val_loss: 0.6888 - val_specificity: 0.2566\n",
      "Epoch 113/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4299 - specificity: 0.2763 - val_accuracy: 0.6826 - val_loss: 0.6930 - val_specificity: 0.2684\n",
      "Epoch 114/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4289 - specificity: 0.2791 - val_accuracy: 0.6946 - val_loss: 0.7017 - val_specificity: 0.2396\n",
      "Epoch 115/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4189 - specificity: 0.2741 - val_accuracy: 0.6934 - val_loss: 0.6930 - val_specificity: 0.2456\n",
      "Epoch 116/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4168 - specificity: 0.2695 - val_accuracy: 0.6909 - val_loss: 0.7039 - val_specificity: 0.2461\n",
      "Epoch 117/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.4181 - specificity: 0.2734 - val_accuracy: 0.6904 - val_loss: 0.6988 - val_specificity: 0.2544\n",
      "Epoch 118/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4141 - specificity: 0.2719 - val_accuracy: 0.6915 - val_loss: 0.6957 - val_specificity: 0.2545\n",
      "Epoch 119/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4158 - specificity: 0.2747 - val_accuracy: 0.6834 - val_loss: 0.6924 - val_specificity: 0.2656\n",
      "Epoch 120/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4203 - specificity: 0.2777 - val_accuracy: 0.6870 - val_loss: 0.7006 - val_specificity: 0.2540\n",
      "Epoch 121/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4191 - specificity: 0.2715 - val_accuracy: 0.6893 - val_loss: 0.7041 - val_specificity: 0.2563\n",
      "Epoch 122/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.4218 - specificity: 0.2829 - val_accuracy: 0.6876 - val_loss: 0.7100 - val_specificity: 0.2442\n",
      "Epoch 123/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4135 - specificity: 0.2791 - val_accuracy: 0.6842 - val_loss: 0.7036 - val_specificity: 0.2716\n",
      "Epoch 124/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4215 - specificity: 0.2838 - val_accuracy: 0.6921 - val_loss: 0.7100 - val_specificity: 0.2452\n",
      "Epoch 125/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.4138 - specificity: 0.2729 - val_accuracy: 0.6965 - val_loss: 0.7153 - val_specificity: 0.2279\n",
      "Epoch 126/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4239 - specificity: 0.2732 - val_accuracy: 0.6904 - val_loss: 0.7047 - val_specificity: 0.2502\n",
      "Epoch 127/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4183 - specificity: 0.2732 - val_accuracy: 0.6971 - val_loss: 0.7168 - val_specificity: 0.2421\n",
      "Epoch 128/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4073 - specificity: 0.2708 - val_accuracy: 0.6937 - val_loss: 0.6953 - val_specificity: 0.2516\n",
      "Epoch 129/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8087 - loss: 0.4194 - specificity: 0.2805 - val_accuracy: 0.6884 - val_loss: 0.7038 - val_specificity: 0.2519\n",
      "Epoch 130/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4187 - specificity: 0.2743 - val_accuracy: 0.6893 - val_loss: 0.7111 - val_specificity: 0.2619\n",
      "Epoch 131/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4116 - specificity: 0.2734 - val_accuracy: 0.6921 - val_loss: 0.7107 - val_specificity: 0.2359\n",
      "Epoch 132/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4151 - specificity: 0.2755 - val_accuracy: 0.6890 - val_loss: 0.7268 - val_specificity: 0.2416\n",
      "Epoch 133/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.4095 - specificity: 0.2742 - val_accuracy: 0.6845 - val_loss: 0.7115 - val_specificity: 0.2640\n",
      "Epoch 134/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8140 - loss: 0.4109 - specificity: 0.2800 - val_accuracy: 0.6884 - val_loss: 0.7113 - val_specificity: 0.2531\n",
      "Epoch 135/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.4110 - specificity: 0.2741 - val_accuracy: 0.6859 - val_loss: 0.7098 - val_specificity: 0.2659\n",
      "Epoch 136/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4154 - specificity: 0.2743 - val_accuracy: 0.6965 - val_loss: 0.7182 - val_specificity: 0.2330\n",
      "Epoch 137/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.4058 - specificity: 0.2714 - val_accuracy: 0.6907 - val_loss: 0.7259 - val_specificity: 0.2416\n",
      "Epoch 138/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4097 - specificity: 0.2710 - val_accuracy: 0.6895 - val_loss: 0.7133 - val_specificity: 0.2459\n",
      "Epoch 139/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4020 - specificity: 0.2729 - val_accuracy: 0.6960 - val_loss: 0.7131 - val_specificity: 0.2383\n",
      "Epoch 140/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4128 - specificity: 0.2731 - val_accuracy: 0.6859 - val_loss: 0.7179 - val_specificity: 0.2653\n",
      "Epoch 141/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.4084 - specificity: 0.2741 - val_accuracy: 0.6901 - val_loss: 0.7204 - val_specificity: 0.2434\n",
      "Epoch 142/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4040 - specificity: 0.2690 - val_accuracy: 0.6879 - val_loss: 0.7187 - val_specificity: 0.2580\n",
      "Epoch 143/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.3996 - specificity: 0.2707 - val_accuracy: 0.6909 - val_loss: 0.7180 - val_specificity: 0.2457\n",
      "Epoch 144/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4093 - specificity: 0.2792 - val_accuracy: 0.6921 - val_loss: 0.7215 - val_specificity: 0.2507\n",
      "Epoch 145/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3964 - specificity: 0.2749 - val_accuracy: 0.6868 - val_loss: 0.7234 - val_specificity: 0.2627\n",
      "Epoch 146/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.4088 - specificity: 0.2725 - val_accuracy: 0.6940 - val_loss: 0.7277 - val_specificity: 0.2439\n",
      "Epoch 147/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4116 - specificity: 0.2740 - val_accuracy: 0.6876 - val_loss: 0.7257 - val_specificity: 0.2490\n",
      "Epoch 148/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.3969 - specificity: 0.2756 - val_accuracy: 0.6862 - val_loss: 0.7266 - val_specificity: 0.2517\n",
      "Epoch 149/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4062 - specificity: 0.2773 - val_accuracy: 0.6921 - val_loss: 0.7365 - val_specificity: 0.2380\n",
      "Epoch 150/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4119 - specificity: 0.2781 - val_accuracy: 0.6856 - val_loss: 0.7288 - val_specificity: 0.2521\n",
      "Epoch 151/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.3922 - specificity: 0.2714 - val_accuracy: 0.6912 - val_loss: 0.7209 - val_specificity: 0.2526\n",
      "Epoch 152/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4019 - specificity: 0.2746 - val_accuracy: 0.6842 - val_loss: 0.7371 - val_specificity: 0.2558\n",
      "Epoch 153/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4030 - specificity: 0.2762 - val_accuracy: 0.6879 - val_loss: 0.7293 - val_specificity: 0.2526\n",
      "Epoch 154/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3951 - specificity: 0.2728 - val_accuracy: 0.6909 - val_loss: 0.7328 - val_specificity: 0.2423\n",
      "Epoch 155/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.3953 - specificity: 0.2722 - val_accuracy: 0.6884 - val_loss: 0.7390 - val_specificity: 0.2401\n",
      "Epoch 156/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4052 - specificity: 0.2738 - val_accuracy: 0.6948 - val_loss: 0.7472 - val_specificity: 0.2314\n",
      "Epoch 157/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3978 - specificity: 0.2784 - val_accuracy: 0.6893 - val_loss: 0.7330 - val_specificity: 0.2528\n",
      "Epoch 158/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4018 - specificity: 0.2758 - val_accuracy: 0.6881 - val_loss: 0.7362 - val_specificity: 0.2392\n",
      "Epoch 159/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3868 - specificity: 0.2787 - val_accuracy: 0.6943 - val_loss: 0.7456 - val_specificity: 0.2317\n",
      "Epoch 160/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3970 - specificity: 0.2723 - val_accuracy: 0.6859 - val_loss: 0.7407 - val_specificity: 0.2457\n",
      "Epoch 161/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3970 - specificity: 0.2741 - val_accuracy: 0.6926 - val_loss: 0.7419 - val_specificity: 0.2400\n",
      "Epoch 162/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4010 - specificity: 0.2709 - val_accuracy: 0.6923 - val_loss: 0.7357 - val_specificity: 0.2331\n",
      "Epoch 163/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3938 - specificity: 0.2710 - val_accuracy: 0.6876 - val_loss: 0.7477 - val_specificity: 0.2426\n",
      "Epoch 164/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.3851 - specificity: 0.2740 - val_accuracy: 0.6820 - val_loss: 0.7398 - val_specificity: 0.2640\n",
      "Epoch 165/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.3981 - specificity: 0.2772 - val_accuracy: 0.6870 - val_loss: 0.7403 - val_specificity: 0.2402\n",
      "Epoch 166/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3930 - specificity: 0.2736 - val_accuracy: 0.6842 - val_loss: 0.7506 - val_specificity: 0.2511\n",
      "Epoch 167/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3873 - specificity: 0.2753 - val_accuracy: 0.6806 - val_loss: 0.7480 - val_specificity: 0.2625\n",
      "Epoch 168/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3932 - specificity: 0.2749 - val_accuracy: 0.6840 - val_loss: 0.7437 - val_specificity: 0.2610\n",
      "Epoch 169/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3942 - specificity: 0.2801 - val_accuracy: 0.6879 - val_loss: 0.7464 - val_specificity: 0.2405\n",
      "Epoch 170/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.3897 - specificity: 0.2728 - val_accuracy: 0.6904 - val_loss: 0.7654 - val_specificity: 0.2255\n",
      "Epoch 171/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3884 - specificity: 0.2774 - val_accuracy: 0.6960 - val_loss: 0.7685 - val_specificity: 0.2234\n",
      "Epoch 172/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.3844 - specificity: 0.2704 - val_accuracy: 0.6795 - val_loss: 0.7552 - val_specificity: 0.2560\n",
      "Epoch 173/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.3911 - specificity: 0.2750 - val_accuracy: 0.6826 - val_loss: 0.7575 - val_specificity: 0.2622\n",
      "Epoch 174/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.3880 - specificity: 0.2809 - val_accuracy: 0.6823 - val_loss: 0.7571 - val_specificity: 0.2613\n",
      "Epoch 175/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.3846 - specificity: 0.2756 - val_accuracy: 0.6739 - val_loss: 0.7705 - val_specificity: 0.2637\n",
      "Epoch 176/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.3883 - specificity: 0.2763 - val_accuracy: 0.6881 - val_loss: 0.7537 - val_specificity: 0.2530\n",
      "Epoch 177/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3810 - specificity: 0.2677 - val_accuracy: 0.6881 - val_loss: 0.7512 - val_specificity: 0.2558\n",
      "Epoch 178/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3850 - specificity: 0.2776 - val_accuracy: 0.6901 - val_loss: 0.7536 - val_specificity: 0.2457\n",
      "Epoch 179/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3835 - specificity: 0.2741 - val_accuracy: 0.6901 - val_loss: 0.7564 - val_specificity: 0.2398\n",
      "Epoch 180/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3824 - specificity: 0.2730 - val_accuracy: 0.6887 - val_loss: 0.7586 - val_specificity: 0.2488\n",
      "Epoch 181/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.3857 - specificity: 0.2783 - val_accuracy: 0.6781 - val_loss: 0.7555 - val_specificity: 0.2624\n",
      "Epoch 182/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.3908 - specificity: 0.2743 - val_accuracy: 0.6879 - val_loss: 0.7560 - val_specificity: 0.2395\n",
      "Epoch 183/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3915 - specificity: 0.2768 - val_accuracy: 0.6876 - val_loss: 0.7444 - val_specificity: 0.2398\n",
      "Epoch 184/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.3821 - specificity: 0.2729 - val_accuracy: 0.6868 - val_loss: 0.7578 - val_specificity: 0.2460\n",
      "Epoch 185/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3870 - specificity: 0.2777 - val_accuracy: 0.6837 - val_loss: 0.7556 - val_specificity: 0.2601\n",
      "Epoch 186/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3825 - specificity: 0.2718 - val_accuracy: 0.6893 - val_loss: 0.7538 - val_specificity: 0.2474\n",
      "Epoch 187/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3779 - specificity: 0.2683 - val_accuracy: 0.6828 - val_loss: 0.7703 - val_specificity: 0.2523\n",
      "Epoch 188/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.3832 - specificity: 0.2743 - val_accuracy: 0.6868 - val_loss: 0.7723 - val_specificity: 0.2424\n",
      "Epoch 189/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3946 - specificity: 0.2765 - val_accuracy: 0.6854 - val_loss: 0.7675 - val_specificity: 0.2353\n",
      "Epoch 190/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.3847 - specificity: 0.2749 - val_accuracy: 0.6803 - val_loss: 0.7654 - val_specificity: 0.2609\n",
      "Epoch 191/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3763 - specificity: 0.2743 - val_accuracy: 0.6909 - val_loss: 0.7791 - val_specificity: 0.2328\n",
      "Epoch 192/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.3788 - specificity: 0.2723 - val_accuracy: 0.6907 - val_loss: 0.7713 - val_specificity: 0.2374\n",
      "Epoch 193/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3731 - specificity: 0.2711 - val_accuracy: 0.6856 - val_loss: 0.7739 - val_specificity: 0.2364\n",
      "Epoch 194/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3893 - specificity: 0.2747 - val_accuracy: 0.6881 - val_loss: 0.7693 - val_specificity: 0.2359\n",
      "Epoch 195/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.3802 - specificity: 0.2780 - val_accuracy: 0.6840 - val_loss: 0.7709 - val_specificity: 0.2392\n",
      "Epoch 196/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.3768 - specificity: 0.2766 - val_accuracy: 0.6854 - val_loss: 0.7744 - val_specificity: 0.2414\n",
      "Epoch 197/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.3859 - specificity: 0.2751 - val_accuracy: 0.6842 - val_loss: 0.7717 - val_specificity: 0.2497\n",
      "Epoch 198/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.3752 - specificity: 0.2779 - val_accuracy: 0.6881 - val_loss: 0.7758 - val_specificity: 0.2389\n",
      "Epoch 199/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3805 - specificity: 0.2760 - val_accuracy: 0.6848 - val_loss: 0.7755 - val_specificity: 0.2547\n",
      "Epoch 200/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.3788 - specificity: 0.2772 - val_accuracy: 0.6801 - val_loss: 0.7830 - val_specificity: 0.2493\n",
      "Epoch 201/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.3776 - specificity: 0.2770 - val_accuracy: 0.6879 - val_loss: 0.7827 - val_specificity: 0.2454\n",
      "Epoch 202/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3787 - specificity: 0.2755 - val_accuracy: 0.6826 - val_loss: 0.7749 - val_specificity: 0.2575\n",
      "Epoch 203/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.3739 - specificity: 0.2760 - val_accuracy: 0.6854 - val_loss: 0.7788 - val_specificity: 0.2489\n",
      "Epoch 204/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.3757 - specificity: 0.2746 - val_accuracy: 0.6837 - val_loss: 0.7846 - val_specificity: 0.2428\n",
      "Epoch 205/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.3866 - specificity: 0.2789 - val_accuracy: 0.6887 - val_loss: 0.7833 - val_specificity: 0.2341\n",
      "Epoch 206/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3769 - specificity: 0.2716 - val_accuracy: 0.6820 - val_loss: 0.7799 - val_specificity: 0.2534\n",
      "Epoch 207/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.3735 - specificity: 0.2794 - val_accuracy: 0.6881 - val_loss: 0.7980 - val_specificity: 0.2308\n",
      "Epoch 208/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.3743 - specificity: 0.2746 - val_accuracy: 0.6834 - val_loss: 0.7844 - val_specificity: 0.2412\n",
      "Epoch 209/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3737 - specificity: 0.2682 - val_accuracy: 0.6845 - val_loss: 0.7876 - val_specificity: 0.2410\n",
      "Epoch 210/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3673 - specificity: 0.2724 - val_accuracy: 0.6859 - val_loss: 0.7867 - val_specificity: 0.2476\n",
      "Epoch 211/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3828 - specificity: 0.2796 - val_accuracy: 0.6884 - val_loss: 0.7955 - val_specificity: 0.2176\n",
      "Epoch 212/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.3781 - specificity: 0.2737 - val_accuracy: 0.6923 - val_loss: 0.7889 - val_specificity: 0.2360\n",
      "Epoch 213/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3691 - specificity: 0.2704 - val_accuracy: 0.6748 - val_loss: 0.7961 - val_specificity: 0.2694\n",
      "Epoch 214/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3721 - specificity: 0.2768 - val_accuracy: 0.6890 - val_loss: 0.7768 - val_specificity: 0.2447\n",
      "Epoch 215/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3766 - specificity: 0.2801 - val_accuracy: 0.6815 - val_loss: 0.7737 - val_specificity: 0.2575\n",
      "Epoch 216/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3672 - specificity: 0.2762 - val_accuracy: 0.6884 - val_loss: 0.7913 - val_specificity: 0.2342\n",
      "Epoch 217/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3640 - specificity: 0.2697 - val_accuracy: 0.6826 - val_loss: 0.8033 - val_specificity: 0.2392\n",
      "Epoch 218/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3681 - specificity: 0.2726 - val_accuracy: 0.6848 - val_loss: 0.8037 - val_specificity: 0.2437\n",
      "Epoch 219/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.3750 - specificity: 0.2736 - val_accuracy: 0.6854 - val_loss: 0.8162 - val_specificity: 0.2367\n",
      "Epoch 220/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3734 - specificity: 0.2720 - val_accuracy: 0.6859 - val_loss: 0.8031 - val_specificity: 0.2449\n",
      "Epoch 221/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.3665 - specificity: 0.2731 - val_accuracy: 0.6921 - val_loss: 0.8084 - val_specificity: 0.2294\n",
      "Epoch 222/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.3719 - specificity: 0.2697 - val_accuracy: 0.6873 - val_loss: 0.8039 - val_specificity: 0.2410\n",
      "Epoch 223/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.3748 - specificity: 0.2756 - val_accuracy: 0.6887 - val_loss: 0.8003 - val_specificity: 0.2395\n",
      "Epoch 224/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3669 - specificity: 0.2738 - val_accuracy: 0.6812 - val_loss: 0.8012 - val_specificity: 0.2499\n",
      "Epoch 225/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3680 - specificity: 0.2784 - val_accuracy: 0.6876 - val_loss: 0.7974 - val_specificity: 0.2380\n",
      "Epoch 226/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3721 - specificity: 0.2735 - val_accuracy: 0.6848 - val_loss: 0.8008 - val_specificity: 0.2427\n",
      "Epoch 227/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.3724 - specificity: 0.2808 - val_accuracy: 0.6837 - val_loss: 0.8007 - val_specificity: 0.2375\n",
      "Epoch 228/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.3707 - specificity: 0.2740 - val_accuracy: 0.6921 - val_loss: 0.8105 - val_specificity: 0.2336\n",
      "Epoch 229/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3601 - specificity: 0.2720 - val_accuracy: 0.6803 - val_loss: 0.8127 - val_specificity: 0.2454\n",
      "Epoch 230/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3679 - specificity: 0.2734 - val_accuracy: 0.6842 - val_loss: 0.8109 - val_specificity: 0.2417\n",
      "Epoch 231/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3750 - specificity: 0.2761 - val_accuracy: 0.6881 - val_loss: 0.8050 - val_specificity: 0.2474\n",
      "Epoch 232/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.3573 - specificity: 0.2688 - val_accuracy: 0.6809 - val_loss: 0.8158 - val_specificity: 0.2539\n",
      "Epoch 233/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3639 - specificity: 0.2737 - val_accuracy: 0.6901 - val_loss: 0.8170 - val_specificity: 0.2357\n",
      "Epoch 234/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3724 - specificity: 0.2814 - val_accuracy: 0.6873 - val_loss: 0.8216 - val_specificity: 0.2383\n",
      "Epoch 235/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3669 - specificity: 0.2754 - val_accuracy: 0.6789 - val_loss: 0.7977 - val_specificity: 0.2617\n",
      "Epoch 236/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.3657 - specificity: 0.2750 - val_accuracy: 0.6845 - val_loss: 0.7973 - val_specificity: 0.2559\n",
      "Epoch 237/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3705 - specificity: 0.2756 - val_accuracy: 0.6842 - val_loss: 0.8095 - val_specificity: 0.2507\n",
      "Epoch 238/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3589 - specificity: 0.2736 - val_accuracy: 0.6887 - val_loss: 0.8075 - val_specificity: 0.2366\n",
      "Epoch 239/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3627 - specificity: 0.2732 - val_accuracy: 0.6806 - val_loss: 0.8133 - val_specificity: 0.2547\n",
      "Epoch 240/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.3651 - specificity: 0.2777 - val_accuracy: 0.6856 - val_loss: 0.8160 - val_specificity: 0.2405\n",
      "Epoch 241/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.3643 - specificity: 0.2780 - val_accuracy: 0.6828 - val_loss: 0.8051 - val_specificity: 0.2440\n",
      "Epoch 242/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3608 - specificity: 0.2776 - val_accuracy: 0.6848 - val_loss: 0.8279 - val_specificity: 0.2405\n",
      "Epoch 243/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3587 - specificity: 0.2704 - val_accuracy: 0.6795 - val_loss: 0.8152 - val_specificity: 0.2542\n",
      "Epoch 244/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3648 - specificity: 0.2778 - val_accuracy: 0.6823 - val_loss: 0.8198 - val_specificity: 0.2397\n",
      "Epoch 245/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3582 - specificity: 0.2719 - val_accuracy: 0.6837 - val_loss: 0.8102 - val_specificity: 0.2481\n",
      "Epoch 246/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.3556 - specificity: 0.2772 - val_accuracy: 0.6890 - val_loss: 0.8187 - val_specificity: 0.2346\n",
      "Epoch 247/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3541 - specificity: 0.2686 - val_accuracy: 0.6876 - val_loss: 0.8306 - val_specificity: 0.2307\n",
      "Epoch 248/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.3611 - specificity: 0.2657 - val_accuracy: 0.6787 - val_loss: 0.8193 - val_specificity: 0.2594\n",
      "Epoch 249/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3626 - specificity: 0.2768 - val_accuracy: 0.6806 - val_loss: 0.8145 - val_specificity: 0.2586\n",
      "Epoch 250/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3562 - specificity: 0.2720 - val_accuracy: 0.6837 - val_loss: 0.8244 - val_specificity: 0.2496\n",
      "Epoch 251/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3645 - specificity: 0.2702 - val_accuracy: 0.6879 - val_loss: 0.8337 - val_specificity: 0.2358\n",
      "Epoch 252/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.3588 - specificity: 0.2758 - val_accuracy: 0.6865 - val_loss: 0.8274 - val_specificity: 0.2418\n",
      "Epoch 253/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3497 - specificity: 0.2685 - val_accuracy: 0.6848 - val_loss: 0.8182 - val_specificity: 0.2464\n",
      "Epoch 254/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3678 - specificity: 0.2793 - val_accuracy: 0.6851 - val_loss: 0.8107 - val_specificity: 0.2474\n",
      "Epoch 255/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3659 - specificity: 0.2795 - val_accuracy: 0.6915 - val_loss: 0.8152 - val_specificity: 0.2289\n",
      "Epoch 256/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3584 - specificity: 0.2717 - val_accuracy: 0.6862 - val_loss: 0.8170 - val_specificity: 0.2421\n",
      "Epoch 257/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3587 - specificity: 0.2743 - val_accuracy: 0.6848 - val_loss: 0.8075 - val_specificity: 0.2578\n",
      "Epoch 258/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3603 - specificity: 0.2771 - val_accuracy: 0.6817 - val_loss: 0.8307 - val_specificity: 0.2459\n",
      "Epoch 259/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3562 - specificity: 0.2748 - val_accuracy: 0.6842 - val_loss: 0.8238 - val_specificity: 0.2389\n",
      "Epoch 260/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3665 - specificity: 0.2672 - val_accuracy: 0.6865 - val_loss: 0.8322 - val_specificity: 0.2419\n",
      "Epoch 261/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3552 - specificity: 0.2738 - val_accuracy: 0.6823 - val_loss: 0.8322 - val_specificity: 0.2362\n",
      "Epoch 262/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3548 - specificity: 0.2711 - val_accuracy: 0.6842 - val_loss: 0.8174 - val_specificity: 0.2449\n",
      "Epoch 263/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3575 - specificity: 0.2766 - val_accuracy: 0.6887 - val_loss: 0.8276 - val_specificity: 0.2398\n",
      "Epoch 264/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3594 - specificity: 0.2793 - val_accuracy: 0.6803 - val_loss: 0.8291 - val_specificity: 0.2530\n",
      "Epoch 265/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.3508 - specificity: 0.2800 - val_accuracy: 0.6879 - val_loss: 0.8358 - val_specificity: 0.2292\n",
      "Epoch 266/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3616 - specificity: 0.2719 - val_accuracy: 0.6887 - val_loss: 0.8258 - val_specificity: 0.2301\n",
      "Epoch 267/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3575 - specificity: 0.2718 - val_accuracy: 0.6868 - val_loss: 0.8290 - val_specificity: 0.2441\n",
      "Epoch 268/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3687 - specificity: 0.2782 - val_accuracy: 0.6868 - val_loss: 0.8267 - val_specificity: 0.2366\n",
      "Epoch 269/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3565 - specificity: 0.2753 - val_accuracy: 0.6893 - val_loss: 0.8399 - val_specificity: 0.2311\n",
      "Epoch 270/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3503 - specificity: 0.2709 - val_accuracy: 0.6826 - val_loss: 0.8426 - val_specificity: 0.2352\n",
      "Epoch 271/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.3689 - specificity: 0.2776 - val_accuracy: 0.6868 - val_loss: 0.8482 - val_specificity: 0.2355\n",
      "Epoch 272/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3535 - specificity: 0.2757 - val_accuracy: 0.6831 - val_loss: 0.8432 - val_specificity: 0.2403\n",
      "Epoch 273/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3464 - specificity: 0.2725 - val_accuracy: 0.6904 - val_loss: 0.8311 - val_specificity: 0.2278\n",
      "Epoch 274/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3535 - specificity: 0.2737 - val_accuracy: 0.6848 - val_loss: 0.8547 - val_specificity: 0.2352\n",
      "Epoch 275/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3467 - specificity: 0.2702 - val_accuracy: 0.6815 - val_loss: 0.8514 - val_specificity: 0.2444\n",
      "Epoch 276/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3543 - specificity: 0.2720 - val_accuracy: 0.6803 - val_loss: 0.8446 - val_specificity: 0.2514\n",
      "Epoch 277/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3565 - specificity: 0.2808 - val_accuracy: 0.6918 - val_loss: 0.8388 - val_specificity: 0.2385\n",
      "Epoch 278/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3514 - specificity: 0.2729 - val_accuracy: 0.6873 - val_loss: 0.8519 - val_specificity: 0.2229\n",
      "Epoch 279/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3579 - specificity: 0.2721 - val_accuracy: 0.6828 - val_loss: 0.8487 - val_specificity: 0.2488\n",
      "Epoch 280/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3538 - specificity: 0.2754 - val_accuracy: 0.6803 - val_loss: 0.8630 - val_specificity: 0.2419\n",
      "Epoch 281/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3672 - specificity: 0.2775 - val_accuracy: 0.6929 - val_loss: 0.8537 - val_specificity: 0.2170\n",
      "Epoch 282/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3475 - specificity: 0.2736 - val_accuracy: 0.6865 - val_loss: 0.8496 - val_specificity: 0.2387\n",
      "Epoch 283/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3488 - specificity: 0.2732 - val_accuracy: 0.6890 - val_loss: 0.8496 - val_specificity: 0.2300\n",
      "Epoch 284/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.3575 - specificity: 0.2722 - val_accuracy: 0.6812 - val_loss: 0.8504 - val_specificity: 0.2461\n",
      "Epoch 285/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3563 - specificity: 0.2786 - val_accuracy: 0.6851 - val_loss: 0.8631 - val_specificity: 0.2350\n",
      "Epoch 286/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3497 - specificity: 0.2687 - val_accuracy: 0.6823 - val_loss: 0.8514 - val_specificity: 0.2582\n",
      "Epoch 287/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3388 - specificity: 0.2743 - val_accuracy: 0.6868 - val_loss: 0.8527 - val_specificity: 0.2350\n",
      "Epoch 288/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.3503 - specificity: 0.2786 - val_accuracy: 0.6870 - val_loss: 0.8688 - val_specificity: 0.2233\n",
      "Epoch 289/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3457 - specificity: 0.2723 - val_accuracy: 0.6756 - val_loss: 0.8414 - val_specificity: 0.2582\n",
      "Epoch 290/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3537 - specificity: 0.2753 - val_accuracy: 0.6901 - val_loss: 0.8616 - val_specificity: 0.2195\n",
      "Epoch 291/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3482 - specificity: 0.2733 - val_accuracy: 0.6901 - val_loss: 0.8611 - val_specificity: 0.2313\n",
      "Epoch 292/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3520 - specificity: 0.2759 - val_accuracy: 0.6915 - val_loss: 0.8721 - val_specificity: 0.2265\n",
      "Epoch 293/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3439 - specificity: 0.2761 - val_accuracy: 0.6854 - val_loss: 0.8692 - val_specificity: 0.2443\n",
      "Epoch 294/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3532 - specificity: 0.2787 - val_accuracy: 0.6842 - val_loss: 0.8615 - val_specificity: 0.2314\n",
      "Epoch 295/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3482 - specificity: 0.2745 - val_accuracy: 0.6815 - val_loss: 0.8700 - val_specificity: 0.2403\n",
      "Epoch 296/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3455 - specificity: 0.2749 - val_accuracy: 0.6870 - val_loss: 0.8672 - val_specificity: 0.2347\n",
      "Epoch 297/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3475 - specificity: 0.2760 - val_accuracy: 0.6865 - val_loss: 0.8639 - val_specificity: 0.2346\n",
      "Epoch 298/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3400 - specificity: 0.2743 - val_accuracy: 0.6895 - val_loss: 0.8669 - val_specificity: 0.2314\n",
      "Epoch 299/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3541 - specificity: 0.2723 - val_accuracy: 0.6803 - val_loss: 0.8683 - val_specificity: 0.2417\n",
      "Epoch 300/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3436 - specificity: 0.2709 - val_accuracy: 0.6789 - val_loss: 0.8571 - val_specificity: 0.2537\n",
      "Epoch 301/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3573 - specificity: 0.2753 - val_accuracy: 0.6907 - val_loss: 0.8666 - val_specificity: 0.2307\n",
      "Epoch 302/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3379 - specificity: 0.2748 - val_accuracy: 0.6873 - val_loss: 0.8696 - val_specificity: 0.2315\n",
      "Epoch 303/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3477 - specificity: 0.2780 - val_accuracy: 0.6881 - val_loss: 0.8766 - val_specificity: 0.2256\n",
      "Epoch 304/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3439 - specificity: 0.2762 - val_accuracy: 0.6881 - val_loss: 0.8712 - val_specificity: 0.2413\n",
      "Epoch 305/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3415 - specificity: 0.2695 - val_accuracy: 0.6873 - val_loss: 0.8819 - val_specificity: 0.2322\n",
      "Epoch 306/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3495 - specificity: 0.2716 - val_accuracy: 0.6865 - val_loss: 0.8729 - val_specificity: 0.2257\n",
      "Epoch 307/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3507 - specificity: 0.2758 - val_accuracy: 0.6828 - val_loss: 0.8824 - val_specificity: 0.2466\n",
      "Epoch 308/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3472 - specificity: 0.2770 - val_accuracy: 0.6828 - val_loss: 0.8702 - val_specificity: 0.2455\n",
      "Epoch 309/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3442 - specificity: 0.2756 - val_accuracy: 0.6921 - val_loss: 0.8806 - val_specificity: 0.2244\n",
      "Epoch 310/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3404 - specificity: 0.2742 - val_accuracy: 0.6873 - val_loss: 0.8780 - val_specificity: 0.2361\n",
      "Epoch 311/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3480 - specificity: 0.2737 - val_accuracy: 0.6865 - val_loss: 0.8655 - val_specificity: 0.2431\n",
      "Epoch 312/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3409 - specificity: 0.2754 - val_accuracy: 0.6873 - val_loss: 0.8691 - val_specificity: 0.2476\n",
      "Epoch 313/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3404 - specificity: 0.2706 - val_accuracy: 0.6854 - val_loss: 0.8814 - val_specificity: 0.2373\n",
      "Epoch 314/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3425 - specificity: 0.2740 - val_accuracy: 0.6809 - val_loss: 0.8743 - val_specificity: 0.2471\n",
      "Epoch 315/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3519 - specificity: 0.2735 - val_accuracy: 0.6873 - val_loss: 0.8774 - val_specificity: 0.2279\n",
      "Epoch 316/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3549 - specificity: 0.2749 - val_accuracy: 0.6893 - val_loss: 0.8857 - val_specificity: 0.2223\n",
      "Epoch 317/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3481 - specificity: 0.2767 - val_accuracy: 0.6840 - val_loss: 0.8976 - val_specificity: 0.2251\n",
      "Epoch 318/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3388 - specificity: 0.2776 - val_accuracy: 0.6840 - val_loss: 0.8693 - val_specificity: 0.2474\n",
      "Epoch 319/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3440 - specificity: 0.2775 - val_accuracy: 0.6854 - val_loss: 0.8929 - val_specificity: 0.2314\n",
      "Epoch 320/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3437 - specificity: 0.2743 - val_accuracy: 0.6901 - val_loss: 0.8726 - val_specificity: 0.2293\n",
      "Epoch 321/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3445 - specificity: 0.2752 - val_accuracy: 0.6823 - val_loss: 0.8861 - val_specificity: 0.2360\n",
      "Epoch 322/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.3458 - specificity: 0.2803 - val_accuracy: 0.6859 - val_loss: 0.8711 - val_specificity: 0.2432\n",
      "Epoch 323/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.3432 - specificity: 0.2681 - val_accuracy: 0.6895 - val_loss: 0.8762 - val_specificity: 0.2357\n",
      "Epoch 324/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3479 - specificity: 0.2687 - val_accuracy: 0.6848 - val_loss: 0.8788 - val_specificity: 0.2342\n",
      "Epoch 325/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.3336 - specificity: 0.2741 - val_accuracy: 0.6848 - val_loss: 0.8988 - val_specificity: 0.2307\n",
      "Epoch 326/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3395 - specificity: 0.2769 - val_accuracy: 0.6881 - val_loss: 0.8936 - val_specificity: 0.2281\n",
      "Epoch 327/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3480 - specificity: 0.2732 - val_accuracy: 0.6848 - val_loss: 0.8897 - val_specificity: 0.2432\n",
      "Epoch 328/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3417 - specificity: 0.2727 - val_accuracy: 0.6817 - val_loss: 0.8933 - val_specificity: 0.2455\n",
      "Epoch 329/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3352 - specificity: 0.2705 - val_accuracy: 0.6801 - val_loss: 0.8812 - val_specificity: 0.2434\n",
      "Epoch 330/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3439 - specificity: 0.2787 - val_accuracy: 0.6854 - val_loss: 0.8919 - val_specificity: 0.2228\n",
      "Epoch 331/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3345 - specificity: 0.2768 - val_accuracy: 0.6901 - val_loss: 0.9050 - val_specificity: 0.2176\n",
      "Epoch 332/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3386 - specificity: 0.2735 - val_accuracy: 0.6854 - val_loss: 0.8862 - val_specificity: 0.2318\n",
      "Epoch 333/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3439 - specificity: 0.2734 - val_accuracy: 0.6837 - val_loss: 0.8886 - val_specificity: 0.2364\n",
      "Epoch 334/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3359 - specificity: 0.2757 - val_accuracy: 0.6842 - val_loss: 0.8745 - val_specificity: 0.2422\n",
      "Epoch 335/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3601 - specificity: 0.2718 - val_accuracy: 0.6868 - val_loss: 0.9094 - val_specificity: 0.2296\n",
      "Epoch 336/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3324 - specificity: 0.2700 - val_accuracy: 0.6823 - val_loss: 0.8957 - val_specificity: 0.2396\n",
      "Epoch 337/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.3353 - specificity: 0.2783 - val_accuracy: 0.6845 - val_loss: 0.8994 - val_specificity: 0.2316\n",
      "Epoch 338/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3302 - specificity: 0.2711 - val_accuracy: 0.6770 - val_loss: 0.9009 - val_specificity: 0.2487\n",
      "Epoch 339/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3436 - specificity: 0.2786 - val_accuracy: 0.6828 - val_loss: 0.8968 - val_specificity: 0.2399\n",
      "Epoch 340/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.3370 - specificity: 0.2768 - val_accuracy: 0.6826 - val_loss: 0.9129 - val_specificity: 0.2349\n",
      "Epoch 341/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.3346 - specificity: 0.2778 - val_accuracy: 0.6854 - val_loss: 0.9008 - val_specificity: 0.2299\n",
      "Epoch 342/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3424 - specificity: 0.2750 - val_accuracy: 0.6848 - val_loss: 0.9142 - val_specificity: 0.2301\n",
      "Epoch 343/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.3454 - specificity: 0.2750 - val_accuracy: 0.6834 - val_loss: 0.8897 - val_specificity: 0.2403\n",
      "Epoch 344/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3421 - specificity: 0.2754 - val_accuracy: 0.6803 - val_loss: 0.9008 - val_specificity: 0.2378\n",
      "Epoch 345/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3384 - specificity: 0.2731 - val_accuracy: 0.6831 - val_loss: 0.8952 - val_specificity: 0.2373\n",
      "Epoch 346/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3395 - specificity: 0.2725 - val_accuracy: 0.6812 - val_loss: 0.9024 - val_specificity: 0.2410\n",
      "Epoch 347/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.3357 - specificity: 0.2718 - val_accuracy: 0.6901 - val_loss: 0.9227 - val_specificity: 0.2143\n",
      "Epoch 348/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3419 - specificity: 0.2701 - val_accuracy: 0.6907 - val_loss: 0.9086 - val_specificity: 0.2267\n",
      "Epoch 349/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3359 - specificity: 0.2739 - val_accuracy: 0.6854 - val_loss: 0.9086 - val_specificity: 0.2378\n",
      "Epoch 350/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3274 - specificity: 0.2760 - val_accuracy: 0.6870 - val_loss: 0.8957 - val_specificity: 0.2299\n",
      "Epoch 351/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.3423 - specificity: 0.2766 - val_accuracy: 0.6831 - val_loss: 0.9007 - val_specificity: 0.2329\n",
      "Epoch 352/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3315 - specificity: 0.2698 - val_accuracy: 0.6881 - val_loss: 0.9010 - val_specificity: 0.2310\n",
      "Epoch 353/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3306 - specificity: 0.2727 - val_accuracy: 0.6879 - val_loss: 0.8939 - val_specificity: 0.2300\n",
      "Epoch 354/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3416 - specificity: 0.2773 - val_accuracy: 0.6862 - val_loss: 0.9090 - val_specificity: 0.2341\n",
      "Epoch 355/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3376 - specificity: 0.2729 - val_accuracy: 0.6856 - val_loss: 0.8999 - val_specificity: 0.2410\n",
      "Epoch 356/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.3342 - specificity: 0.2700 - val_accuracy: 0.6854 - val_loss: 0.9211 - val_specificity: 0.2201\n",
      "Epoch 357/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3308 - specificity: 0.2680 - val_accuracy: 0.6840 - val_loss: 0.9083 - val_specificity: 0.2399\n",
      "Epoch 358/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8572 - loss: 0.3318 - specificity: 0.2719 - val_accuracy: 0.6865 - val_loss: 0.9162 - val_specificity: 0.2352\n",
      "Epoch 359/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.3288 - specificity: 0.2761 - val_accuracy: 0.6865 - val_loss: 0.9194 - val_specificity: 0.2244\n",
      "Epoch 360/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3395 - specificity: 0.2713 - val_accuracy: 0.6859 - val_loss: 0.9126 - val_specificity: 0.2296\n",
      "Epoch 361/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3236 - specificity: 0.2699 - val_accuracy: 0.6770 - val_loss: 0.9255 - val_specificity: 0.2443\n",
      "Epoch 362/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.3380 - specificity: 0.2717 - val_accuracy: 0.6812 - val_loss: 0.9005 - val_specificity: 0.2398\n",
      "Epoch 363/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3323 - specificity: 0.2722 - val_accuracy: 0.6826 - val_loss: 0.9088 - val_specificity: 0.2436\n",
      "Epoch 364/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3299 - specificity: 0.2772 - val_accuracy: 0.6773 - val_loss: 0.9136 - val_specificity: 0.2416\n",
      "Epoch 365/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3397 - specificity: 0.2768 - val_accuracy: 0.6845 - val_loss: 0.9272 - val_specificity: 0.2314\n",
      "Epoch 366/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.3242 - specificity: 0.2739 - val_accuracy: 0.6792 - val_loss: 0.9091 - val_specificity: 0.2523\n",
      "Epoch 367/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3429 - specificity: 0.2775 - val_accuracy: 0.6859 - val_loss: 0.9276 - val_specificity: 0.2268\n",
      "Epoch 368/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.3321 - specificity: 0.2684 - val_accuracy: 0.6854 - val_loss: 0.9399 - val_specificity: 0.2302\n",
      "Epoch 369/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3476 - specificity: 0.2773 - val_accuracy: 0.6806 - val_loss: 0.9239 - val_specificity: 0.2399\n",
      "Epoch 370/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.3329 - specificity: 0.2690 - val_accuracy: 0.6798 - val_loss: 0.9232 - val_specificity: 0.2440\n",
      "Epoch 371/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3351 - specificity: 0.2743 - val_accuracy: 0.6820 - val_loss: 0.9219 - val_specificity: 0.2295\n",
      "Epoch 372/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3375 - specificity: 0.2821 - val_accuracy: 0.6901 - val_loss: 0.9397 - val_specificity: 0.2145\n",
      "Epoch 373/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3282 - specificity: 0.2716 - val_accuracy: 0.6831 - val_loss: 0.9414 - val_specificity: 0.2231\n",
      "Epoch 374/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3350 - specificity: 0.2683 - val_accuracy: 0.6890 - val_loss: 0.9399 - val_specificity: 0.2111\n",
      "Epoch 375/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3244 - specificity: 0.2690 - val_accuracy: 0.6798 - val_loss: 0.9398 - val_specificity: 0.2402\n",
      "Epoch 376/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3409 - specificity: 0.2778 - val_accuracy: 0.6809 - val_loss: 0.9280 - val_specificity: 0.2343\n",
      "Epoch 377/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3297 - specificity: 0.2771 - val_accuracy: 0.6789 - val_loss: 0.9332 - val_specificity: 0.2387\n",
      "Epoch 378/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3314 - specificity: 0.2769 - val_accuracy: 0.6792 - val_loss: 0.9411 - val_specificity: 0.2407\n",
      "Epoch 379/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3295 - specificity: 0.2748 - val_accuracy: 0.6801 - val_loss: 0.9273 - val_specificity: 0.2356\n",
      "Epoch 380/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3351 - specificity: 0.2691 - val_accuracy: 0.6756 - val_loss: 0.9356 - val_specificity: 0.2425\n",
      "Epoch 381/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3319 - specificity: 0.2775 - val_accuracy: 0.6806 - val_loss: 0.9322 - val_specificity: 0.2355\n",
      "Epoch 382/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.3383 - specificity: 0.2812 - val_accuracy: 0.6795 - val_loss: 0.9457 - val_specificity: 0.2339\n",
      "Epoch 383/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3288 - specificity: 0.2705 - val_accuracy: 0.6828 - val_loss: 0.9300 - val_specificity: 0.2363\n",
      "Epoch 384/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3311 - specificity: 0.2750 - val_accuracy: 0.6848 - val_loss: 0.9440 - val_specificity: 0.2236\n",
      "Epoch 385/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3250 - specificity: 0.2740 - val_accuracy: 0.6787 - val_loss: 0.9388 - val_specificity: 0.2367\n",
      "Epoch 386/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3323 - specificity: 0.2721 - val_accuracy: 0.6840 - val_loss: 0.9413 - val_specificity: 0.2326\n",
      "Epoch 387/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3351 - specificity: 0.2783 - val_accuracy: 0.6817 - val_loss: 0.9380 - val_specificity: 0.2348\n",
      "Epoch 388/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3236 - specificity: 0.2710 - val_accuracy: 0.6842 - val_loss: 0.9341 - val_specificity: 0.2287\n",
      "Epoch 389/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3240 - specificity: 0.2708 - val_accuracy: 0.6809 - val_loss: 0.9402 - val_specificity: 0.2376\n",
      "Epoch 390/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3299 - specificity: 0.2817 - val_accuracy: 0.6798 - val_loss: 0.9406 - val_specificity: 0.2312\n",
      "Epoch 391/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3299 - specificity: 0.2744 - val_accuracy: 0.6820 - val_loss: 0.9435 - val_specificity: 0.2308\n",
      "Epoch 392/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3262 - specificity: 0.2712 - val_accuracy: 0.6868 - val_loss: 0.9432 - val_specificity: 0.2242\n",
      "Epoch 393/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3319 - specificity: 0.2733 - val_accuracy: 0.6854 - val_loss: 0.9469 - val_specificity: 0.2196\n",
      "Epoch 394/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3285 - specificity: 0.2705 - val_accuracy: 0.6809 - val_loss: 0.9588 - val_specificity: 0.2326\n",
      "Epoch 395/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3280 - specificity: 0.2707 - val_accuracy: 0.6840 - val_loss: 0.9628 - val_specificity: 0.2269\n",
      "Epoch 396/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3267 - specificity: 0.2729 - val_accuracy: 0.6831 - val_loss: 0.9514 - val_specificity: 0.2271\n",
      "Epoch 397/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3329 - specificity: 0.2754 - val_accuracy: 0.6809 - val_loss: 0.9465 - val_specificity: 0.2362\n",
      "Epoch 398/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3293 - specificity: 0.2738 - val_accuracy: 0.6865 - val_loss: 0.9363 - val_specificity: 0.2251\n",
      "Epoch 399/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.3253 - specificity: 0.2744 - val_accuracy: 0.6870 - val_loss: 0.9600 - val_specificity: 0.2217\n",
      "Epoch 400/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8541 - loss: 0.3319 - specificity: 0.2687 - val_accuracy: 0.6801 - val_loss: 0.9628 - val_specificity: 0.2241\n",
      "Epoch 401/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3241 - specificity: 0.2728 - val_accuracy: 0.6762 - val_loss: 0.9482 - val_specificity: 0.2425\n",
      "Epoch 402/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3263 - specificity: 0.2715 - val_accuracy: 0.6881 - val_loss: 0.9439 - val_specificity: 0.2207\n",
      "Epoch 403/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3232 - specificity: 0.2702 - val_accuracy: 0.6742 - val_loss: 0.9591 - val_specificity: 0.2449\n",
      "Epoch 404/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3270 - specificity: 0.2721 - val_accuracy: 0.6801 - val_loss: 0.9373 - val_specificity: 0.2406\n",
      "Epoch 405/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3217 - specificity: 0.2727 - val_accuracy: 0.6826 - val_loss: 0.9532 - val_specificity: 0.2337\n",
      "Epoch 406/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3158 - specificity: 0.2735 - val_accuracy: 0.6795 - val_loss: 0.9520 - val_specificity: 0.2380\n",
      "Epoch 407/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3310 - specificity: 0.2755 - val_accuracy: 0.6848 - val_loss: 0.9476 - val_specificity: 0.2288\n",
      "Epoch 408/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3345 - specificity: 0.2739 - val_accuracy: 0.6854 - val_loss: 0.9457 - val_specificity: 0.2305\n",
      "Epoch 409/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.3235 - specificity: 0.2749 - val_accuracy: 0.6862 - val_loss: 0.9585 - val_specificity: 0.2236\n",
      "Epoch 410/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.3238 - specificity: 0.2727 - val_accuracy: 0.6890 - val_loss: 0.9482 - val_specificity: 0.2220\n",
      "Epoch 411/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3241 - specificity: 0.2643 - val_accuracy: 0.6787 - val_loss: 0.9585 - val_specificity: 0.2328\n",
      "Epoch 412/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3263 - specificity: 0.2701 - val_accuracy: 0.6817 - val_loss: 0.9704 - val_specificity: 0.2306\n",
      "Epoch 413/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3138 - specificity: 0.2709 - val_accuracy: 0.6842 - val_loss: 0.9470 - val_specificity: 0.2347\n",
      "Epoch 414/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.3295 - specificity: 0.2713 - val_accuracy: 0.6759 - val_loss: 0.9573 - val_specificity: 0.2471\n",
      "Epoch 415/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.3185 - specificity: 0.2732 - val_accuracy: 0.6851 - val_loss: 0.9755 - val_specificity: 0.2310\n",
      "Epoch 416/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3272 - specificity: 0.2770 - val_accuracy: 0.6837 - val_loss: 0.9515 - val_specificity: 0.2342\n",
      "Epoch 417/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3230 - specificity: 0.2748 - val_accuracy: 0.6820 - val_loss: 0.9634 - val_specificity: 0.2329\n",
      "Epoch 418/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3309 - specificity: 0.2736 - val_accuracy: 0.6828 - val_loss: 0.9555 - val_specificity: 0.2303\n",
      "Epoch 419/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3249 - specificity: 0.2756 - val_accuracy: 0.6865 - val_loss: 0.9687 - val_specificity: 0.2238\n",
      "Epoch 420/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.3263 - specificity: 0.2763 - val_accuracy: 0.6842 - val_loss: 0.9576 - val_specificity: 0.2280\n",
      "Epoch 421/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3371 - specificity: 0.2814 - val_accuracy: 0.6851 - val_loss: 0.9733 - val_specificity: 0.2294\n",
      "Epoch 422/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3262 - specificity: 0.2774 - val_accuracy: 0.6820 - val_loss: 0.9622 - val_specificity: 0.2330\n",
      "Epoch 423/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3254 - specificity: 0.2720 - val_accuracy: 0.6787 - val_loss: 0.9651 - val_specificity: 0.2376\n",
      "Epoch 424/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3166 - specificity: 0.2742 - val_accuracy: 0.6834 - val_loss: 0.9548 - val_specificity: 0.2238\n",
      "Epoch 425/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.3240 - specificity: 0.2754 - val_accuracy: 0.6823 - val_loss: 0.9751 - val_specificity: 0.2315\n",
      "Epoch 426/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3225 - specificity: 0.2707 - val_accuracy: 0.6812 - val_loss: 0.9628 - val_specificity: 0.2422\n",
      "Epoch 427/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3199 - specificity: 0.2781 - val_accuracy: 0.6870 - val_loss: 0.9806 - val_specificity: 0.2168\n",
      "Epoch 428/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.3302 - specificity: 0.2765 - val_accuracy: 0.6767 - val_loss: 0.9546 - val_specificity: 0.2472\n",
      "Epoch 429/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3210 - specificity: 0.2755 - val_accuracy: 0.6873 - val_loss: 0.9801 - val_specificity: 0.2132\n",
      "Epoch 430/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3254 - specificity: 0.2748 - val_accuracy: 0.6792 - val_loss: 0.9692 - val_specificity: 0.2343\n",
      "Epoch 431/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3247 - specificity: 0.2759 - val_accuracy: 0.6831 - val_loss: 0.9698 - val_specificity: 0.2371\n",
      "Epoch 432/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3199 - specificity: 0.2758 - val_accuracy: 0.6823 - val_loss: 0.9599 - val_specificity: 0.2328\n",
      "Epoch 433/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.3310 - specificity: 0.2722 - val_accuracy: 0.6789 - val_loss: 0.9542 - val_specificity: 0.2398\n",
      "Epoch 434/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3072 - specificity: 0.2724 - val_accuracy: 0.6764 - val_loss: 0.9708 - val_specificity: 0.2378\n",
      "Epoch 435/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3286 - specificity: 0.2801 - val_accuracy: 0.6879 - val_loss: 0.9949 - val_specificity: 0.2097\n",
      "Epoch 436/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3217 - specificity: 0.2710 - val_accuracy: 0.6879 - val_loss: 0.9919 - val_specificity: 0.2218\n",
      "Epoch 437/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3186 - specificity: 0.2733 - val_accuracy: 0.6773 - val_loss: 0.9757 - val_specificity: 0.2304\n",
      "Epoch 438/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3248 - specificity: 0.2731 - val_accuracy: 0.6770 - val_loss: 0.9648 - val_specificity: 0.2377\n",
      "Epoch 439/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3314 - specificity: 0.2707 - val_accuracy: 0.6823 - val_loss: 0.9772 - val_specificity: 0.2227\n",
      "Epoch 440/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3233 - specificity: 0.2774 - val_accuracy: 0.6784 - val_loss: 0.9768 - val_specificity: 0.2383\n",
      "Epoch 441/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3192 - specificity: 0.2724 - val_accuracy: 0.6826 - val_loss: 0.9896 - val_specificity: 0.2266\n",
      "Epoch 442/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3230 - specificity: 0.2827 - val_accuracy: 0.6831 - val_loss: 0.9894 - val_specificity: 0.2280\n",
      "Epoch 443/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3127 - specificity: 0.2717 - val_accuracy: 0.6828 - val_loss: 0.9963 - val_specificity: 0.2299\n",
      "Epoch 444/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3175 - specificity: 0.2783 - val_accuracy: 0.6742 - val_loss: 0.9782 - val_specificity: 0.2401\n",
      "Epoch 445/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3128 - specificity: 0.2805 - val_accuracy: 0.6831 - val_loss: 0.9810 - val_specificity: 0.2246\n",
      "Epoch 446/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3155 - specificity: 0.2724 - val_accuracy: 0.6837 - val_loss: 0.9928 - val_specificity: 0.2183\n",
      "Epoch 447/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3194 - specificity: 0.2737 - val_accuracy: 0.6792 - val_loss: 0.9803 - val_specificity: 0.2385\n",
      "Epoch 448/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3179 - specificity: 0.2744 - val_accuracy: 0.6856 - val_loss: 1.0091 - val_specificity: 0.2145\n",
      "Epoch 449/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3106 - specificity: 0.2726 - val_accuracy: 0.6812 - val_loss: 0.9950 - val_specificity: 0.2291\n",
      "Epoch 450/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3156 - specificity: 0.2753 - val_accuracy: 0.6812 - val_loss: 0.9810 - val_specificity: 0.2378\n",
      "Epoch 451/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3215 - specificity: 0.2775 - val_accuracy: 0.6826 - val_loss: 0.9961 - val_specificity: 0.2192\n",
      "Epoch 452/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3227 - specificity: 0.2718 - val_accuracy: 0.6828 - val_loss: 1.0011 - val_specificity: 0.2209\n",
      "Epoch 453/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3139 - specificity: 0.2719 - val_accuracy: 0.6823 - val_loss: 0.9897 - val_specificity: 0.2285\n",
      "Epoch 454/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3255 - specificity: 0.2748 - val_accuracy: 0.6831 - val_loss: 0.9992 - val_specificity: 0.2213\n",
      "Epoch 455/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3281 - specificity: 0.2739 - val_accuracy: 0.6828 - val_loss: 0.9800 - val_specificity: 0.2243\n",
      "Epoch 456/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.3204 - specificity: 0.2695 - val_accuracy: 0.6854 - val_loss: 0.9808 - val_specificity: 0.2268\n",
      "Epoch 457/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.3129 - specificity: 0.2759 - val_accuracy: 0.6840 - val_loss: 0.9906 - val_specificity: 0.2313\n",
      "Epoch 458/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3132 - specificity: 0.2772 - val_accuracy: 0.6842 - val_loss: 1.0067 - val_specificity: 0.2164\n",
      "Epoch 459/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.3173 - specificity: 0.2707 - val_accuracy: 0.6692 - val_loss: 0.9938 - val_specificity: 0.2444\n",
      "Epoch 460/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3258 - specificity: 0.2786 - val_accuracy: 0.6767 - val_loss: 1.0014 - val_specificity: 0.2354\n",
      "Epoch 461/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3212 - specificity: 0.2847 - val_accuracy: 0.6856 - val_loss: 0.9882 - val_specificity: 0.2297\n",
      "Epoch 462/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3124 - specificity: 0.2718 - val_accuracy: 0.6795 - val_loss: 1.0055 - val_specificity: 0.2260\n",
      "Epoch 463/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3216 - specificity: 0.2702 - val_accuracy: 0.6812 - val_loss: 1.0022 - val_specificity: 0.2271\n",
      "Epoch 464/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.3192 - specificity: 0.2693 - val_accuracy: 0.6817 - val_loss: 0.9930 - val_specificity: 0.2354\n",
      "Epoch 465/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3272 - specificity: 0.2764 - val_accuracy: 0.6820 - val_loss: 0.9988 - val_specificity: 0.2331\n",
      "Epoch 466/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3121 - specificity: 0.2710 - val_accuracy: 0.6801 - val_loss: 1.0179 - val_specificity: 0.2278\n",
      "Epoch 467/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3208 - specificity: 0.2764 - val_accuracy: 0.6806 - val_loss: 1.0011 - val_specificity: 0.2243\n",
      "Epoch 468/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3205 - specificity: 0.2754 - val_accuracy: 0.6851 - val_loss: 1.0216 - val_specificity: 0.2105\n",
      "Epoch 469/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3249 - specificity: 0.2744 - val_accuracy: 0.6787 - val_loss: 1.0076 - val_specificity: 0.2335\n",
      "Epoch 470/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3209 - specificity: 0.2779 - val_accuracy: 0.6787 - val_loss: 0.9846 - val_specificity: 0.2360\n",
      "Epoch 471/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3219 - specificity: 0.2779 - val_accuracy: 0.6809 - val_loss: 1.0187 - val_specificity: 0.2214\n",
      "Epoch 472/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3245 - specificity: 0.2748 - val_accuracy: 0.6834 - val_loss: 0.9965 - val_specificity: 0.2211\n",
      "Epoch 473/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3110 - specificity: 0.2709 - val_accuracy: 0.6817 - val_loss: 0.9972 - val_specificity: 0.2333\n",
      "Epoch 474/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.3218 - specificity: 0.2717 - val_accuracy: 0.6753 - val_loss: 0.9856 - val_specificity: 0.2391\n",
      "Epoch 475/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3153 - specificity: 0.2719 - val_accuracy: 0.6798 - val_loss: 0.9920 - val_specificity: 0.2319\n",
      "Epoch 476/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3167 - specificity: 0.2705 - val_accuracy: 0.6831 - val_loss: 1.0109 - val_specificity: 0.2270\n",
      "Epoch 477/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3033 - specificity: 0.2741 - val_accuracy: 0.6767 - val_loss: 1.0166 - val_specificity: 0.2236\n",
      "Epoch 478/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3236 - specificity: 0.2683 - val_accuracy: 0.6851 - val_loss: 1.0085 - val_specificity: 0.2203\n",
      "Epoch 479/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3202 - specificity: 0.2768 - val_accuracy: 0.6809 - val_loss: 1.0202 - val_specificity: 0.2253\n",
      "Epoch 480/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3065 - specificity: 0.2708 - val_accuracy: 0.6820 - val_loss: 1.0036 - val_specificity: 0.2315\n",
      "Epoch 481/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3219 - specificity: 0.2748 - val_accuracy: 0.6809 - val_loss: 1.0040 - val_specificity: 0.2320\n",
      "Epoch 482/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.3237 - specificity: 0.2747 - val_accuracy: 0.6787 - val_loss: 1.0143 - val_specificity: 0.2331\n",
      "Epoch 483/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3147 - specificity: 0.2746 - val_accuracy: 0.6775 - val_loss: 1.0116 - val_specificity: 0.2368\n",
      "Epoch 484/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3196 - specificity: 0.2723 - val_accuracy: 0.6842 - val_loss: 1.0259 - val_specificity: 0.2205\n",
      "Epoch 485/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3150 - specificity: 0.2735 - val_accuracy: 0.6840 - val_loss: 1.0214 - val_specificity: 0.2194\n",
      "Epoch 486/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3021 - specificity: 0.2719 - val_accuracy: 0.6770 - val_loss: 1.0231 - val_specificity: 0.2346\n",
      "Epoch 487/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3129 - specificity: 0.2719 - val_accuracy: 0.6834 - val_loss: 1.0316 - val_specificity: 0.2175\n",
      "Epoch 488/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3193 - specificity: 0.2735 - val_accuracy: 0.6767 - val_loss: 1.0105 - val_specificity: 0.2305\n",
      "Epoch 489/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3140 - specificity: 0.2755 - val_accuracy: 0.6815 - val_loss: 1.0333 - val_specificity: 0.2124\n",
      "Epoch 490/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3114 - specificity: 0.2755 - val_accuracy: 0.6820 - val_loss: 1.0162 - val_specificity: 0.2233\n",
      "Epoch 491/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.3190 - specificity: 0.2693 - val_accuracy: 0.6848 - val_loss: 1.0242 - val_specificity: 0.2281\n",
      "Epoch 492/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.3178 - specificity: 0.2800 - val_accuracy: 0.6815 - val_loss: 1.0309 - val_specificity: 0.2194\n",
      "Epoch 493/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3040 - specificity: 0.2663 - val_accuracy: 0.6756 - val_loss: 1.0275 - val_specificity: 0.2349\n",
      "Epoch 494/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3185 - specificity: 0.2784 - val_accuracy: 0.6820 - val_loss: 1.0147 - val_specificity: 0.2248\n",
      "Epoch 495/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3197 - specificity: 0.2790 - val_accuracy: 0.6784 - val_loss: 1.0248 - val_specificity: 0.2366\n",
      "Epoch 496/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.3150 - specificity: 0.2783 - val_accuracy: 0.6842 - val_loss: 1.0387 - val_specificity: 0.2077\n",
      "Epoch 497/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3127 - specificity: 0.2679 - val_accuracy: 0.6823 - val_loss: 1.0214 - val_specificity: 0.2250\n",
      "Epoch 498/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3148 - specificity: 0.2755 - val_accuracy: 0.6845 - val_loss: 1.0306 - val_specificity: 0.2150\n",
      "Epoch 499/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3177 - specificity: 0.2751 - val_accuracy: 0.6725 - val_loss: 1.0159 - val_specificity: 0.2339\n",
      "Epoch 500/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3110 - specificity: 0.2760 - val_accuracy: 0.6815 - val_loss: 1.0143 - val_specificity: 0.2294\n",
      "Epoch 501/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3092 - specificity: 0.2749 - val_accuracy: 0.6806 - val_loss: 1.0285 - val_specificity: 0.2282\n",
      "Epoch 502/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3107 - specificity: 0.2719 - val_accuracy: 0.6789 - val_loss: 1.0194 - val_specificity: 0.2320\n",
      "Epoch 503/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.3186 - specificity: 0.2769 - val_accuracy: 0.6759 - val_loss: 1.0201 - val_specificity: 0.2312\n",
      "Epoch 504/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3141 - specificity: 0.2725 - val_accuracy: 0.6781 - val_loss: 1.0334 - val_specificity: 0.2272\n",
      "Epoch 505/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3093 - specificity: 0.2799 - val_accuracy: 0.6773 - val_loss: 1.0333 - val_specificity: 0.2266\n",
      "Epoch 506/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3051 - specificity: 0.2732 - val_accuracy: 0.6812 - val_loss: 1.0433 - val_specificity: 0.2215\n",
      "Epoch 507/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3229 - specificity: 0.2737 - val_accuracy: 0.6809 - val_loss: 1.0266 - val_specificity: 0.2277\n",
      "Epoch 508/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3066 - specificity: 0.2719 - val_accuracy: 0.6792 - val_loss: 1.0230 - val_specificity: 0.2275\n",
      "Epoch 509/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3239 - specificity: 0.2749 - val_accuracy: 0.6826 - val_loss: 1.0422 - val_specificity: 0.2210\n",
      "Epoch 510/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3105 - specificity: 0.2735 - val_accuracy: 0.6868 - val_loss: 1.0406 - val_specificity: 0.2136\n",
      "Epoch 511/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3037 - specificity: 0.2718 - val_accuracy: 0.6840 - val_loss: 1.0317 - val_specificity: 0.2197\n",
      "Epoch 512/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3069 - specificity: 0.2673 - val_accuracy: 0.6750 - val_loss: 1.0465 - val_specificity: 0.2308\n",
      "Epoch 513/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3117 - specificity: 0.2752 - val_accuracy: 0.6767 - val_loss: 1.0290 - val_specificity: 0.2335\n",
      "Epoch 514/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3158 - specificity: 0.2770 - val_accuracy: 0.6806 - val_loss: 1.0437 - val_specificity: 0.2232\n",
      "Epoch 515/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3140 - specificity: 0.2786 - val_accuracy: 0.6795 - val_loss: 1.0308 - val_specificity: 0.2260\n",
      "Epoch 516/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3160 - specificity: 0.2793 - val_accuracy: 0.6748 - val_loss: 1.0454 - val_specificity: 0.2286\n",
      "Epoch 517/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3101 - specificity: 0.2735 - val_accuracy: 0.6789 - val_loss: 1.0362 - val_specificity: 0.2332\n",
      "Epoch 518/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.3154 - specificity: 0.2734 - val_accuracy: 0.6820 - val_loss: 1.0414 - val_specificity: 0.2240\n",
      "Epoch 519/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.3023 - specificity: 0.2753 - val_accuracy: 0.6770 - val_loss: 1.0305 - val_specificity: 0.2389\n",
      "Epoch 520/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3127 - specificity: 0.2821 - val_accuracy: 0.6787 - val_loss: 1.0598 - val_specificity: 0.2328\n",
      "Epoch 521/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3132 - specificity: 0.2753 - val_accuracy: 0.6806 - val_loss: 1.0396 - val_specificity: 0.2345\n",
      "Epoch 522/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3067 - specificity: 0.2776 - val_accuracy: 0.6787 - val_loss: 1.0536 - val_specificity: 0.2259\n",
      "Epoch 523/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3043 - specificity: 0.2715 - val_accuracy: 0.6792 - val_loss: 1.0357 - val_specificity: 0.2310\n",
      "Epoch 524/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3060 - specificity: 0.2753 - val_accuracy: 0.6731 - val_loss: 1.0385 - val_specificity: 0.2433\n",
      "Epoch 525/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3085 - specificity: 0.2797 - val_accuracy: 0.6778 - val_loss: 1.0519 - val_specificity: 0.2287\n",
      "Epoch 526/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3066 - specificity: 0.2746 - val_accuracy: 0.6848 - val_loss: 1.0516 - val_specificity: 0.2152\n",
      "Epoch 527/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3118 - specificity: 0.2733 - val_accuracy: 0.6840 - val_loss: 1.0562 - val_specificity: 0.2263\n",
      "Epoch 528/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3068 - specificity: 0.2723 - val_accuracy: 0.6792 - val_loss: 1.0570 - val_specificity: 0.2292\n",
      "Epoch 529/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3066 - specificity: 0.2733 - val_accuracy: 0.6806 - val_loss: 1.0863 - val_specificity: 0.2131\n",
      "Epoch 530/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3040 - specificity: 0.2693 - val_accuracy: 0.6745 - val_loss: 1.0562 - val_specificity: 0.2341\n",
      "Epoch 531/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3128 - specificity: 0.2748 - val_accuracy: 0.6764 - val_loss: 1.0344 - val_specificity: 0.2443\n",
      "Epoch 532/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3146 - specificity: 0.2709 - val_accuracy: 0.6787 - val_loss: 1.0583 - val_specificity: 0.2288\n",
      "Epoch 533/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3004 - specificity: 0.2714 - val_accuracy: 0.6842 - val_loss: 1.0537 - val_specificity: 0.2145\n",
      "Epoch 534/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3113 - specificity: 0.2814 - val_accuracy: 0.6812 - val_loss: 1.0533 - val_specificity: 0.2168\n",
      "Epoch 535/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3058 - specificity: 0.2780 - val_accuracy: 0.6787 - val_loss: 1.0541 - val_specificity: 0.2274\n",
      "Epoch 536/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3190 - specificity: 0.2791 - val_accuracy: 0.6789 - val_loss: 1.0696 - val_specificity: 0.2198\n",
      "Epoch 537/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3143 - specificity: 0.2761 - val_accuracy: 0.6837 - val_loss: 1.0690 - val_specificity: 0.2195\n",
      "Epoch 538/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3070 - specificity: 0.2721 - val_accuracy: 0.6784 - val_loss: 1.0440 - val_specificity: 0.2268\n",
      "Epoch 539/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3076 - specificity: 0.2743 - val_accuracy: 0.6762 - val_loss: 1.0501 - val_specificity: 0.2339\n",
      "Epoch 540/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.2999 - specificity: 0.2800 - val_accuracy: 0.6762 - val_loss: 1.0377 - val_specificity: 0.2346\n",
      "Epoch 541/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3104 - specificity: 0.2708 - val_accuracy: 0.6767 - val_loss: 1.0713 - val_specificity: 0.2299\n",
      "Epoch 542/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3129 - specificity: 0.2748 - val_accuracy: 0.6775 - val_loss: 1.0542 - val_specificity: 0.2318\n",
      "Epoch 543/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3050 - specificity: 0.2783 - val_accuracy: 0.6784 - val_loss: 1.0748 - val_specificity: 0.2262\n",
      "Epoch 544/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.2958 - specificity: 0.2747 - val_accuracy: 0.6806 - val_loss: 1.0735 - val_specificity: 0.2223\n",
      "Epoch 545/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3040 - specificity: 0.2758 - val_accuracy: 0.6784 - val_loss: 1.0656 - val_specificity: 0.2286\n",
      "Epoch 546/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.3061 - specificity: 0.2796 - val_accuracy: 0.6842 - val_loss: 1.0730 - val_specificity: 0.2192\n",
      "Epoch 547/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3055 - specificity: 0.2710 - val_accuracy: 0.6775 - val_loss: 1.0557 - val_specificity: 0.2335\n",
      "Epoch 548/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3061 - specificity: 0.2744 - val_accuracy: 0.6762 - val_loss: 1.0559 - val_specificity: 0.2277\n",
      "Epoch 549/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3089 - specificity: 0.2744 - val_accuracy: 0.6753 - val_loss: 1.0576 - val_specificity: 0.2307\n",
      "Epoch 550/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3151 - specificity: 0.2776 - val_accuracy: 0.6803 - val_loss: 1.0529 - val_specificity: 0.2342\n",
      "Epoch 551/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3090 - specificity: 0.2772 - val_accuracy: 0.6809 - val_loss: 1.0531 - val_specificity: 0.2167\n",
      "Epoch 552/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.3071 - specificity: 0.2695 - val_accuracy: 0.6828 - val_loss: 1.0809 - val_specificity: 0.2184\n",
      "Epoch 553/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.3099 - specificity: 0.2698 - val_accuracy: 0.6826 - val_loss: 1.0428 - val_specificity: 0.2260\n",
      "Epoch 554/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3094 - specificity: 0.2793 - val_accuracy: 0.6809 - val_loss: 1.0753 - val_specificity: 0.2199\n",
      "Epoch 555/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.3113 - specificity: 0.2741 - val_accuracy: 0.6828 - val_loss: 1.0814 - val_specificity: 0.2184\n",
      "Epoch 556/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3134 - specificity: 0.2753 - val_accuracy: 0.6784 - val_loss: 1.0803 - val_specificity: 0.2216\n",
      "Epoch 557/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3053 - specificity: 0.2736 - val_accuracy: 0.6809 - val_loss: 1.0693 - val_specificity: 0.2212\n",
      "Epoch 558/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.3105 - specificity: 0.2750 - val_accuracy: 0.6775 - val_loss: 1.0784 - val_specificity: 0.2261\n",
      "Epoch 559/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3026 - specificity: 0.2726 - val_accuracy: 0.6826 - val_loss: 1.0915 - val_specificity: 0.2164\n",
      "Epoch 560/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.3112 - specificity: 0.2721 - val_accuracy: 0.6789 - val_loss: 1.0817 - val_specificity: 0.2240\n",
      "Epoch 561/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3026 - specificity: 0.2757 - val_accuracy: 0.6820 - val_loss: 1.0533 - val_specificity: 0.2265\n",
      "Epoch 562/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.3015 - specificity: 0.2721 - val_accuracy: 0.6734 - val_loss: 1.0713 - val_specificity: 0.2372\n",
      "Epoch 563/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.3097 - specificity: 0.2753 - val_accuracy: 0.6764 - val_loss: 1.0706 - val_specificity: 0.2298\n",
      "Epoch 564/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3028 - specificity: 0.2767 - val_accuracy: 0.6773 - val_loss: 1.0568 - val_specificity: 0.2343\n",
      "Epoch 565/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3086 - specificity: 0.2748 - val_accuracy: 0.6775 - val_loss: 1.0607 - val_specificity: 0.2342\n",
      "Epoch 566/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3018 - specificity: 0.2763 - val_accuracy: 0.6792 - val_loss: 1.0845 - val_specificity: 0.2264\n",
      "Epoch 567/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3115 - specificity: 0.2751 - val_accuracy: 0.6728 - val_loss: 1.0793 - val_specificity: 0.2402\n",
      "Epoch 568/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.3092 - specificity: 0.2753 - val_accuracy: 0.6725 - val_loss: 1.0529 - val_specificity: 0.2370\n",
      "Epoch 569/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3078 - specificity: 0.2784 - val_accuracy: 0.6728 - val_loss: 1.0600 - val_specificity: 0.2276\n",
      "Epoch 570/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3031 - specificity: 0.2742 - val_accuracy: 0.6742 - val_loss: 1.0743 - val_specificity: 0.2314\n",
      "Epoch 571/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.3105 - specificity: 0.2801 - val_accuracy: 0.6784 - val_loss: 1.0805 - val_specificity: 0.2186\n",
      "Epoch 572/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.3140 - specificity: 0.2762 - val_accuracy: 0.6770 - val_loss: 1.0847 - val_specificity: 0.2295\n",
      "Epoch 573/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3040 - specificity: 0.2778 - val_accuracy: 0.6801 - val_loss: 1.0812 - val_specificity: 0.2223\n",
      "Epoch 574/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3171 - specificity: 0.2736 - val_accuracy: 0.6803 - val_loss: 1.0879 - val_specificity: 0.2261\n",
      "Epoch 575/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3037 - specificity: 0.2676 - val_accuracy: 0.6806 - val_loss: 1.0865 - val_specificity: 0.2264\n",
      "Epoch 576/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.2998 - specificity: 0.2761 - val_accuracy: 0.6748 - val_loss: 1.0902 - val_specificity: 0.2305\n",
      "Epoch 577/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3007 - specificity: 0.2750 - val_accuracy: 0.6803 - val_loss: 1.0915 - val_specificity: 0.2221\n",
      "Epoch 578/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3067 - specificity: 0.2698 - val_accuracy: 0.6736 - val_loss: 1.0910 - val_specificity: 0.2352\n",
      "Epoch 579/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3062 - specificity: 0.2709 - val_accuracy: 0.6734 - val_loss: 1.0773 - val_specificity: 0.2323\n",
      "Epoch 580/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3151 - specificity: 0.2768 - val_accuracy: 0.6809 - val_loss: 1.0890 - val_specificity: 0.2196\n",
      "Epoch 581/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3078 - specificity: 0.2748 - val_accuracy: 0.6775 - val_loss: 1.0987 - val_specificity: 0.2306\n",
      "Epoch 582/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.3099 - specificity: 0.2722 - val_accuracy: 0.6851 - val_loss: 1.0874 - val_specificity: 0.2139\n",
      "Epoch 583/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.3095 - specificity: 0.2704 - val_accuracy: 0.6792 - val_loss: 1.1034 - val_specificity: 0.2199\n",
      "Epoch 584/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.3116 - specificity: 0.2727 - val_accuracy: 0.6773 - val_loss: 1.0958 - val_specificity: 0.2226\n",
      "Epoch 585/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8644 - loss: 0.3070 - specificity: 0.2720 - val_accuracy: 0.6745 - val_loss: 1.0866 - val_specificity: 0.2393\n",
      "Epoch 586/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3064 - specificity: 0.2777 - val_accuracy: 0.6759 - val_loss: 1.0734 - val_specificity: 0.2337\n",
      "Epoch 587/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.2969 - specificity: 0.2811 - val_accuracy: 0.6817 - val_loss: 1.1050 - val_specificity: 0.2180\n",
      "Epoch 588/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.2974 - specificity: 0.2738 - val_accuracy: 0.6750 - val_loss: 1.0975 - val_specificity: 0.2273\n",
      "Epoch 589/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3082 - specificity: 0.2739 - val_accuracy: 0.6812 - val_loss: 1.1149 - val_specificity: 0.2130\n",
      "Epoch 590/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.2993 - specificity: 0.2684 - val_accuracy: 0.6820 - val_loss: 1.0950 - val_specificity: 0.2313\n",
      "Epoch 591/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3003 - specificity: 0.2760 - val_accuracy: 0.6781 - val_loss: 1.1057 - val_specificity: 0.2305\n",
      "Epoch 592/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3028 - specificity: 0.2771 - val_accuracy: 0.6812 - val_loss: 1.0788 - val_specificity: 0.2239\n",
      "Epoch 593/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.3006 - specificity: 0.2752 - val_accuracy: 0.6809 - val_loss: 1.1068 - val_specificity: 0.2123\n",
      "Epoch 594/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3015 - specificity: 0.2706 - val_accuracy: 0.6823 - val_loss: 1.0906 - val_specificity: 0.2248\n",
      "Epoch 595/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.3011 - specificity: 0.2755 - val_accuracy: 0.6787 - val_loss: 1.0899 - val_specificity: 0.2285\n",
      "Epoch 596/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.3071 - specificity: 0.2749 - val_accuracy: 0.6854 - val_loss: 1.1073 - val_specificity: 0.2132\n",
      "Epoch 597/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3014 - specificity: 0.2702 - val_accuracy: 0.6812 - val_loss: 1.0871 - val_specificity: 0.2232\n",
      "Epoch 598/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3012 - specificity: 0.2712 - val_accuracy: 0.6773 - val_loss: 1.0925 - val_specificity: 0.2302\n",
      "Epoch 599/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3091 - specificity: 0.2718 - val_accuracy: 0.6828 - val_loss: 1.0773 - val_specificity: 0.2258\n",
      "Epoch 600/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.2980 - specificity: 0.2728 - val_accuracy: 0.6823 - val_loss: 1.0870 - val_specificity: 0.2197\n",
      "Epoch 601/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2927 - specificity: 0.2741 - val_accuracy: 0.6809 - val_loss: 1.0937 - val_specificity: 0.2270\n",
      "Epoch 602/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3047 - specificity: 0.2733 - val_accuracy: 0.6803 - val_loss: 1.1127 - val_specificity: 0.2127\n",
      "Epoch 603/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3007 - specificity: 0.2705 - val_accuracy: 0.6842 - val_loss: 1.1044 - val_specificity: 0.2140\n",
      "Epoch 604/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3043 - specificity: 0.2684 - val_accuracy: 0.6851 - val_loss: 1.0943 - val_specificity: 0.2113\n",
      "Epoch 605/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3009 - specificity: 0.2736 - val_accuracy: 0.6795 - val_loss: 1.1103 - val_specificity: 0.2237\n",
      "Epoch 606/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.2988 - specificity: 0.2718 - val_accuracy: 0.6739 - val_loss: 1.0898 - val_specificity: 0.2426\n",
      "Epoch 607/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.3080 - specificity: 0.2786 - val_accuracy: 0.6775 - val_loss: 1.1007 - val_specificity: 0.2250\n",
      "Epoch 608/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3027 - specificity: 0.2697 - val_accuracy: 0.6709 - val_loss: 1.1122 - val_specificity: 0.2299\n",
      "Epoch 609/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3081 - specificity: 0.2744 - val_accuracy: 0.6784 - val_loss: 1.1046 - val_specificity: 0.2248\n",
      "Epoch 610/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3116 - specificity: 0.2752 - val_accuracy: 0.6798 - val_loss: 1.1028 - val_specificity: 0.2135\n",
      "Epoch 611/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3039 - specificity: 0.2712 - val_accuracy: 0.6778 - val_loss: 1.1136 - val_specificity: 0.2222\n",
      "Epoch 612/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3043 - specificity: 0.2771 - val_accuracy: 0.6770 - val_loss: 1.1304 - val_specificity: 0.2165\n",
      "Epoch 613/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3154 - specificity: 0.2725 - val_accuracy: 0.6742 - val_loss: 1.1062 - val_specificity: 0.2283\n",
      "Epoch 614/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3052 - specificity: 0.2753 - val_accuracy: 0.6831 - val_loss: 1.1105 - val_specificity: 0.2215\n",
      "Epoch 615/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.3048 - specificity: 0.2732 - val_accuracy: 0.6775 - val_loss: 1.0936 - val_specificity: 0.2275\n",
      "Epoch 616/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3093 - specificity: 0.2751 - val_accuracy: 0.6764 - val_loss: 1.1028 - val_specificity: 0.2329\n",
      "Epoch 617/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3051 - specificity: 0.2751 - val_accuracy: 0.6784 - val_loss: 1.0925 - val_specificity: 0.2304\n",
      "Epoch 618/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3084 - specificity: 0.2739 - val_accuracy: 0.6753 - val_loss: 1.0940 - val_specificity: 0.2329\n",
      "Epoch 619/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.2955 - specificity: 0.2746 - val_accuracy: 0.6789 - val_loss: 1.1338 - val_specificity: 0.2184\n",
      "Epoch 620/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3023 - specificity: 0.2754 - val_accuracy: 0.6781 - val_loss: 1.1130 - val_specificity: 0.2234\n",
      "Epoch 621/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3034 - specificity: 0.2727 - val_accuracy: 0.6762 - val_loss: 1.1147 - val_specificity: 0.2332\n",
      "Epoch 622/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3144 - specificity: 0.2765 - val_accuracy: 0.6837 - val_loss: 1.1242 - val_specificity: 0.2123\n",
      "Epoch 623/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3018 - specificity: 0.2738 - val_accuracy: 0.6764 - val_loss: 1.1077 - val_specificity: 0.2294\n",
      "Epoch 624/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3099 - specificity: 0.2801 - val_accuracy: 0.6753 - val_loss: 1.1204 - val_specificity: 0.2288\n",
      "Epoch 625/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.2990 - specificity: 0.2730 - val_accuracy: 0.6789 - val_loss: 1.1143 - val_specificity: 0.2265\n",
      "Epoch 626/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3115 - specificity: 0.2781 - val_accuracy: 0.6817 - val_loss: 1.1155 - val_specificity: 0.2194\n",
      "Epoch 627/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3104 - specificity: 0.2700 - val_accuracy: 0.6784 - val_loss: 1.1149 - val_specificity: 0.2228\n",
      "Epoch 628/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3018 - specificity: 0.2724 - val_accuracy: 0.6789 - val_loss: 1.1076 - val_specificity: 0.2236\n",
      "Epoch 629/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.2942 - specificity: 0.2737 - val_accuracy: 0.6759 - val_loss: 1.1306 - val_specificity: 0.2270\n",
      "Epoch 630/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3014 - specificity: 0.2698 - val_accuracy: 0.6787 - val_loss: 1.1224 - val_specificity: 0.2223\n",
      "Epoch 631/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.2980 - specificity: 0.2765 - val_accuracy: 0.6731 - val_loss: 1.1287 - val_specificity: 0.2319\n",
      "Epoch 632/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3072 - specificity: 0.2759 - val_accuracy: 0.6742 - val_loss: 1.1253 - val_specificity: 0.2233\n",
      "Epoch 633/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.2916 - specificity: 0.2732 - val_accuracy: 0.6837 - val_loss: 1.1229 - val_specificity: 0.2129\n",
      "Epoch 634/1000\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2974 - specificity: 0.2684 - val_accuracy: 0.6775 - val_loss: 1.1218 - val_specificity: 0.2268\n",
      "Epoch 635/1000\n",
      "\u001b[1m 47/525\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.2915 - specificity: 0.2775"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_label_tf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Omar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_tf, train_label_tf, epochs=1000, validation_data = (dev_tf, dev_label_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history.get('val_loss')\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "if val_loss_values:\n",
    "    plt.plot(val_loss_values, label='Validation Loss', linestyle='--')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5882 - specificity: 0.2693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5949135422706604, 0.7054393291473389, 0.26712945103645325]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_tf, dev_label_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
