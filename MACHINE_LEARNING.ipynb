{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = pd.read_csv(\"data_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready[data_ready.select_dtypes(include=['float64']).columns] = data_ready.select_dtypes(include=['float64']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% training data, 15% validation, 15% test\n",
    "train_dev, test = train_test_split(data_ready, test_size=0.15, random_state=42)\n",
    "train, dev = train_test_split(train_dev, test_size=0.176, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors and extract labels\n",
    "\n",
    "train_label = train.pop(\"5YR_SURV\")\n",
    "dev_label = dev.pop(\"5YR_SURV\")\n",
    "test_label = test.pop(\"5YR_SURV\")\n",
    "\n",
    "train_tf = tf.convert_to_tensor(train)\n",
    "dev_tf = tf.convert_to_tensor(dev)\n",
    "test_tf = tf.convert_to_tensor(test)\n",
    "\n",
    "train_label_tf = tf.convert_to_tensor(train_label)\n",
    "dev_label_tf = tf.convert_to_tensor(dev_label)\n",
    "test_label_tf = tf.convert_to_tensor(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "       tf.keras.Input(shape=(214,)),\n",
    "       tf.keras.layers.Dense(25, activation=\"leaky_relu\", name=\"L1\"),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(25, activation=\"leaky_relu\", name=\"L3\"),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(10, activation=\"leaky_relu\", name=\"L5\"),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(5, activation=\"leaky_relu\", name=\"L7\"),\n",
    "       tf.keras.layers.Dropout(0.2),\n",
    "       tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"L9\") \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    pos_y_true = y_true\n",
    "    pos_y_pred = y_pred\n",
    "    fn = K.sum(pos_y_true * y_pred)\n",
    "    tp = K.sum(pos_y_true * pos_y_pred)\n",
    "    specificity = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    return sensitivity\n",
    "# Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    spec_val = specificity\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "    metrics=[\"accuracy\", specificity]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_tf, train_label_tf, epochs=1000, validation_data = (dev_tf, dev_label_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history.get('val_loss')\n",
    "\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "if val_loss_values:\n",
    "    plt.plot(val_loss_values, label='Validation Loss', linestyle='--')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_tf, dev_label_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
