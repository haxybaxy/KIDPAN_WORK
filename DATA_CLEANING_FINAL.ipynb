{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_10452\\381285905.py:1: DtypeWarning: Columns (3,6,9,18,19,20,21,22,23,24,28,29,30,31,32,34,35,36,37,38,39,45,46,47,48,49,52,53,54,55,66,67,70,72,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,103,104,106,112,115,116,117,120,122,123,132,134,135,136,138,140,141,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,173,175,176,177,178,179,180,181,182,183,184,188,189,190,191,193,199,200,202,203,204,207,208,209,210,211,212,213,214,216,217,222,223,224,225,226,227,228,234,236,237,242,243,248,253,255,260,261,262,263,264,266,267,268,269,270,271,277,280,281,283,285,287,289,290,294,295,296,297,299,300,301,302,303,306,308,317,321,328,330,332,347,352,357,358,365,366,367,368,372,379,382,386,387,388,393,410,411,412,413,414,421,422,429,430,431,432,433,434,435,436,438,442,455,456,457,458,459,468,469,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PAN_data = pd.read_csv(\"PAN_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "PAN_data = pd.read_csv(\"PAN_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_94 = pd.to_datetime(\"04/01/1994\", dayfirst=False)\n",
    "pan_data_after_94 = PAN_data.copy()\n",
    "pan_data_after_94[\"TX_DATE\"] = pd.to_datetime(pan_data_after_94[\"TX_DATE\"], dayfirst=False)\n",
    "pan_data_after_94 = pan_data_after_94[pan_data_after_94[\"TX_DATE\"] > after_94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = [\n",
    "    \"GENDER\", \"PERIP_VASC\", \"AGE_DIAB\",\n",
    "    \"CREAT_TRR\",\n",
    "    \"AMIS\", \"BMIS\", \"DRMIS\", \"HLAMIS\", \"NPKID\", \"NPPAN\", \"AGE_DON\", \"DDAVP_DON\", \"CMV_DON\",\n",
    "    \"GENDER_DON\",\n",
    "    \"NON_HRT_DON\", \"ANTIHYPE_DON\", \"BUN_DON\", \"CREAT_DON\", \n",
    "    \"PT_DIURETICS_DON\", \"PT_STEROIDS_DON\", \"PT_T3_DON\", \"PT_T4_DON\", \"SGOT_DON\",\n",
    "    \"SGPT_DON\", \"TBILI_DON\", \"VASODIL_DON\", \"CLIN_INFECT_DON\", \"HIST_CIG_DON\",\n",
    "    \"HIST_HYPERTENS_DON\", \"HIST_COCAINE_DON\", \"HIST_OTH_DRUG_DON\", \"HEPARIN_DON\", \"HGT_CM_DON_CALC\", \"WGT_KG_DON_CALC\",\n",
    "    \"BMI_DON_CALC\", \"ABO_MAT\", \"AGE\", \"DIAL_TRR\", \"ART_RECON\", \"DUCT_MGMT\", \"GRF_PLACEM\",\n",
    "    \"PA_PRESERV_TM\", \"VASC_MGMT\", \"VEN_EXT_GRF\", \"DIAG_PA\", \"GRF_STAT_PA\",\n",
    "    \"DAYSWAIT_CHRON_PA\", \"EBV_SEROSTATUS\", \"HBV_CORE\",\n",
    "    \"HCV_SEROSTATUS\", \"CMV_STATUS\", \n",
    "    \"TX_TYPE\", \"MALIG\", \"HGT_CM_CALC\", \"WGT_KG_CALC\", \"BMI_CALC\",\n",
    "    \"PROTEIN_URINE\", \"LIPASE\", \"AMYLASE\", \"CARDARREST_NEURO\", \"INOTROP_SUPPORT_DON\",   \n",
    "    \"REM_CD\", \"AGE_GROUP\", \"DON_TY\", \"MULTIORG\", \"TX_DATE\",\"FAILDATE_PA\",\"PX_STAT_DATE\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = pan_data_after_94[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_10452\\2907620572.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_10452\\2907620572.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])\n"
     ]
    }
   ],
   "source": [
    "# convert the reason of removal to numeric and only include those that underwent transplantation [2,3,4,14,15,18,19]\n",
    "clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
    "clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = clean_good[clean_good[\"REM_CD\"].isin([2,3,4,14,15,18,19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>PERIP_VASC</th>\n",
       "      <th>AGE_DIAB</th>\n",
       "      <th>CREAT_TRR</th>\n",
       "      <th>AMIS</th>\n",
       "      <th>BMIS</th>\n",
       "      <th>DRMIS</th>\n",
       "      <th>HLAMIS</th>\n",
       "      <th>NPKID</th>\n",
       "      <th>NPPAN</th>\n",
       "      <th>...</th>\n",
       "      <th>AMYLASE</th>\n",
       "      <th>CARDARREST_NEURO</th>\n",
       "      <th>INOTROP_SUPPORT_DON</th>\n",
       "      <th>REM_CD</th>\n",
       "      <th>AGE_GROUP</th>\n",
       "      <th>DON_TY</th>\n",
       "      <th>MULTIORG</th>\n",
       "      <th>TX_DATE</th>\n",
       "      <th>FAILDATE_PA</th>\n",
       "      <th>PX_STAT_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-06-11</td>\n",
       "      <td>.</td>\n",
       "      <td>06/21/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-04-18</td>\n",
       "      <td>.</td>\n",
       "      <td>01/16/2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-07-29</td>\n",
       "      <td>.</td>\n",
       "      <td>05/04/1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>09/02/1995</td>\n",
       "      <td>07/04/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-01-17</td>\n",
       "      <td>12/27/1999</td>\n",
       "      <td>12/28/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37499</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37500</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-17</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37502</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.00</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37503</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34162 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GENDER PERIP_VASC AGE_DIAB CREAT_TRR AMIS BMIS DRMIS HLAMIS  NPKID  \\\n",
       "0          M        NaN        .      2.90    1    2     2      5      1   \n",
       "1          F        NaN        .      1.00    0    1     0      1      1   \n",
       "2          F        NaN        .      1.30    0    1     2      3      1   \n",
       "3          F        NaN        .      1.20    1    1     1      3      1   \n",
       "4          F        NaN        .      0.60    0    1     0      1      0   \n",
       "...      ...        ...      ...       ...  ...  ...   ...    ...    ...   \n",
       "37499      F          N       16         .    2    2     2      6      0   \n",
       "37500      F          N        2         .    1    2     2      5      0   \n",
       "37501      M          N       12         .    2    2     1      5      0   \n",
       "37502      F        NaN        .         .    1    2     2      5      0   \n",
       "37503      F          N       10         .    0    2     2      4      0   \n",
       "\n",
       "       NPPAN  ... AMYLASE CARDARREST_NEURO INOTROP_SUPPORT_DON REM_CD  \\\n",
       "0          0  ...       .                U                   N      4   \n",
       "1          0  ...       .                U                   N      4   \n",
       "2          1  ...       .                U                   N      4   \n",
       "3          0  ...       .                U                   N      4   \n",
       "4          0  ...       .                U                   N      4   \n",
       "...      ...  ...     ...              ...                 ...    ...   \n",
       "37499      0  ...       .              NaN                 NaN      4   \n",
       "37500      0  ...       .              NaN                 NaN      4   \n",
       "37501      0  ...       .              NaN                 NaN      4   \n",
       "37502      0  ...   87.00                N                   Y      4   \n",
       "37503      0  ...       .              NaN                 NaN      4   \n",
       "\n",
       "      AGE_GROUP DON_TY MULTIORG    TX_DATE FAILDATE_PA PX_STAT_DATE  \n",
       "0             A      C      NaN 1994-06-11           .   06/21/1994  \n",
       "1             A      C      NaN 1995-04-18           .   01/16/2003  \n",
       "2             A      C      NaN 1995-07-29           .   05/04/1998  \n",
       "3             A      C      NaN 1995-09-01  09/02/1995   07/04/2004  \n",
       "4             A      C      NaN 1997-01-17  12/27/1999   12/28/1999  \n",
       "...         ...    ...      ...        ...         ...          ...  \n",
       "37499         A      C      NaN 2024-03-21           .            .  \n",
       "37500         A      C      NaN 2024-03-17           .            .  \n",
       "37501         A      C      NaN 2024-03-11           .            .  \n",
       "37502         A      C      NaN 2024-03-20           .            .  \n",
       "37503         A      C      NaN 2024-03-29           .            .  \n",
       "\n",
       "[34162 rows x 68 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34024, 68)\n"
     ]
    }
   ],
   "source": [
    "#remove very recent transplants\n",
    "\n",
    "clean_good = clean_good[clean_good[\"PX_STAT_DATE\"] != \".\"]\n",
    "print(clean_good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_10452\\3346024158.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_10452\\3346024158.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)\n"
     ]
    }
   ],
   "source": [
    "clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
    "clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.to_datetime(\"04/04/2019\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove transplants with less than 5 years of followup time\n",
    "#clean_good = clean_good[clean_good[\"TX_DATE\"] < cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34024, 68)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = very_clean_data[very_clean_data[\"AGE_GROUP\"] == \"A\"]\n",
    "\n",
    "very_clean_data = very_clean_data[very_clean_data[\"DON_TY\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = very_clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"HLAMIS\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33004, 68)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pre_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23436, 68)\n",
      "(23431, 68)\n"
     ]
    }
   ],
   "source": [
    "#grafts that survived five years\n",
    "surv = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"Y\"]\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"FAILDATE_PA\"] == \".\"]\n",
    "print(surv.shape)\n",
    "surv[\"time_frame\"] = surv[\"PX_STAT_DATE\"] - surv[\"TX_DATE\"]\n",
    "surv[\"time_frame\"] = surv[\"time_frame\"].dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 68)\n",
      "(9559, 68)\n",
      "(9559, 68)\n",
      "(9559, 69)\n",
      "(9559, 69)\n",
      "(9534, 69)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fail = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"N\"]\n",
    "print(fail.shape)\n",
    "#drop data wihtout fail date\n",
    "fail = fail[fail[\"FAILDATE_PA\"] != \".\"]\n",
    "print(fail.shape)\n",
    "fail[\"FAILDATE_PA\"] = pd.to_datetime(fail[\"FAILDATE_PA\"], dayfirst=False)\n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"FAILDATE_PA\"] - fail[\"TX_DATE\"] \n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"fail_frame\"].dt.days\n",
    "print(fail.shape)\n",
    "fail[\"time_frame\"] = fail[\"fail_frame\"]\n",
    "fail = fail[fail[\"time_frame\"] >= 0] \n",
    "fail = fail.drop(columns=[\"fail_frame\"], axis=1)\n",
    "print(fail.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [surv, fail]\n",
    "labelled_pre_imp = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_pre_imp = labelled_pre_imp.sort_values(['index'])\n",
    "no_longer_needed = [\"PX_STAT_DATE\", \"FAILDATE_PA\", \n",
    "                    \"TX_DATE\", \"AGE_GROUP\", \"DON_TY\", \"REM_CD\"]\n",
    "labelled_pre_imp = labelled_pre_imp.drop(columns=no_longer_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 86 donors with unkown height or weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_DON_CALC\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = labelled_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(imputation):\n",
    "    # Replace missing values with \"U\" in column: 'PERIP_VASC'\n",
    "    imputation = imputation.fillna({'PERIP_VASC': \"U\"})\n",
    "  # Change column type to int32 for column: 'AMIS'\n",
    "    imputation = imputation.astype({'AMIS': 'int32'})\n",
    "    # Change column type to int32 for columns: 'BMIS', 'DRMIS', 'HLAMIS'\n",
    "    imputation = imputation.astype({'BMIS': 'int32', 'DRMIS': 'int32', 'HLAMIS': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE_DON'\n",
    "    imputation = imputation.astype({'AGE_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DDAVP_DON'\n",
    "    imputation = imputation.fillna({'DDAVP_DON': \"U\"})\n",
    "    # Replace missing values with \"N\" in column: 'CMV_DON'\n",
    "    imputation = imputation.fillna({'CMV_DON': \"N\"})\n",
    "    # Replace all instances of \"ND\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"I\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"I\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"C\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"C\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"P\" with \"1\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    \n",
    "   # Replace missing values with \"N\" in column: 'NON_HRT_DON'\n",
    "    imputation = imputation.fillna({'NON_HRT_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'ANTIHYPE_DON'\n",
    "    imputation = imputation.fillna({'ANTIHYPE_DON': \"U\"})\n",
    "   # Change column type to string for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'BUN_DON'\n",
    "    imputation.loc[imputation['BUN_DON'].str.lower() == \".\".lower(), 'BUN_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'BUN_DON'\n",
    "    imputation = imputation.fillna({'BUN_DON': imputation['BUN_DON'].median()})\n",
    "    # Change column type to string for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_DON'\n",
    "    imputation.loc[imputation['CREAT_DON'].str.lower() == \".\".lower(), 'CREAT_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_DON'\n",
    "    imputation = imputation.fillna({'CREAT_DON': imputation['CREAT_DON'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PT_DIURETICS_DON'\n",
    "    imputation = imputation.fillna({'PT_DIURETICS_DON': \"U\"})\n",
    "   \n",
    "    # Replace missing values with \"U\" in column: 'PT_STEROIDS_DON'\n",
    "    imputation = imputation.fillna({'PT_STEROIDS_DON': \"U\"})\n",
    "   # Replace missing values with \"U\" in column: 'PT_T3_DON'\n",
    "    imputation = imputation.fillna({'PT_T3_DON': \"U\"})\n",
    "     # Replace missing values with \"U\" in column: 'PT_T4_DON'\n",
    "    imputation = imputation.fillna({'PT_T4_DON': \"U\"})\n",
    "   # Change column type to string for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'string', 'SGPT_DON': 'string', 'TBILI_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation.loc[imputation['SGOT_DON'].str.lower() == \".\".lower(), 'SGOT_DON'] = np.nan\n",
    "    imputation.loc[imputation['SGPT_DON'].str.lower() == \".\".lower(), 'SGPT_DON'] = np.nan\n",
    "    imputation.loc[imputation['TBILI_DON'].str.lower() == \".\".lower(), 'TBILI_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'float32', 'SGPT_DON': 'float32', 'TBILI_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.fillna({'SGOT_DON': imputation['SGOT_DON'].median(), 'SGPT_DON': imputation['SGPT_DON'].median(), 'TBILI_DON': imputation['TBILI_DON'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'VASODIL_DON'\n",
    "    imputation = imputation.fillna({'VASODIL_DON': \"U\"})\n",
    "    # Replace missing values with \"U\" in column: 'CLIN_INFECT_DON'\n",
    "    imputation = imputation.fillna({'CLIN_INFECT_DON': \"U\"})\n",
    "    \n",
    "    # Replace missing values with \"U\" in column: 'HIST_CIG_DON'\n",
    "    imputation = imputation.fillna({'HIST_CIG_DON': \"U\"})\n",
    "    # Replace missing values with \"U\" in columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    imputation = imputation.fillna({'HIST_COCAINE_DON': \"U\", 'HIST_HYPERTENS_DON': \"U\", 'HIST_OTH_DRUG_DON': \"U\"})\n",
    " # Replace missing values with \"U\" in column: 'HEPARIN_DON'\n",
    "    imputation = imputation.fillna({'HEPARIN_DON': \"U\"})\n",
    "    # Change column type to int32 for column: 'ABO_MAT'\n",
    "    imputation = imputation.astype({'ABO_MAT': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE'\n",
    "    imputation = imputation.astype({'AGE': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DIAL_TRR'\n",
    "    imputation = imputation.fillna({'DIAL_TRR': \"U\"})\n",
    "     # Replace missing values with \"0\" in column: 'MULTIORG'\n",
    "    imputation = imputation.fillna({'MULTIORG': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'MULTIORG'\n",
    "    imputation['MULTIORG'] = imputation['MULTIORG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'MULTIORG'\n",
    "    imputation = imputation.astype({'MULTIORG': 'int32'})\n",
    "    # Change column type to string for column: 'ART_RECON'\n",
    "    imputation = imputation.astype({'ART_RECON': 'string'})\n",
    "    # Replace all instances of \".\" with \"2\" in column: 'ART_RECON'\n",
    "    imputation['ART_RECON'] = imputation['ART_RECON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # Change column type to string for column: 'DUCT_MGMT'\n",
    "    imputation = imputation.astype({'DUCT_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation['DUCT_MGMT'] = imputation['DUCT_MGMT'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # Change column type to string for column: 'GRF_PLACEM'\n",
    "    imputation = imputation.astype({'GRF_PLACEM': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'GRF_PLACEM'\n",
    "    imputation['GRF_PLACEM'] = imputation['GRF_PLACEM'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'PA_PRESERV_TM'\n",
    "    imputation.loc[imputation['PA_PRESERV_TM'].str.lower() == \".\".lower(), 'PA_PRESERV_TM'] = np.nan\n",
    "    # Change column type to float32 for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.fillna({'PA_PRESERV_TM': imputation['PA_PRESERV_TM'].median()})\n",
    "\n",
    "    # Change column type to string for column: 'VASC_MGMT'\n",
    "    imputation = imputation.astype({'VASC_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'VASC_MGMT'\n",
    "    imputation['VASC_MGMT'] = imputation['VASC_MGMT'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # Replace missing values with \"N\" in column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.fillna({'VEN_EXT_GRF': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.astype({'VEN_EXT_GRF': 'int32'})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Change column type to string for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation.loc[imputation['DAYSWAIT_CHRON_PA'].str.lower() == \".\".lower(), 'DAYSWAIT_CHRON_PA'] = np.nan\n",
    "    # Change column type to float32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.fillna({'DAYSWAIT_CHRON_PA': imputation['DAYSWAIT_CHRON_PA'].median()})\n",
    "    # Change column type to int32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'int32'})\n",
    "    imputation['HBV_CORE'] = imputation['HBV_CORE'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HCV_SEROSTATUS'] = imputation['HCV_SEROSTATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['CMV_STATUS'] = imputation['CMV_STATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation = imputation.fillna({'EBV_SEROSTATUS': \"U\"})\n",
    "   # Change column type to string for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'string', 'WGT_KG_CALC': 'string', 'BMI_CALC': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'HGT_CM_CALC'\n",
    "    imputation.loc[imputation['HGT_CM_CALC'].str.lower() == \".\".lower(), 'HGT_CM_CALC'] = np.nan\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation.loc[imputation['WGT_KG_CALC'].str.lower() == \".\".lower(), 'WGT_KG_CALC'] = np.nan\n",
    "    imputation.loc[imputation['BMI_CALC'].str.lower() == \".\".lower(), 'BMI_CALC'] = np.nan\n",
    "    # Change column type to float32 for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'float32', 'WGT_KG_CALC': 'float32', 'BMI_CALC': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.fillna({'HGT_CM_CALC': imputation['HGT_CM_CALC'].median(), 'WGT_KG_CALC': imputation['WGT_KG_CALC'].median(), 'BMI_CALC': imputation['BMI_CALC'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PROTEIN_URINE'\n",
    "    imputation = imputation.fillna({'PROTEIN_URINE': \"U\"})\n",
    "    # Replace missing values with \"U\" in column: 'CARDARREST_NEURO'\n",
    "    imputation = imputation.fillna({'CARDARREST_NEURO': \"U\"})\n",
    "   # Replace missing values with \"U\" in column: 'INOTROP_SUPPORT_DON'\n",
    "    imputation = imputation.fillna({'INOTROP_SUPPORT_DON': \"U\"})\n",
    "\n",
    "    # Change column type to int32 for column: 'ETHCAT'\n",
    "    # Replace all instances of \".\" with \"\" in column: 'AGE_DIAB'\n",
    "    imputation.loc[imputation['AGE_DIAB'].str.lower() == \".\".lower(), 'AGE_DIAB'] = np.nan\n",
    "    # Change column type to float32 for column: 'AGE_DIAB'\n",
    "    imputation = imputation.astype({'AGE_DIAB': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'AGE_DIAB'\n",
    "    imputation = imputation.fillna({'AGE_DIAB': imputation['AGE_DIAB'].median()})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_TRR'\n",
    "    imputation.loc[imputation['CREAT_TRR'].str.lower() == \".\".lower(), 'CREAT_TRR'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_TRR'\n",
    "    imputation = imputation.astype({'CREAT_TRR': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_TRR'\n",
    "    imputation = imputation.fillna({'CREAT_TRR': imputation['CREAT_TRR'].median()})\n",
    "    # Change column type to string for column: 'ETHCAT_DON'\n",
    "    # Change column type to float32 for columns: 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_DON_CALC': 'float32', 'WGT_KG_DON_CALC': 'float32', 'BMI_DON_CALC': 'float32'})\n",
    "    # Round column 'BMI_DON_CALC' (Number of decimals: 1)\n",
    "    imputation = imputation.round({'BMI_DON_CALC': 1})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"5001\" in column: 'DIAG_PA'\n",
    "    imputation['DIAG_PA'] = imputation['DIAG_PA'].str.replace(\".\", \"5001\", case=False, regex=False)\n",
    "    return imputation\n",
    "   \n",
    "\n",
    "\n",
    "imputation_clean_no_oh = clean_data(imputation.copy())\n",
    "\n",
    "imputation_new = clean_data(imputation.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>PERIP_VASC</th>\n",
       "      <th>AGE_DIAB</th>\n",
       "      <th>CREAT_TRR</th>\n",
       "      <th>AMIS</th>\n",
       "      <th>BMIS</th>\n",
       "      <th>DRMIS</th>\n",
       "      <th>HLAMIS</th>\n",
       "      <th>NPKID</th>\n",
       "      <th>NPPAN</th>\n",
       "      <th>...</th>\n",
       "      <th>HGT_CM_CALC</th>\n",
       "      <th>WGT_KG_CALC</th>\n",
       "      <th>BMI_CALC</th>\n",
       "      <th>PROTEIN_URINE</th>\n",
       "      <th>LIPASE</th>\n",
       "      <th>AMYLASE</th>\n",
       "      <th>CARDARREST_NEURO</th>\n",
       "      <th>INOTROP_SUPPORT_DON</th>\n",
       "      <th>MULTIORG</th>\n",
       "      <th>time_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>86.099998</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>61.099998</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>165.100006</td>\n",
       "      <td>66.199997</td>\n",
       "      <td>24.299999</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GENDER PERIP_VASC  AGE_DIAB  CREAT_TRR  AMIS  BMIS  DRMIS  HLAMIS  NPKID  \\\n",
       "0       0          0      13.0       2.90     1     2      2       5      1   \n",
       "1       1          0      13.0       1.00     0     1      0       1      1   \n",
       "2       1          0      13.0       1.30     0     1      2       3      1   \n",
       "14      1          0      13.0       1.00     1     2      1       4      1   \n",
       "16      1          0      13.0       5.22     1     0      1       2      0   \n",
       "\n",
       "    NPPAN  ...  HGT_CM_CALC WGT_KG_CALC   BMI_CALC PROTEIN_URINE  LIPASE  \\\n",
       "0       0  ...   183.000000   86.099998  25.700001             0    26.0   \n",
       "1       0  ...   155.000000   46.700001  19.400000             0    26.0   \n",
       "2       1  ...   165.000000   61.099998  22.400000             0    26.0   \n",
       "14      1  ...   165.100006   66.199997  24.299999             0    26.0   \n",
       "16      0  ...   168.000000   77.000000  27.299999             0    26.0   \n",
       "\n",
       "   AMYLASE  CARDARREST_NEURO  INOTROP_SUPPORT_DON MULTIORG time_frame  \n",
       "0     63.0                 0                    0        0         10  \n",
       "1     63.0                 0                    0        0       2830  \n",
       "2     63.0                 0                    0        0       1010  \n",
       "14    63.0                 0                    0        0      10406  \n",
       "16    63.0                 0                    0        0       9605  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def clean_data(imputation_new):\n",
    "    # Replace all instances of \"M\" with \"0\" in columns: 'GENDER', 'GENDER_DON'\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"F\" with \"1\" in columns: 'GENDER', 'GENDER_DON'\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in columns: 'PERIP_VASC', 'DDAVP_DON' and 17 other columns\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"Y\" in columns: 'HEPARIN_DON', 'DIAL_TRR'\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"U\", \"Y\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"U\", \"Y\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in columns: 'GENDER', 'ABO' and 34 other columns\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['GRF_STAT_PA'] = imputation_new['GRF_STAT_PA'].str.replace(\"Y\", \"0\", case=False, regex=False)\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['TX_TYPE'] = imputation_new['TX_TYPE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['LIPASE'] = imputation_new['LIPASE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['AMYLASE'] = imputation_new['AMYLASE'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in columns: 'GENDER', 'ABO' and 34 other columns\n",
    "    imputation_new['GENDER'] = imputation_new['GENDER'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PERIP_VASC'] = imputation_new['PERIP_VASC'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DDAVP_DON'] = imputation_new['DDAVP_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GENDER_DON'] = imputation_new['GENDER_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ANTIHYPE_DON'] = imputation_new['ANTIHYPE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_DIURETICS_DON'] = imputation_new['PT_DIURETICS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_STEROIDS_DON'] = imputation_new['PT_STEROIDS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_T3_DON'] = imputation_new['PT_T3_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['VASODIL_DON'] = imputation_new['VASODIL_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CLIN_INFECT_DON'] = imputation_new['CLIN_INFECT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_CIG_DON'] = imputation_new['HIST_CIG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_HYPERTENS_DON'] = imputation_new['HIST_HYPERTENS_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PT_T4_DON'] = imputation_new['PT_T4_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_COCAINE_DON'] = imputation_new['HIST_COCAINE_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HIST_OTH_DRUG_DON'] = imputation_new['HIST_OTH_DRUG_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HEPARIN_DON'] = imputation_new['HEPARIN_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DIAL_TRR'] = imputation_new['DIAL_TRR'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['GRF_STAT_PA'] = imputation_new['GRF_STAT_PA'].str.replace(\"N\", \"1\", case=False, regex=False)\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['TX_TYPE'] = imputation_new['TX_TYPE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['MALIG'] = imputation_new['MALIG'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['PROTEIN_URINE'] = imputation_new['PROTEIN_URINE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['LIPASE'] = imputation_new['LIPASE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['AMYLASE'] = imputation_new['AMYLASE'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CARDARREST_NEURO'] = imputation_new['CARDARREST_NEURO'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    imputation_new['INOTROP_SUPPORT_DON'] = imputation_new['INOTROP_SUPPORT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Change column type to string for columns: 'COD_CAD_DON', 'DEATH_CIRCUM_DON' and 5 other columns\n",
    "    imputation_new = imputation_new.astype({'ART_RECON': 'string', 'DUCT_MGMT': 'string', 'DIAG_PA': 'string'})\n",
    "    # Replace all instances of \"P\" with \"1\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"0\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HBV_CORE'] = imputation_new['HBV_CORE'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['HCV_SEROSTATUS'] = imputation_new['HCV_SEROSTATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    imputation_new['CMV_STATUS'] = imputation_new['CMV_STATUS'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"0D\" with \"0\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation_new['EBV_SEROSTATUS'] = imputation_new['EBV_SEROSTATUS'].str.replace(\"0D\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in columns: 'EBV_SEROSTATUS', 'HBV_CORE' and 2 other columns\n",
    "    imputation_new = imputation_new.fillna({'EBV_SEROSTATUS': \"0\", 'HBV_CORE': \"0\", 'HCV_SEROSTATUS': \"0\", 'CMV_STATUS': \"0\"})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new.loc[imputation_new['LIPASE'].str.lower() == \".\".lower(), 'LIPASE'] = np.nan\n",
    "    imputation_new.loc[imputation_new['AMYLASE'].str.lower() == \".\".lower(), 'AMYLASE'] = np.nan\n",
    "    # Change column type to float32 for columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new = imputation_new.astype({'LIPASE': 'float32', 'AMYLASE': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'LIPASE', 'AMYLASE'\n",
    "    imputation_new = imputation_new.fillna({'LIPASE': imputation_new['LIPASE'].median(), 'AMYLASE': imputation_new['AMYLASE'].median()})\n",
    "    # One-hot encode column: 'TX_TYPE'\n",
    "    insert_loc = imputation_new.columns.get_loc('TX_TYPE')\n",
    "    imputation_new = pd.concat([imputation_new.iloc[:,:insert_loc], pd.get_dummies(imputation_new.loc[:, ['TX_TYPE']]), imputation_new.iloc[:,insert_loc+1:]], axis=1)\n",
    "    \n",
    "    \n",
    "    # Replace all instances of \"4\" with \"other\" in column: 'DUCT_MGMT'\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"4\", \"other\", case=False, regex=False)\n",
    "    # Replace all instances of \"5\" with \"other\" in column: 'DUCT_MGMT'\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"5\", \"other\", case=False, regex=False)\n",
    "    # Replace all instances of \"999\" with \"other\" in column: 'DUCT_MGMT'\n",
    "    imputation_new['DUCT_MGMT'] = imputation_new['DUCT_MGMT'].str.replace(\"999\", \"other\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"999\" in column: 'ART_RECON'\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"3\", \"999\", case=False, regex=False)\n",
    "    # Replace all instances of \"1\" with \"999\" in column: 'ART_RECON'\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"1\", \"999\", case=False, regex=False)\n",
    "    # Replace all instances of \"4\" with \"999\" in column: 'ART_RECON'\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"4\", \"999\", case=False, regex=False)\n",
    "    # Replace all instances of \"5\" with \"999\" in column: 'ART_RECON'\n",
    "    imputation_new['ART_RECON'] = imputation_new['ART_RECON'].str.replace(\"5\", \"999\", case=False, regex=False)\n",
    "    # Rename column 'ART_RECON' to 'ART_RECON_is2'\n",
    "    imputation_new = imputation_new.rename(columns={'ART_RECON': 'ART_RECON_is2'})\n",
    "    # Replace all instances of \"2\" with \"1\" in column: 'ART_RECON_is2'\n",
    "    imputation_new['ART_RECON_is2'] = imputation_new['ART_RECON_is2'].str.replace(\"2\", \"1\", case=False, regex=False)\n",
    "    # Replace all instances of \"999\" with \"0\" in column: 'ART_RECON_is2'\n",
    "    imputation_new['ART_RECON_is2'] = imputation_new['ART_RECON_is2'].str.replace(\"999\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"2\" with \"0\" in column: 'GRF_PLACEM'\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"2\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"0\" in column: 'GRF_PLACEM'\n",
    "    imputation_new['GRF_PLACEM'] = imputation_new['GRF_PLACEM'].str.replace(\"3\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'GRF_PLACEM' to 'GRF_PLACEM_is1'\n",
    "    imputation_new = imputation_new.rename(columns={'GRF_PLACEM': 'GRF_PLACEM_is1'})\n",
    "    # One-hot encode column: 'DUCT_MGMT'\n",
    "    insert_loc = imputation_new.columns.get_loc('DUCT_MGMT')\n",
    "    imputation_new = pd.concat([imputation_new.iloc[:,:insert_loc], pd.get_dummies(imputation_new.loc[:, ['DUCT_MGMT']]), imputation_new.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"2\" with \"0\" in column: 'VASC_MGMT'\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"2\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"3\" with \"0\" in column: 'VASC_MGMT'\n",
    "    imputation_new['VASC_MGMT'] = imputation_new['VASC_MGMT'].str.replace(\"3\", \"0\", case=False, regex=False)\n",
    "    # Rename column 'VASC_MGMT' to 'VASC_MGMT_is1'\n",
    "    imputation_new = imputation_new.rename(columns={'VASC_MGMT': 'VASC_MGMT_is1'})\n",
    "    # Replace all instances of \"5000\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5000\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"999\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"999\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5009\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5009\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5008\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5008\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5007\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5007\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5003\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5003\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5005\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5005\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5004\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5004\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5006\" with \"5002\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5006\", \"5002\", case=False, regex=False)\n",
    "    # Replace all instances of \"5002\" with \"0\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5002\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"5001\" with \"1\" in column: 'DIAG_PA'\n",
    "    imputation_new['DIAG_PA'] = imputation_new['DIAG_PA'].str.replace(\"5001\", \"1\", case=False, regex=False)\n",
    "    # Rename column 'DIAG_PA' to 'DIAG_PA_is5001'\n",
    "    imputation_new = imputation_new.rename(columns={'DIAG_PA': 'DIAG_PA_is5001'})\n",
    "    \n",
    "    \n",
    "    return imputation_new\n",
    "\n",
    "imputation_new_clean = clean_data(imputation_new.copy())\n",
    "imputation_new_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_new_clean[imputation_new_clean.select_dtypes(include=['bool']).columns] = imputation_new_clean.select_dtypes(include=['bool']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = [\"BUN_DON\", \"CREAT_DON\", \"SGOT_DON\", \"SGPT_DON\", \"TBILI_DON\", \"LIPASE\", \"AMYLASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "\n",
    "imputation_new_clean[skewed_cols] = np.log(imputation_new_clean[skewed_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_new_clean[imputation_new_clean.select_dtypes(include=['int']).columns] = imputation_new_clean.select_dtypes(include=['int']).astype(\"float32\")\n",
    "\n",
    "imputation_new_clean[imputation_new_clean.select_dtypes(include=['string']).columns] = imputation_new_clean.select_dtypes(include=['string']).astype(\"float32\")\n",
    "\n",
    "imputation_new_clean[imputation_new_clean.select_dtypes(include=['object']).columns] = imputation_new_clean.select_dtypes(include=['object']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_new_clean.to_csv(\"data_ready_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
