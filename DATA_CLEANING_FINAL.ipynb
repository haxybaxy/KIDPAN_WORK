{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_1452\\381285905.py:1: DtypeWarning: Columns (3,6,9,18,19,20,21,22,23,24,28,29,30,31,32,34,35,36,37,38,39,45,46,47,48,49,52,53,54,55,66,67,70,72,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,103,104,106,112,115,116,117,120,122,123,132,134,135,136,138,140,141,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,173,175,176,177,178,179,180,181,182,183,184,188,189,190,191,193,199,200,202,203,204,207,208,209,210,211,212,213,214,216,217,222,223,224,225,226,227,228,234,236,237,242,243,248,253,255,260,261,262,263,264,266,267,268,269,270,271,277,280,281,283,285,287,289,290,294,295,296,297,299,300,301,302,303,306,308,317,321,328,330,332,347,352,357,358,365,366,367,368,372,379,382,386,387,388,393,410,411,412,413,414,421,422,429,430,431,432,433,434,435,436,438,442,455,456,457,458,459,468,469,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PAN_data = pd.read_csv(\"PAN_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "PAN_data = pd.read_csv(\"PAN_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_94 = pd.to_datetime(\"04/01/1994\", dayfirst=False)\n",
    "pan_data_after_94 = PAN_data.copy()\n",
    "pan_data_after_94[\"TX_DATE\"] = pd.to_datetime(pan_data_after_94[\"TX_DATE\"], dayfirst=False)\n",
    "pan_data_after_94 = pan_data_after_94[pan_data_after_94[\"TX_DATE\"] > after_94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = [\n",
    "    \"GENDER\", \"PERIP_VASC\", \"AGE_DIAB\", \"ABO\", \"ABO_DON\", \"COD_CAD_DON\", \"DEATH_MECH_DON\",\n",
    "    \"CREAT_TRR\",\n",
    "    \"AMIS\", \"BMIS\", \"DRMIS\", \"HLAMIS\", \"NPKID\", \"NPPAN\", \"AGE_DON\", \"DDAVP_DON\", \"CMV_DON\",\n",
    "    \"GENDER_DON\",\n",
    "    \"NON_HRT_DON\", \"ANTIHYPE_DON\", \"BUN_DON\", \"CREAT_DON\", \n",
    "    \"PT_DIURETICS_DON\", \"PT_STEROIDS_DON\", \"PT_T4_DON\", \"SGOT_DON\",\n",
    "    \"SGPT_DON\", \"TBILI_DON\", \"VASODIL_DON\", \"CLIN_INFECT_DON\", \"HIST_CIG_DON\",\n",
    "    \"HIST_HYPERTENS_DON\", \"HIST_COCAINE_DON\", \"HIST_OTH_DRUG_DON\", \"HEPARIN_DON\", \n",
    "    \"BMI_DON_CALC\", \"ABO_MAT\", \"AGE\", \"DIAL_TRR\", \"ART_RECON\", \"DUCT_MGMT\", \"GRF_PLACEM\",\n",
    "    \"PA_PRESERV_TM\", \"VASC_MGMT\", \"VEN_EXT_GRF\",\n",
    "    \"DAYSWAIT_CHRON_PA\", \"EBV_SEROSTATUS\", \"HBV_CORE\",\n",
    "    \"HCV_SEROSTATUS\", \"CMV_STATUS\",\n",
    "    \"MALIG\", \"BMI_CALC\",\n",
    "    \"PROTEIN_URINE\", \"LIPASE\", \"AMYLASE\", \"CARDARREST_NEURO\", \"INOTROP_SUPPORT_DON\",   \n",
    "    \"REM_CD\", \"AGE_GROUP\", \"DON_TY\", \"MULTIORG\", \"TX_DATE\",\"FAILDATE_PA\",\"PX_STAT_DATE\", \"DIAB\", \"GRF_STAT_PA\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = pan_data_after_94[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_1452\\2907620572.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_1452\\2907620572.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])\n"
     ]
    }
   ],
   "source": [
    "# convert the reason of removal to numeric and only include those that underwent transplantation [2,3,4,14,15,18,19]\n",
    "clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
    "clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = clean_good[clean_good[\"REM_CD\"].isin([2,3,4,14,15,18,19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34024, 66)\n"
     ]
    }
   ],
   "source": [
    "#remove transplants with no followup\n",
    "\n",
    "clean_good = clean_good[clean_good[\"PX_STAT_DATE\"] != \".\"]\n",
    "print(clean_good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
    "clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = very_clean_data[very_clean_data[\"AGE_GROUP\"] == \"A\"]\n",
    "\n",
    "very_clean_data = very_clean_data[very_clean_data[\"DON_TY\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = very_clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"HLAMIS\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23436, 66)\n",
      "(23431, 66)\n"
     ]
    }
   ],
   "source": [
    "#grafts that survived five years\n",
    "surv = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"Y\"]\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"FAILDATE_PA\"] == \".\"]\n",
    "print(surv.shape)\n",
    "surv[\"time_frame\"] = surv[\"PX_STAT_DATE\"] - surv[\"TX_DATE\"]\n",
    "surv[\"time_frame\"] = surv[\"time_frame\"].dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 66)\n",
      "(9559, 66)\n",
      "(9559, 66)\n",
      "(9559, 67)\n",
      "(9559, 67)\n",
      "(9534, 67)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fail = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"N\"]\n",
    "print(fail.shape)\n",
    "#drop data wihtout fail date\n",
    "fail = fail[fail[\"FAILDATE_PA\"] != \".\"]\n",
    "print(fail.shape)\n",
    "fail[\"FAILDATE_PA\"] = pd.to_datetime(fail[\"FAILDATE_PA\"], dayfirst=False)\n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"FAILDATE_PA\"] - fail[\"TX_DATE\"] \n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"fail_frame\"].dt.days\n",
    "print(fail.shape)\n",
    "fail[\"time_frame\"] = fail[\"fail_frame\"]\n",
    "fail = fail[fail[\"time_frame\"] >= 0] \n",
    "fail = fail.drop(columns=[\"fail_frame\"], axis=1)\n",
    "print(fail.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [surv, fail]\n",
    "labelled_pre_imp = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_pre_imp = labelled_pre_imp.sort_values(['index'])\n",
    "no_longer_needed = [\"PX_STAT_DATE\", \"FAILDATE_PA\", \n",
    "                    \"TX_DATE\", \"AGE_GROUP\", \"DON_TY\", \"REM_CD\"]\n",
    "labelled_pre_imp = labelled_pre_imp.drop(columns=no_longer_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 86 donors with unkown height or weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_DON_CALC\"] != \".\"]\n",
    "\n",
    "#remove recipients with unkown height weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_CALC\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = labelled_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = imputation.replace(to_replace=\"U\", value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(imputation):\n",
    "    # Replace all instances of \"\" with \"\" in columns: 'GENDER', 'GENDER_DON'\n",
    "    imputation['GENDER'] = imputation['GENDER'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    imputation['GENDER_DON'] = imputation['GENDER_DON'].str.replace(\"M\", \"0\", case=False, regex=False)\n",
    "    imputation['GENDER'] = imputation['GENDER'].str.replace(\"f\", \"1\", case=False, regex=False)\n",
    "    imputation['GENDER_DON'] = imputation['GENDER_DON'].str.replace(\"F\", \"1\", case=False, regex=False)\n",
    "    # Replace missing values with \"N\" in column: 'PERIP_VASC' : the most common value\n",
    "    imputation = imputation.fillna({'PERIP_VASC': \"N\"})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'AGE_DIAB'\n",
    "    imputation.loc[imputation['AGE_DIAB'].str.lower() == \".\".lower(), 'AGE_DIAB'] = np.nan\n",
    "    # Change column type to float32 for column: 'AGE_DIAB'\n",
    "    imputation = imputation.astype({'AGE_DIAB': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'AGE_DIAB'\n",
    "    imputation = imputation.fillna({'AGE_DIAB': imputation['AGE_DIAB'].median()})\n",
    "    # Change column type to string for columns: 'ABO', 'ABO_DON' and 3 other columns\n",
    "    imputation = imputation.astype({'ABO': 'string', 'ABO_DON': 'string', 'COD_CAD_DON': 'string', 'DEATH_MECH_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_TRR'\n",
    "    imputation.loc[imputation['CREAT_TRR'].str.lower() == \".\".lower(), 'CREAT_TRR'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_TRR'\n",
    "    imputation = imputation.astype({'CREAT_TRR': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_TRR'\n",
    "    imputation = imputation.fillna({'CREAT_TRR': imputation['CREAT_TRR'].median()})\n",
    "    # Change column type to float32 for columns: 'AMIS', 'BMIS' and 2 other columns\n",
    "    imputation = imputation.astype({'AMIS': 'float32', 'BMIS': 'float32', 'DRMIS': 'float32', 'HLAMIS': 'float32'})\n",
    "    # One-hot encode columns: 'ABO', 'ABO_DON'\n",
    "    for column in ['ABO', 'ABO_DON']:\n",
    "        insert_loc = imputation.columns.get_loc(column)\n",
    "        imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, [column]]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"4\" with \"\" in column: 'COD_CAD_DON'\n",
    "    imputation['COD_CAD_DON'] = imputation['COD_CAD_DON'].str.replace(\"4\", \"other\", case=False, regex=False)\n",
    "    imputation['COD_CAD_DON'] = imputation['COD_CAD_DON'].str.replace(\"999\", \"other\", case=False, regex=False)\n",
    "    imputation['COD_CAD_DON'] = imputation['COD_CAD_DON'].str.replace(\".\", \"other\", case=False, regex=False)\n",
    "    # One-hot encode column: 'COD_CAD_DON'\n",
    "    insert_loc = imputation.columns.get_loc('COD_CAD_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['COD_CAD_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Rename column 'COD_CAD_DON_1' to 'COD_CAD_DON_anoxia'\n",
    "    imputation = imputation.rename(columns={'COD_CAD_DON_1': 'COD_CAD_DON_anoxia'})\n",
    "    # Rename column 'COD_CAD_DON_2' to 'COD_CAD_DON_stroke'\n",
    "    imputation = imputation.rename(columns={'COD_CAD_DON_2': 'COD_CAD_DON_stroke'})\n",
    "    # Rename column 'COD_CAD_DON_3' to 'COD_CAD_DON_headTrauma'\n",
    "    imputation = imputation.rename(columns={'COD_CAD_DON_3': 'COD_CAD_DON_headTrauma'})\n",
    "    # Replace all instances of \"5\" with \"other\" in column: 'DEATH_MECH_DON'\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"5\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"10\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"3\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"12\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"4\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"6\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"995\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"997\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"2\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"1\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \"8\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    imputation.loc[imputation['DEATH_MECH_DON'].str.lower() == \".\".lower(), 'DEATH_MECH_DON'] = \"other\"\n",
    "    # One-hot encode column: 'DEATH_MECH_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DEATH_MECH_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DEATH_MECH_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Rename column 'DEATH_MECH_DON_11' to 'DEATH_MECH_DON_ICH'\n",
    "    imputation = imputation.rename(columns={'DEATH_MECH_DON_11': 'DEATH_MECH_DON_ICH'})\n",
    "    # Rename column 'DEATH_MECH_DON_7' to 'DEATH_MECH_DON_GSW'\n",
    "    imputation = imputation.rename(columns={'DEATH_MECH_DON_7': 'DEATH_MECH_DON_GSW'})\n",
    "    # Rename column 'DEATH_MECH_DON_9' to 'DEATH_MECH_DON_bluntInjury'\n",
    "    imputation = imputation.rename(columns={'DEATH_MECH_DON_9': 'DEATH_MECH_DON_bluntInjury'})\n",
    "    # Change column type to float32 for column: 'AGE_DON'\n",
    "    imputation = imputation.astype({'AGE_DON': 'float32'})\n",
    "    # Replace missing values with \"N\" in column: 'DDAVP_DON': most common value\n",
    "    imputation = imputation.fillna({'DDAVP_DON': \"N\"})\n",
    "    # Replace all instances of \"ND\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation.loc[imputation['CMV_DON'].str.lower() == \"ND\".lower(), 'CMV_DON'] = \"N\"\n",
    "    imputation.loc[imputation['CMV_DON'].str.lower() == \"I\".lower(), 'CMV_DON'] = \"N\"\n",
    "    imputation.loc[imputation['CMV_DON'].str.lower() == \"C\".lower(), 'CMV_DON'] = \"N\"\n",
    "    # Replace missing values with \"N\" in column: 'CMV_DON'\n",
    "    imputation = imputation.fillna({'CMV_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in columns: 'NON_HRT_DON', 'ANTIHYPE_DON'\n",
    "    imputation = imputation.fillna({'NON_HRT_DON': \"N\", 'ANTIHYPE_DON': \"N\"})\n",
    "    # Change column type to string for columns: 'BUN_DON', 'CREAT_DON' and 3 other columns\n",
    "    imputation = imputation.astype({'BUN_DON': 'string', 'CREAT_DON': 'string', 'SGOT_DON': 'string', 'SGPT_DON': 'string', 'TBILI_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'BUN_DON'\n",
    "    imputation.loc[imputation['BUN_DON'].str.lower() == \".\".lower(), 'BUN_DON'] = np.nan\n",
    "    imputation.loc[imputation['CREAT_DON'].str.lower() == \".\".lower(), 'CREAT_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'CREAT_DON', 'BUN_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'float32', 'BUN_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'BUN_DON', 'CREAT_DON'\n",
    "    imputation = imputation.fillna({'BUN_DON': imputation['BUN_DON'].median(), 'CREAT_DON': imputation['CREAT_DON'].median()})\n",
    "    # Replace missing values with \"Y\" in column: 'PT_DIURETICS_DON'\n",
    "    imputation = imputation.fillna({'PT_DIURETICS_DON': \"Y\"})\n",
    "    # Replace missing values with \"Y\" in column: 'PT_STEROIDS_DON'\n",
    "    imputation = imputation.fillna({'PT_STEROIDS_DON': \"Y\"})\n",
    "    # Replace missing values with \"Y\" in column: 'PT_T4_DON'\n",
    "    imputation = imputation.fillna({'PT_T4_DON': \"Y\"})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'SGOT_DON'\n",
    "    imputation.loc[imputation['SGOT_DON'].str.lower() == \".\".lower(), 'SGOT_DON'] = np.nan\n",
    "    imputation.loc[imputation['SGPT_DON'].str.lower() == \".\".lower(), 'SGPT_DON'] = np.nan\n",
    "    imputation.loc[imputation['TBILI_DON'].str.lower() == \".\".lower(), 'TBILI_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'SGPT_DON', 'SGOT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGPT_DON': 'float32', 'SGOT_DON': 'float32', 'TBILI_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.fillna({'SGOT_DON': imputation['SGOT_DON'].median(), 'SGPT_DON': imputation['SGPT_DON'].median(), 'TBILI_DON': imputation['TBILI_DON'].median()})\n",
    "    # Replace missing values with \"N\" in column: 'VASODIL_DON'\n",
    "    imputation = imputation.fillna({'VASODIL_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'CLIN_INFECT_DON'\n",
    "    imputation = imputation.fillna({'CLIN_INFECT_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'HIST_CIG_DON'\n",
    "    imputation = imputation.fillna({'HIST_CIG_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'HIST_HYPERTENS_DON'\n",
    "    imputation = imputation.fillna({'HIST_HYPERTENS_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'HIST_COCAINE_DON'\n",
    "    imputation = imputation.fillna({'HIST_COCAINE_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'HIST_OTH_DRUG_DON'\n",
    "    imputation = imputation.fillna({'HIST_OTH_DRUG_DON': \"N\"})\n",
    "    # Replace missing values with \"Y\" in column: 'HEPARIN_DON'\n",
    "    imputation = imputation.fillna({'HEPARIN_DON': \"Y\"})\n",
    "    # Replace missing values with \"Y\" in column: 'DIAL_TRR'\n",
    "    imputation = imputation.fillna({'DIAL_TRR': \"Y\"})\n",
    "    # Change column type to string for columns: 'VASC_MGMT', 'GRF_PLACEM' and 2 other columns\n",
    "    imputation = imputation.astype({'VASC_MGMT': 'string', 'GRF_PLACEM': 'string', 'DUCT_MGMT': 'string', 'ART_RECON': 'string'})\n",
    "    # Replace all instances of \"3\" with \"\" in column: 'ART_RECON'\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"3\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"999\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"5\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"4\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"1\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \".\".lower(), 'ART_RECON'] = \"0\"\n",
    "    imputation.loc[imputation['ART_RECON'].str.lower() == \"2\".lower(), 'ART_RECON'] = \"1\"\n",
    "    # Rename column 'ART_RECON' to 'ART_RECON_Y-Graft'\n",
    "    imputation = imputation.rename(columns={'ART_RECON': 'ART_RECON_Y-Graft'})\n",
    "    # Replace all instances of \"999\" with \"other\" in column: 'DUCT_MGMT'\n",
    "    imputation.loc[imputation['DUCT_MGMT'].str.lower() == \"999\".lower(), 'DUCT_MGMT'] = \"other\"\n",
    "    imputation.loc[imputation['DUCT_MGMT'].str.lower() == \"4\".lower(), 'DUCT_MGMT'] = \"other\"\n",
    "    imputation.loc[imputation['DUCT_MGMT'].str.lower() == \"5\".lower(), 'DUCT_MGMT'] = \"other\"\n",
    "    imputation.loc[imputation['DUCT_MGMT'].str.lower() == \".\".lower(), 'DUCT_MGMT'] = \"other\"\n",
    "    # One-hot encode column: 'DUCT_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('DUCT_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DUCT_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Rename column 'DUCT_MGMT_1' to 'DUCT_MGMT_ENTERIC W/ROUX-EN-Y'\n",
    "    imputation = imputation.rename(columns={'DUCT_MGMT_1': 'DUCT_MGMT_ENTERIC W/ROUX-EN-Y'})\n",
    "    # Rename column 'DUCT_MGMT_2' to 'DUCT_MGMT_ENTERIC W/O ROUX-EN-Y'\n",
    "    imputation = imputation.rename(columns={'DUCT_MGMT_2': 'DUCT_MGMT_ENTERIC W/O ROUX-EN-Y'})\n",
    "    # Rename column 'DUCT_MGMT_3' to 'DUCT_MGMT_cystostomy'\n",
    "    imputation = imputation.rename(columns={'DUCT_MGMT_3': 'DUCT_MGMT_cystostomy'})\n",
    "    # Replace all instances of \"2\" with \"0\" in column: 'GRF_PLACEM'\n",
    "    imputation.loc[imputation['GRF_PLACEM'].str.lower() == \"2\".lower(), 'GRF_PLACEM'] = \"0\"\n",
    "    imputation.loc[imputation['GRF_PLACEM'].str.lower() == \"3\".lower(), 'GRF_PLACEM'] = \"0\"\n",
    "    imputation.loc[imputation['GRF_PLACEM'].str.lower() == \".\".lower(), 'GRF_PLACEM'] = \"0\"\n",
    "    # Rename column 'GRF_PLACEM' to 'GRF_PLACEM_intra'\n",
    "    imputation = imputation.rename(columns={'GRF_PLACEM': 'GRF_PLACEM_intra'})\n",
    "    # Change column type to string for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'PA_PRESERV_TM'\n",
    "    imputation.loc[imputation['PA_PRESERV_TM'].str.lower() == \".\".lower(), 'PA_PRESERV_TM'] = np.nan\n",
    "    # Change column type to float32 for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.fillna({'PA_PRESERV_TM': imputation['PA_PRESERV_TM'].median()})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'VASC_MGMT'\n",
    "    imputation['VASC_MGMT'] = imputation['VASC_MGMT'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # One-hot encode column: 'VASC_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('VASC_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['VASC_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Rename column 'VASC_MGMT_1' to 'VASC_MGMT_systemic'\n",
    "    imputation = imputation.rename(columns={'VASC_MGMT_1': 'VASC_MGMT_systemic'})\n",
    "    # Rename column 'VASC_MGMT_2' to 'VASC_MGMT_portal'\n",
    "    imputation = imputation.rename(columns={'VASC_MGMT_2': 'VASC_MGMT_portal'})\n",
    "    # Rename column 'VASC_MGMT_3' to 'VASC_MGMT_na/multiOrg'\n",
    "    imputation = imputation.rename(columns={'VASC_MGMT_3': 'VASC_MGMT_na/multiOrg'})\n",
    "    # Replace missing values with \"N\" in column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.fillna({'VEN_EXT_GRF': \"N\"})\n",
    "    # Change column type to string for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation.loc[imputation['DAYSWAIT_CHRON_PA'].str.lower() == \".\".lower(), 'DAYSWAIT_CHRON_PA'] = np.nan\n",
    "    # Change column type to float32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.fillna({'DAYSWAIT_CHRON_PA': imputation['DAYSWAIT_CHRON_PA'].median()})\n",
    "    # Replace all instances of \"ND\" with \"N\" in columns: 'HBV_CORE', 'EBV_SEROSTATUS' and 2 other columns\n",
    "    imputation['HBV_CORE'] = imputation['HBV_CORE'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    imputation['EBV_SEROSTATUS'] = imputation['EBV_SEROSTATUS'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    imputation['HCV_SEROSTATUS'] = imputation['HCV_SEROSTATUS'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    imputation['CMV_STATUS'] = imputation['CMV_STATUS'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    # Replace missing values with \"P\" in columns: 'EBV_SEROSTATUS', 'CMV_STATUS'\n",
    "    imputation = imputation.fillna({'EBV_SEROSTATUS': \"P\", 'CMV_STATUS': \"P\"})\n",
    "    # Replace missing values with \"N\" in columns: 'HCV_SEROSTATUS', 'HBV_CORE'\n",
    "    imputation = imputation.fillna({'HCV_SEROSTATUS': \"N\", 'HBV_CORE': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'MALIG'\n",
    "    imputation = imputation.fillna({'MALIG': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'PROTEIN_URINE'\n",
    "    imputation = imputation.fillna({'PROTEIN_URINE': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'CARDARREST_NEURO'\n",
    "    imputation = imputation.fillna({'CARDARREST_NEURO': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'INOTROP_SUPPORT_DON'\n",
    "    imputation = imputation.fillna({'INOTROP_SUPPORT_DON': \"N\"})\n",
    "    # Replace missing values with \"N\" in column: 'MULTIORG'\n",
    "    imputation = imputation.fillna({'MULTIORG': \"N\"})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation.loc[imputation['LIPASE'].str.lower() == \".\".lower(), 'LIPASE'] = np.nan\n",
    "    imputation.loc[imputation['AMYLASE'].str.lower() == \".\".lower(), 'AMYLASE'] = np.nan\n",
    "    # Change column type to float32 for columns: 'LIPASE', 'AMYLASE'\n",
    "    imputation = imputation.astype({'LIPASE': 'float32', 'AMYLASE': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'LIPASE', 'AMYLASE'\n",
    "    imputation = imputation.fillna({'LIPASE': imputation['LIPASE'].median(), 'AMYLASE': imputation['AMYLASE'].median()})\n",
    "    # Change column type to string for column: 'DIAB'\n",
    "    imputation = imputation.astype({'DIAB': 'string'})\n",
    "    # Replace all instances of \"1\" with \"0\" in column: 'DIAB'\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"1\".lower(), 'DIAB'] = \"0\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"998\".lower(), 'DIAB'] = \"0\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \".\".lower(), 'DIAB'] = \"0\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"2\".lower(), 'DIAB'] = \"1\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"3\".lower(), 'DIAB'] = \"1\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"4\".lower(), 'DIAB'] = \"1\"\n",
    "    imputation.loc[imputation['DIAB'].str.lower() == \"5\".lower(), 'DIAB'] = \"1\"\n",
    "    # Rename column 'DIAB' to 'DIAB_Y/N'\n",
    "    imputation = imputation.rename(columns={'DIAB': 'DIAB_Y/N'})\n",
    "\n",
    "\n",
    "    imputation = imputation.rename(columns={'GRF_STAT_PA': 'GRF_STAT_PA_didFail'})  \n",
    "\n",
    "    imputation['GRF_STAT_PA_didFail'] = imputation['GRF_STAT_PA_didFail'].str.replace(\"Y\", \"0\", case=False, regex=False)\n",
    "    imputation['GRF_STAT_PA_didFail'] = imputation['GRF_STAT_PA_didFail'].str.replace(\"N\", \"1\", case=False, regex=False)\n",
    "\n",
    "    return imputation\n",
    "\n",
    "imputation_clean = clean_data(imputation.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_1452\\430475599.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  imputation_clean = imputation_clean.replace(to_replace=\"Y\", value=1)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_1452\\430475599.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  imputation_clean = imputation_clean.replace(to_replace=\"P\", value=1)\n"
     ]
    }
   ],
   "source": [
    "imputation_clean = imputation_clean.replace(to_replace=\"N\", value=0)\n",
    "imputation_clean = imputation_clean.replace(to_replace=\"Y\", value=1)\n",
    "imputation_clean = imputation_clean.replace(to_replace=\"P\", value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[imputation_clean.select_dtypes(include=['int']).columns] = imputation_clean.select_dtypes(include=['int']).astype(\"float32\")\n",
    "\n",
    "imputation_clean[imputation_clean.select_dtypes(include=['string']).columns] = imputation_clean.select_dtypes(include=['string']).astype(\"float32\")\n",
    "\n",
    "imputation_clean[imputation_clean.select_dtypes(include=['object']).columns] = imputation_clean.select_dtypes(include=['object']).astype(\"float32\")\n",
    "\n",
    "imputation_clean[imputation_clean.select_dtypes(include=['bool']).columns] = imputation_clean.select_dtypes(include=['bool']).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[\"YRS_DIAB\"] = (imputation_clean[\"AGE\"] - imputation_clean[\"AGE_DIAB\"]) * imputation_clean[\"DIAB_Y/N\"]\n",
    "\n",
    "imputation_clean[\"YRS_DIAB\"] = imputation_clean[\"YRS_DIAB\"].clip(lower=0)\n",
    "\n",
    "imputation_clean = imputation_clean.drop(\"AGE_DIAB\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = [\"BUN_DON\", \"CREAT_DON\", \"SGOT_DON\", \"SGPT_DON\", \"TBILI_DON\", \"LIPASE\", \"AMYLASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean_winsor = imputation_clean.copy()\n",
    "\n",
    "# Define the lower and upper percentiles\n",
    "lower_percentile = 0.00\n",
    "upper_percentile = 0.95\n",
    "\n",
    "# Apply percentile-based capping\n",
    "imputation_clean_winsor[skewed_cols] = imputation_clean_winsor[skewed_cols].clip(lower=imputation_clean_winsor[skewed_cols].quantile(lower_percentile), upper=imputation_clean_winsor[skewed_cols].quantile(upper_percentile), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean = imputation_clean_winsor.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"CREAT_TRR\", \"AMIS\", \"BMIS\", \"DRMIS\", \"HLAMIS\", \"NPKID\", \"NPPAN\", \"AGE_DON\", \"BUN_DON\", \n",
    "    \"CREAT_DON\", \"SGOT_DON\", \"SGPT_DON\", \"TBILI_DON\", \"BMI_DON_CALC\", \"AGE\", \"PA_PRESERV_TM\", \n",
    "    \"DAYSWAIT_CHRON_PA\", \"BMI_CALC\", \"LIPASE\", \"AMYLASE\", \"YRS_DIAB\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_df = imputation_clean.copy()\n",
    "\n",
    "scaled_df[numeric_cols] = scaler.fit_transform(scaled_df[numeric_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.to_csv(\"data_ready_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
