{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_16164\\381285905.py:1: DtypeWarning: Columns (3,6,9,18,19,20,21,22,23,24,28,29,30,31,32,34,35,36,37,38,39,45,46,47,48,49,52,53,54,55,66,67,70,72,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,103,104,106,112,115,116,117,120,122,123,132,134,135,136,138,140,141,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,173,175,176,177,178,179,180,181,182,183,184,188,189,190,191,193,199,200,202,203,204,207,208,209,210,211,212,213,214,216,217,222,223,224,225,226,227,228,234,236,237,242,243,248,253,255,260,261,262,263,264,266,267,268,269,270,271,277,280,281,283,285,287,289,290,294,295,296,297,299,300,301,302,303,306,308,317,321,328,330,332,347,352,357,358,365,366,367,368,372,379,382,386,387,388,393,410,411,412,413,414,421,422,429,430,431,432,433,434,435,436,438,442,455,456,457,458,459,468,469,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PAN_data = pd.read_csv(\"PAN_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "PAN_data = pd.read_csv(\"PAN_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\"WL_ORG\", \"COD_WL\", \"DONATION\", \"A2A2B_ELIGIBILITY\", \"ANTIBODY_TESTED\", \"ETHNICITY\", \"CITIZENSHIP\", \n",
    "             \"CITIZEN_COUNTRY\", \"PERM_STATE\", \"INIT_CURRENT_PRA\", \"INIT_PEAK_PRA\", \"INIT_STAT\", \"INIT_EPTS\", \n",
    "             \"END_EPTS\", \"ACTIVATE_DATE\", \"CREAT_CLEAR_DATE\", \"DEATH_DATE\", \"INIT_DATE\", \"WT_QUAL_DATE\", \"PT_CODE\", \n",
    "             \"DAYSWAIT_ALLOC\", \"WLHR\", \"WLHL\", \"WLIN\", \"WLKI\", \"WLKP\", \"WLLI\", \"WLLU\", \"WLPA\", \"WLPI\", \"WLVC\", \"REGION\", \n",
    "             \"INACT_REASON_CD\", \"WL_ID_CODE\", \"YR_ENTRY_US_TCR\", \"WORK_INCOME_TCR\", \"PRI_PAYMENT_TCR_KI\", \n",
    "             \"PRI_PAYMENT_TCR_PA\", \"PERM_STATE_TRR\", \"PRI_PAYMENT_TRR_KI\", \"PRI_PAYMENT_CTRY_TRR_KI\", \"FIRST_WK_DIAL\", \n",
    "             \"SERUM_CREAT\", \"RESUM_MAINT_DIAL_DT\", \"CMV_OLD_LIV_DON\", \"CMV_TEST_DON\", \"EBV_TEST_DON\", \"HBV_TEST_DON\", \n",
    "             \"HCV_TEST_DON\", \"CITIZENSHIP_DON\", \"HOME_STATE_DON\", \"CITIZEN_COUNTRY_DON\", \"RETXDATE_KI\", \"FAILDATE_KI\", \n",
    "             \"RESUM_MAINT_DIAL\", \"GRF_FAIL_CAUSE_TY_KI\", \"DWFG_KI\", \"PRVTXDIF_KI\", \"GTIME_KI\", \"GSTATUS_KI\", \"COD_KI\", \n",
    "             \"COD2_KI\", \"COD3_KI\", \"DAYSWAIT_CHRON_KI\", \"TX_PROCEDUR_TY_KI\", \"TRTREJ1Y_KI\", \"TRTREJ6M_KI\", \n",
    "             \"PRI_PAYMENT_CTRY_TRR_PA\", \"ACUTE_REJ_EPI_PA\", \"INSULIN_RESUMED_DATE_PA\", \"BLOOD_SUGAR_MED_RESUMED_DATE_PA\", \n",
    "             \"PRI_PAYMENT_CTRY_TCR_PA\", \"ENTERIC_DRAIN\", \"ENTERIC_DRAIN_DT\", \"RETXDATE_PA\", \n",
    "             \"PRVTXDIF_PA\", \"COD_PA\", \"COD2_PA\", \"COD3_PA\", \"TRTREJ1Y_PA\", \"TRTREJ6M_PA\", \n",
    "             \"PREV_KI_DATE\", \"FUNC_STAT_TRF\", \"SHARE_TY\", \"PSTATUS\", \"PTIME\", \"LOS\", \"PAYBACK\", \"ECD_DONOR\", \"STATUS_TCR\", \n",
    "             \"STATUS_TRR\", \"STATUS_DDR\", \"VAL_DT_DDR\", \"STATUS_LDR\", \"VAL_DT_LDR\", \"VAL_DT_TCR\", \"VAL_DT_TRR\", \n",
    "             \"RIGHTKIDNEYCHECKINDATE\", \"RIGHTKIDNEYCHECKINTIME\", \"RIGHTKIDNEYCHECKINTIMEZONEID\", \n",
    "             \"LEFTKIDNEYCHECKINDATE\", \"LEFTKIDNEYCHECKINTIME\", \"LEFTKIDNEYCHECKINTIMEZONEID\", \"ENBLOCKIDNEYCHECKINDATE\", \n",
    "             \"ENBLOCKIDNEYCHECKINTIME\", \"ENBLOCKIDNEYCHECKINTIMEZONEID\", \"PANCREASCHECKINDATE\", \"PANCREASCHECKINTIME\", \n",
    "             \"PANCREASCHECKINTIMEZONEID\", \"LT_ONE_WEEK_DON\", \"REJ_BIOPSY\", \"REJCNF_KI\", \"REJTRT_KI\", \"REJCNF_PA\", \n",
    "             \"REJTRT_PA\", \"DISCHARGE_DATE\", \"COMPL_ABSC\", \"COMPL_ANASLK\", \"COMPL_PANCREA\", \"SURG_INCIS\", \n",
    "             \"HASHBVVACCINATION\", \"REASONNOHBVVACCINATIONID\", \"EDUCATION_DON\", \"PRI_PAYMENT_DON\", \"PRI_PAYMENT_CTRY_DON\", \n",
    "             \"MEDICARE_DON\", \"MEDICAID_DON\", \"OTH_GOVT_DON\", \"PRIV_INS_DON\", \"HMO_PPO_DON\", \"SELF_DON\", \"DONATION_DON\", \n",
    "             \"FREE_DON\", \"RECOV_OUT_US\", \"RECOV_COUNTRY\", \"REFERRAL_DATE\", \"RECOVERY_DATE\", \"ADMIT_DATE_DON\", \n",
    "             \"TRANSPLANT_TIME\", \"TRANSPLANTTIMEZONEID\", \"DATA_TRANSPLANT\", \"DATA_WAITLIST\", \"CTR_CODE\", \"OPO_CTR_CODE\", \n",
    "             \"INIT_OPO_CTR_CODE\", \"END_OPO_CTR_CODE\", \"LISTING_CTR_CODE\", \"MAX_KDPI_LOCAL_ZERO_ABDR\", \n",
    "             \"MAX_KDPI_LOCAL_NON_ZERO_ABDR\", \"MAX_KDPI_IMPORT_ZERO_ABDR\", \"MAX_KDPI_IMPORT_NON_ZERO_ABDR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = PAN_data.drop(columns=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reason of removal to numeric and only include those that underwent transplantation [2,3,4,14,15,18,19]\n",
    "clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
    "clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = clean_good[clean_good[\"REM_CD\"].isin([2,3,4,14,15,18,19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra removals\n",
    "to_remove_extra = [\"CURRENT_PRA\", \"PEAK_PRA\", \"USE_WHICH_PRA\", \"CREAT_CLEAR\", \"GFR\", \"C_PEPTIDE\", \"C_PEPTIDEDATE\", \n",
    "                   \"WGT_KG_TCR\", \"HGT_CM_TCR\", \"BMI_TCR\", \"TOT_SERUM_ALBUM\", \"C_PEPTIDE_PA_TCR\", \"HBA1C_PA_TCR\", \n",
    "                   \"INIT_WGT_KG\", \"INIT_HGT_CM\", \"INIT_CPRA\", \"END_CPRA\", \"END_STAT\", \"INIT_AGE\", \"DIALYSIS_DATE\", \n",
    "                   \"GFR_DATE\", \"INIT_BMI_CALC\", \"A1\", \"A2\", \"B1\", \"B2\", \"DR1\", \"DR2\", \"EDUCATION\", \"FUNC_STAT_TCR\", \n",
    "                   \"BW4\", \"BW6\", \"C1\", \"C2\", \"DR51\", \"DR51_2\", \"DR52\", \"DR52_2\", \"DR53\", \"DR53_2\", \"DQ1\", \"DQ2\", \n",
    "                   \"ACADEMIC_PRG_TCR\", \"ACADEMIC_LEVEL_TCR\", \"PREV_TX\", \"PREV_KI_TX\", \"PREV_PA_TX\", \"ACUTE_REJ_EPI_KI\", \n",
    "                   \"ORG_REC_ON\", \"L_FIN_FLOW_RATE_TX\", \"L_FIN_RESIST_TX\", \"R_FIN_FLOW_RATE_TX\", \"R_FIN_RESIST_TX\", \n",
    "                   \"FIN_RESIST_TX\", \"TXHRT\", \"TXINT\", \"TXKID\", \"TXLIV\", \"TXLNG\", \"TXPAN\", \"TXVCA\", \"RDA1\", \"RDA2\", \n",
    "                   \"RDB1\", \"RDB2\", \"RDDR1\", \"RDDR2\", \"DON_RETYP\", \"DA1\", \"DA2\", \"DB1\", \"DB2\", \"DDR1\", \"DDR2\", \"RA1\", \n",
    "                   \"RA2\", \"RB1\", \"RB2\", \"RDR1\", \"RDR2\", \"END_CPRA_DETAIL\", \"HAPLO_TY_MATCH_DON\", \"CMV_NUCLEIC_DON\", \n",
    "                   \"CMV_IGG_DON\", \"CMV_IGM_DON\", \"EBV_DNA_DON\", \"EBV_IGG_DON\", \"EBV_IGM_DON\", \n",
    "                   \"HCV_RNA_DON\", \"WARM_ISCH_TM_DON\", \"HCV_RIBA_DON\", \"HCV_ANTIBODY_DON\", \"CONTROLLED_DON\", \n",
    "                   \"CORE_COOL_DON\", \"HTLV1_OLD_DON\", \"HTLV2_OLD_DON\", \"DOBUT_DON_OLD\", \"DOPAMINE_DON_OLD\", \n",
    "                   \"PRETREAT_MED_DON_OLD\", \"CONTIN_ALCOHOL_OLD_DON\", \"CONTIN_OTH_DRUG_DON\", \"HIST_ALCOHOL_OLD_DON\", \n",
    "                   \"DIABDUR_DON\", \"HIST_IV_DRUG_OLD_DON\", \"INSULIN_DEP_DON\", \"OTHER_HYPERTENS_MED_DON\", \n",
    "                   \"HIST_INSULIN_DEP_DON\", \"INSULIN_DUR_DON\", \"HBV_NAT_DON\", \"HCV_NAT_DON\", \"HIV_NAT_DON\", \n",
    "                   \"CREAT6M\", \"CREAT1Y\", \"DIAL_DATE\", \"PRI_PAYMENT_TRR_PA\", \"PRE_AVG_INSULIN_USED_TRR\", \n",
    "                   \"PRE_AVG_INSULIN_USED_OLD_TRR\", \"INSULIN_PA\", \"INSULIN_DOSAGE_PA\", \"INSULIN_DURATION_PA\", \n",
    "                   \"METHOD_BLOOD_SUGAR_CONTROL_PA\", \"BLOOD_SUGAR_MEDICATION_PA\", \"BLOOD_SUGAR_DIET_PA\",\n",
    "                   \"C_PEPTIDE_PA_TRR\", \"HBA1C_PA_TRR\", \"INSULIN_DOSAGE_OLD_PA\", \"PK_DA1\", \"PK_DA2\", \"PK_DB1\", \n",
    "                   \"PK_DB2\", \"PK_DDR1\", \"PK_DDR2\", \"GRF_VASC_THROMB_PA\", \"INFECT_PA\", \"BLEED_PA\", \"ANAST_LK_PA\", \n",
    "                   \"REJ_ACUTE_PA\", \"REJ_HYPER_PA\", \"BIOP_ISLET_PA\", \"PANCREATIT_PA\", \"REJ_CHRONIC_PA\", \n",
    "                   \"PX_NON_COMPL_PA\", \"HBV_SURF_TOTAL\", \"HIV_NAT\", \"HCV_NAT\", \"HBV_NAT\", \"PREV_TX_ANY\", \"PREV_TX_ANY_N\", \n",
    "                   \"KI_CREAT_PREOP\", \"KI_PROC_TY\", \"TATTOOS\", \"LT_KI_GLOMERUL\", \"LT_KI_BIOPSY\", \"RT_KI_BIOPSY\", \n",
    "                   \"RT_KI_GLOMERUL\", \"HBV_DNA_DON\", \"CDC_RISK_HIV_DON\", \"INO_PROCURE_AGENT_1\", \"INO_PROCURE_AGENT_2\", \n",
    "                   \"INO_PROCURE_AGENT_3\", \"ACADEMIC_LEVEL_TRR\", \"ACADEMIC_PRG_TRR\", \"WORK_INCOME_TRR\", \n",
    "                   \"PRI_PAYMENT_CTRY_TCR_KI\", \"DONOR_ID\", \"ORGAN\", \"TX_PROCEDUR_TY_PA\", \"DIAG_PA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37139, 321)\n"
     ]
    }
   ],
   "source": [
    "#remove very recent transplants\n",
    "\n",
    "clean_good = clean_good[clean_good[\"PX_STAT_DATE\"] != \".\"]\n",
    "print(clean_good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
    "clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good[\"time_frame\"] = clean_good[\"PX_STAT_DATE\"] - clean_good[\"TX_DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include those with more than 5 years of followup\n",
    "clean_good[\"time_frame\"] = clean_good[\"time_frame\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_good = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.to_datetime(\"04/04/2019\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove transplants with less than 5 years of followup time\n",
    "#clean_good = clean_good[clean_good[\"TX_DATE\"] < cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37139, 322)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = clean_good.drop(columns=to_remove_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = very_clean_data[very_clean_data[\"AGE_GROUP\"] == \"A\"]\n",
    "\n",
    "very_clean_data = very_clean_data[very_clean_data[\"DON_TY\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_extra_to_remove = [\"NUM_PREV_TX\", \"DRUGTRT_COPD\", \"REM_CD\", \"END_BMI_CALC\", \"MALIG_TCR_KI\", \"MALIG_TCR_PA\", \n",
    "                         \"PREV_MALIG_TY\", \"LIV_DON_TY\", \"EXTRACRANIAL_CANCER_DON\", \n",
    "                         \"INTRACRANIAL_CANCER_DON\", \"SKIN_CANCER_DON\", \"HIST_DIABETES_DON\", \n",
    "                         \"ON_DIALYSIS\", \"END_STAT_PA\", \"ADMISSION_DATE\", \"END_STAT_KI\", \"END_DATE\", \"DIABETES_DON\", \n",
    "                         \"DGN2_TCR\", \"EXH_PERIT_ACCESS\", \"EXH_VASC_ACCESS\", \"REC_ON_ICE\", \"REC_ON_PUMP\", \"PRE_TX_TXFUS\", \n",
    "                         \"DON_TY\", \"CONTIN_CIG_DON\", \"CONTIN_IV_DRUG_OLD_DON\", \"CONTIN_COCAINE_DON\", \"DIET_DON\", \n",
    "                         \"DIURETICS_DON\", \"KDPI\", \"KDRI_MED\", \"KDRI_RAO\", \"PUMP_KI\", \"DIAG_KI\", \"COLD_ISCH_KI\", \n",
    "                         \"GRF_STAT_KI\", \"GSTATUS_PA\", \"INOTROP_AGENTS\", \"HBSAB_DON\", \"EBV_IGG_CAD_DON\", \n",
    "                         \"EBV_IGM_CAD_DON\", \"DAYSWAIT_CHRON\", \"FUNC_STAT_TRR\", \"MALIG_TRR\" ,\"MALIG_TY_TRR\", \n",
    "                         \"PREV_PREG\", \"HBV_CORE_DON\", \"HEP_C_ANTI_DON\", \"BLOOD_INF_DON\", \"OTHER_INF_DON\", \"PULM_INF_DON\", \n",
    "                         \"URINE_INF_DON\", \"VDRL_DON\", \"HYPERTENS_DUR_DON\", \"CANCER_FREE_INT_DON\", \"ARGININE_DON\", \n",
    "                         \"INSULIN_DON\", \"DISTANCE\", \"GRF_FAIL_CAUSE_TY_PA\", \"AGE_GROUP\", \"HIV_SEROSTATUS\", \"OPER_TECH\", \n",
    "                         \"LIPASE\", \"AMYLASE\", \"HBV_SUR_ANTIGEN_DON\", \"CANCER_SITE_DON\", \"MALIG_TY\", \"DGN_TCR\"]\n",
    "\n",
    "#fix me: i removed DIAB from teh removed columns to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = very_clean_data.drop(columns=final_extra_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many variables were first collected in 1994 and the transplants done prior to this account for most of the missing data\n",
    "# in this dataset\n",
    "after_94 = pd.to_datetime(\"04/01/1994\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"TX_DATE\"] > after_94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"HLAMIS\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33004, 88)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pre_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp[\"5YR_SURV\"] = pd.Series(dtype=\"int\")\n",
    "data_pre_imp[\"index\"] = range(33004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23436, 90)\n",
      "(23431, 90)\n"
     ]
    }
   ],
   "source": [
    "#grafts that survived five years\n",
    "surv = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"Y\"]\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"FAILDATE_PA\"] == \".\"]\n",
    "print(surv.shape)\n",
    "surv[\"time_frame\"] = surv[\"PX_STAT_DATE\"] - surv[\"TX_DATE\"]\n",
    "surv[\"time_frame\"] = surv[\"time_frame\"].dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 90)\n",
      "(9559, 90)\n",
      "(9559, 90)\n",
      "(9559, 91)\n",
      "(9559, 91)\n",
      "(9534, 90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fail = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"N\"]\n",
    "print(fail.shape)\n",
    "#drop data wihtout fail date\n",
    "fail = fail[fail[\"FAILDATE_PA\"] != \".\"]\n",
    "print(fail.shape)\n",
    "fail[\"FAILDATE_PA\"] = pd.to_datetime(fail[\"FAILDATE_PA\"], dayfirst=False)\n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"FAILDATE_PA\"] - fail[\"TX_DATE\"] \n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"fail_frame\"].dt.days\n",
    "print(fail.shape)\n",
    "fail[\"time_frame\"] = fail[\"fail_frame\"]\n",
    "fail = fail[fail[\"time_frame\"] >= 0] \n",
    "fail = fail.drop(columns=[\"fail_frame\"], axis=1)\n",
    "print(fail.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [surv, fail]\n",
    "labelled_pre_imp = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_pre_imp = labelled_pre_imp.sort_values(['index'])\n",
    "no_longer_needed = [\"index\", \"PX_STAT_DATE\", \"PX_STAT\", \"GTIME_PA\", \"5YR_SURV\",\"FAILDATE_PA\", \n",
    "                    \"TX_DATE\", \"COMPOSITE_DEATH_DATE\"]\n",
    "labelled_pre_imp = labelled_pre_imp.drop(columns=no_longer_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 86 donors with unkown height or weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_DON_CALC\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(labelled_pre_imp):\n",
    "    # Change column type to string for column: 'DIAB'\n",
    "    labelled_pre_imp = labelled_pre_imp.astype({'DIAB': 'string'})\n",
    "    # Replace all instances of \".\" with \"998\" in column: 'DIAB'\n",
    "    labelled_pre_imp['DIAB'] = labelled_pre_imp['DIAB'].str.replace(\".\", \"998\", case=False, regex=False)\n",
    "    return labelled_pre_imp\n",
    "\n",
    "labelled_pre_imp = clean_data(labelled_pre_imp.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = labelled_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(imputation):\n",
    "    # One-hot encode column: 'GENDER'\n",
    "    insert_loc = imputation.columns.get_loc('GENDER')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GENDER']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'ABO'\n",
    "    insert_loc = imputation.columns.get_loc('ABO')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ABO']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PERIP_VASC'\n",
    "    imputation = imputation.fillna({'PERIP_VASC': \"U\"})\n",
    "    # One-hot encode column: 'PERIP_VASC'\n",
    "    insert_loc = imputation.columns.get_loc('PERIP_VASC')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PERIP_VASC']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to int32 for column: 'AMIS'\n",
    "    imputation = imputation.astype({'AMIS': 'int32'})\n",
    "    # Change column type to int32 for columns: 'BMIS', 'DRMIS', 'HLAMIS'\n",
    "    imputation = imputation.astype({'BMIS': 'int32', 'DRMIS': 'int32', 'HLAMIS': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE_DON'\n",
    "    imputation = imputation.astype({'AGE_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DDAVP_DON'\n",
    "    imputation = imputation.fillna({'DDAVP_DON': \"U\"})\n",
    "    # One-hot encode column: 'DDAVP_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DDAVP_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DDAVP_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'CMV_DON'\n",
    "    imputation = imputation.fillna({'CMV_DON': \"N\"})\n",
    "    # Replace all instances of \"ND\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"I\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"I\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"C\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"C\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"P\" with \"1\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to string for column: 'COD_CAD_DON'\n",
    "    imputation = imputation.astype({'COD_CAD_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'COD_CAD_DON'\n",
    "    imputation['COD_CAD_DON'] = imputation['COD_CAD_DON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'COD_CAD_DON'\n",
    "    insert_loc = imputation.columns.get_loc('COD_CAD_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['COD_CAD_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DEATH_CIRCUM_DON'\n",
    "    imputation = imputation.astype({'DEATH_CIRCUM_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"997\" in column: 'DEATH_CIRCUM_DON'\n",
    "    imputation['DEATH_CIRCUM_DON'] = imputation['DEATH_CIRCUM_DON'].str.replace(\".\", \"997\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DEATH_CIRCUM_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DEATH_CIRCUM_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DEATH_CIRCUM_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DEATH_MECH_DON'\n",
    "    imputation = imputation.astype({'DEATH_MECH_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"997\" in column: 'DEATH_MECH_DON'\n",
    "    imputation['DEATH_MECH_DON'] = imputation['DEATH_MECH_DON'].str.replace(\".\", \"997\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DEATH_MECH_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DEATH_MECH_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DEATH_MECH_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'ABO_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ABO_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ABO_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'GENDER_DON'\n",
    "    insert_loc = imputation.columns.get_loc('GENDER_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GENDER_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'NON_HRT_DON'\n",
    "    imputation = imputation.fillna({'NON_HRT_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'ANTIHYPE_DON'\n",
    "    imputation = imputation.fillna({'ANTIHYPE_DON': \"U\"})\n",
    "    # One-hot encode column: 'ANTIHYPE_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ANTIHYPE_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ANTIHYPE_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation['BLOOD_INF_CONF_DON'] = imputation['BLOOD_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'BLOOD_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation['BLOOD_INF_CONF_DON'] = imputation['BLOOD_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'BLOOD_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'BLOOD_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to string for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'BUN_DON'\n",
    "    imputation.loc[imputation['BUN_DON'].str.lower() == \".\".lower(), 'BUN_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'BUN_DON'\n",
    "    imputation = imputation.fillna({'BUN_DON': imputation['BUN_DON'].median()})\n",
    "    # Change column type to string for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_DON'\n",
    "    imputation.loc[imputation['CREAT_DON'].str.lower() == \".\".lower(), 'CREAT_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_DON'\n",
    "    imputation = imputation.fillna({'CREAT_DON': imputation['CREAT_DON'].median()})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation['OTHER_INF_CONF_DON'] = imputation['OTHER_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'OTHER_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation['OTHER_INF_CONF_DON'] = imputation['OTHER_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'OTHER_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'OTHER_INF_CONF_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'PT_DIURETICS_DON'\n",
    "    imputation = imputation.fillna({'PT_DIURETICS_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_DIURETICS_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_DIURETICS_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_DIURETICS_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_STEROIDS_DON'\n",
    "    imputation = imputation.fillna({'PT_STEROIDS_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_STEROIDS_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_STEROIDS_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_STEROIDS_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_T3_DON'\n",
    "    imputation = imputation.fillna({'PT_T3_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_T3_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_T3_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_T3_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_T4_DON'\n",
    "    imputation = imputation.fillna({'PT_T4_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_T4_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_T4_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_T4_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"0\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'PULM_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation['PULM_INF_CONF_DON'] = imputation['PULM_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation['PULM_INF_CONF_DON'] = imputation['PULM_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'PULM_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'PULM_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to string for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'string', 'SGPT_DON': 'string', 'TBILI_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation.loc[imputation['SGOT_DON'].str.lower() == \".\".lower(), 'SGOT_DON'] = np.nan\n",
    "    imputation.loc[imputation['SGPT_DON'].str.lower() == \".\".lower(), 'SGPT_DON'] = np.nan\n",
    "    imputation.loc[imputation['TBILI_DON'].str.lower() == \".\".lower(), 'TBILI_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'float32', 'SGPT_DON': 'float32', 'TBILI_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.fillna({'SGOT_DON': imputation['SGOT_DON'].median(), 'SGPT_DON': imputation['SGPT_DON'].median(), 'TBILI_DON': imputation['TBILI_DON'].median()})\n",
    "    # Replace missing values with \"0\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'URINE_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation['URINE_INF_CONF_DON'] = imputation['URINE_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation['URINE_INF_CONF_DON'] = imputation['URINE_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'URINE_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'URINE_INF_CONF_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'VASODIL_DON'\n",
    "    imputation = imputation.fillna({'VASODIL_DON': \"U\"})\n",
    "    # One-hot encode column: 'VASODIL_DON'\n",
    "    insert_loc = imputation.columns.get_loc('VASODIL_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['VASODIL_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CLIN_INFECT_DON'\n",
    "    imputation = imputation.fillna({'CLIN_INFECT_DON': \"U\"})\n",
    "    # One-hot encode column: 'CLIN_INFECT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('CLIN_INFECT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CLIN_INFECT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "\n",
    "    # Replace missing values with \"U\" in column: 'HIST_CIG_DON'\n",
    "    imputation = imputation.fillna({'HIST_CIG_DON': \"U\"})\n",
    "    # One-hot encode column: 'HIST_CIG_DON'\n",
    "    insert_loc = imputation.columns.get_loc('HIST_CIG_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['HIST_CIG_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    imputation = imputation.fillna({'HIST_COCAINE_DON': \"U\", 'HIST_HYPERTENS_DON': \"U\", 'HIST_OTH_DRUG_DON': \"U\"})\n",
    "    # One-hot encode columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    for column in ['HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON']:\n",
    "        insert_loc = imputation.columns.get_loc(column)\n",
    "        imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, [column]]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'HEPARIN_DON'\n",
    "    imputation = imputation.fillna({'HEPARIN_DON': \"U\"})\n",
    "    # One-hot encode column: 'HEPARIN_DON'\n",
    "    insert_loc = imputation.columns.get_loc('HEPARIN_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['HEPARIN_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to int32 for column: 'ABO_MAT'\n",
    "    imputation = imputation.astype({'ABO_MAT': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE'\n",
    "    imputation = imputation.astype({'AGE': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DIAL_TRR'\n",
    "    imputation = imputation.fillna({'DIAL_TRR': \"U\"})\n",
    "    # One-hot encode column: 'DIAL_TRR'\n",
    "    insert_loc = imputation.columns.get_loc('DIAL_TRR')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DIAL_TRR']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"0\" in column: 'MULTIORG'\n",
    "    imputation = imputation.fillna({'MULTIORG': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'MULTIORG'\n",
    "    imputation['MULTIORG'] = imputation['MULTIORG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'MULTIORG'\n",
    "    imputation = imputation.astype({'MULTIORG': 'int32'})\n",
    "    # Change column type to string for column: 'ART_RECON'\n",
    "    imputation = imputation.astype({'ART_RECON': 'string'})\n",
    "    # Replace all instances of \".\" with \"2\" in column: 'ART_RECON'\n",
    "    imputation['ART_RECON'] = imputation['ART_RECON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'ART_RECON'\n",
    "    insert_loc = imputation.columns.get_loc('ART_RECON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ART_RECON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DUCT_MGMT'\n",
    "    imputation = imputation.astype({'DUCT_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation['DUCT_MGMT'] = imputation['DUCT_MGMT'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DUCT_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('DUCT_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DUCT_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'GRF_PLACEM'\n",
    "    imputation = imputation.astype({'GRF_PLACEM': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'GRF_PLACEM'\n",
    "    imputation['GRF_PLACEM'] = imputation['GRF_PLACEM'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # One-hot encode column: 'GRF_PLACEM'\n",
    "    insert_loc = imputation.columns.get_loc('GRF_PLACEM')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GRF_PLACEM']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'PA_PRESERV_TM'\n",
    "    imputation.loc[imputation['PA_PRESERV_TM'].str.lower() == \".\".lower(), 'PA_PRESERV_TM'] = np.nan\n",
    "    # Change column type to float32 for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.fillna({'PA_PRESERV_TM': imputation['PA_PRESERV_TM'].median()})\n",
    "\n",
    "    # Change column type to string for column: 'VASC_MGMT'\n",
    "    imputation = imputation.astype({'VASC_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'VASC_MGMT'\n",
    "    imputation['VASC_MGMT'] = imputation['VASC_MGMT'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # One-hot encode column: 'VASC_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('VASC_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['VASC_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.fillna({'VEN_EXT_GRF': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.astype({'VEN_EXT_GRF': 'int32'})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Change column type to string for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation.loc[imputation['DAYSWAIT_CHRON_PA'].str.lower() == \".\".lower(), 'DAYSWAIT_CHRON_PA'] = np.nan\n",
    "    # Change column type to float32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.fillna({'DAYSWAIT_CHRON_PA': imputation['DAYSWAIT_CHRON_PA'].median()})\n",
    "    # Change column type to int32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'int32'})\n",
    "    # One-hot encode column: 'ORGAN'\n",
    "    insert_loc = imputation.columns.get_loc('ORGAN')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ORGAN']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CMV_IGG'\n",
    "    imputation = imputation.fillna({'CMV_IGG': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in column: 'CMV_IGG'\n",
    "    imputation['CMV_IGG'] = imputation['CMV_IGG'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # One-hot encode column: 'CMV_IGG'\n",
    "    insert_loc = imputation.columns.get_loc('CMV_IGG')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CMV_IGG']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in columns: 'CMV_IGM', 'HBV_CORE' and 2 other columns\n",
    "    imputation = imputation.fillna({'CMV_IGM': \"U\", 'HBV_CORE': \"U\", 'HCV_SEROSTATUS': \"U\", 'CMV_STATUS': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in columns: 'CMV_IGM', 'HBV_CORE' and 2 other columns\n",
    "    imputation['CMV_IGM'] = imputation['CMV_IGM'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HBV_CORE'] = imputation['HBV_CORE'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HCV_SEROSTATUS'] = imputation['HCV_SEROSTATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['CMV_STATUS'] = imputation['CMV_STATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'HBV_SUR_ANTIGEN'\n",
    "    imputation = imputation.fillna({'HBV_SUR_ANTIGEN': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in column: 'HBV_SUR_ANTIGEN'\n",
    "    imputation['HBV_SUR_ANTIGEN'] = imputation['HBV_SUR_ANTIGEN'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation = imputation.fillna({'EBV_SEROSTATUS': \"U\"})\n",
    "    # One-hot encode columns: 'HCV_SEROSTATUS', 'CMV_IGM' and 4 other columns\n",
    "    for column in ['HCV_SEROSTATUS', 'CMV_IGM', 'EBV_SEROSTATUS', 'HBV_CORE', 'HBV_SUR_ANTIGEN', 'CMV_STATUS']:\n",
    "        insert_loc = imputation.columns.get_loc(column)\n",
    "        imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, [column]]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'TX_TYPE'\n",
    "    insert_loc = imputation.columns.get_loc('TX_TYPE')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['TX_TYPE']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'MED_COND_TRR'\n",
    "    imputation = imputation.astype({'MED_COND_TRR': 'string'})\n",
    "    # Replace all instances of \".\" with \"U\" in column: 'MED_COND_TRR'\n",
    "    imputation['MED_COND_TRR'] = imputation['MED_COND_TRR'].str.replace(\".\", \"U\", case=False, regex=False)\n",
    "    # One-hot encode column: 'MED_COND_TRR'\n",
    "    insert_loc = imputation.columns.get_loc('MED_COND_TRR')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['MED_COND_TRR']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'MALIG'\n",
    "    insert_loc = imputation.columns.get_loc('MALIG')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['MALIG']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'string', 'WGT_KG_CALC': 'string', 'BMI_CALC': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'HGT_CM_CALC'\n",
    "    imputation.loc[imputation['HGT_CM_CALC'].str.lower() == \".\".lower(), 'HGT_CM_CALC'] = np.nan\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation.loc[imputation['WGT_KG_CALC'].str.lower() == \".\".lower(), 'WGT_KG_CALC'] = np.nan\n",
    "    imputation.loc[imputation['BMI_CALC'].str.lower() == \".\".lower(), 'BMI_CALC'] = np.nan\n",
    "    # Change column type to float32 for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'float32', 'WGT_KG_CALC': 'float32', 'BMI_CALC': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.fillna({'HGT_CM_CALC': imputation['HGT_CM_CALC'].median(), 'WGT_KG_CALC': imputation['WGT_KG_CALC'].median(), 'BMI_CALC': imputation['BMI_CALC'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PROTEIN_URINE'\n",
    "    imputation = imputation.fillna({'PROTEIN_URINE': \"U\"})\n",
    "    # One-hot encode column: 'PROTEIN_URINE'\n",
    "    insert_loc = imputation.columns.get_loc('PROTEIN_URINE')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PROTEIN_URINE']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CARDARREST_NEURO'\n",
    "    imputation = imputation.fillna({'CARDARREST_NEURO': \"U\"})\n",
    "    # One-hot encode column: 'CARDARREST_NEURO'\n",
    "    insert_loc = imputation.columns.get_loc('CARDARREST_NEURO')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CARDARREST_NEURO']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"0\" in column: 'RESUSCIT_DUR'\n",
    "    imputation.loc[imputation['RESUSCIT_DUR'].str.lower() == \".\".lower(), 'RESUSCIT_DUR'] = \"0\"\n",
    "    # Change column type to float32 for column: 'RESUSCIT_DUR'\n",
    "    imputation = imputation.astype({'RESUSCIT_DUR': 'float32'})\n",
    "    # Change column type to int32 for column: 'RESUSCIT_DUR'\n",
    "    imputation = imputation.astype({'RESUSCIT_DUR': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'INOTROP_SUPPORT_DON'\n",
    "    imputation = imputation.fillna({'INOTROP_SUPPORT_DON': \"U\"})\n",
    "    # One-hot encode column: 'INOTROP_SUPPORT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('INOTROP_SUPPORT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['INOTROP_SUPPORT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "\n",
    "    # Replace missing values with \"N\" in column: 'HIST_CANCER_DON'\n",
    "    imputation = imputation.fillna({'HIST_CANCER_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"0\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'HIST_CANCER_DON'\n",
    "    imputation = imputation.astype({'HIST_CANCER_DON': 'int32'})\n",
    "\n",
    "    # Change column type to int32 for column: 'ETHCAT'\n",
    "    imputation = imputation.astype({'ETHCAT': 'string'})\n",
    "    # One-hot encode column: 'ETHCAT'\n",
    "    insert_loc = imputation.columns.get_loc('ETHCAT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ETHCAT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'AGE_DIAB'\n",
    "    imputation.loc[imputation['AGE_DIAB'].str.lower() == \".\".lower(), 'AGE_DIAB'] = np.nan\n",
    "    # Change column type to float32 for column: 'AGE_DIAB'\n",
    "    imputation = imputation.astype({'AGE_DIAB': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'AGE_DIAB'\n",
    "    imputation = imputation.fillna({'AGE_DIAB': imputation['AGE_DIAB'].median()})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_TRR'\n",
    "    imputation.loc[imputation['CREAT_TRR'].str.lower() == \".\".lower(), 'CREAT_TRR'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_TRR'\n",
    "    imputation = imputation.astype({'CREAT_TRR': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_TRR'\n",
    "    imputation = imputation.fillna({'CREAT_TRR': imputation['CREAT_TRR'].median()})\n",
    "    # Change column type to string for column: 'ETHCAT_DON'\n",
    "    imputation = imputation.astype({'ETHCAT_DON': 'string'})\n",
    "    # One-hot encode column: 'ETHCAT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ETHCAT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ETHCAT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to float32 for columns: 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_DON_CALC': 'float32', 'WGT_KG_DON_CALC': 'float32', 'BMI_DON_CALC': 'float32'})\n",
    "    # Round column 'BMI_DON_CALC' (Number of decimals: 1)\n",
    "    imputation = imputation.round({'BMI_DON_CALC': 1})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"5001\" in column: 'DIAG_PA'\n",
    "    imputation['DIAG_PA'] = imputation['DIAG_PA'].str.replace(\".\", \"5001\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DIAG_PA'\n",
    "    insert_loc = imputation.columns.get_loc('DIAG_PA')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DIAG_PA']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    \n",
    "    \n",
    "    # Replace all instances of \"1\" with \"0\" in column: 'DIAB'\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"1\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"998\" with \"0\" in column: 'DIAB'\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"998\", \"0\", case=False, regex=False)\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"2\", \"1\", case=False, regex=False)\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"3\", \"1\", case=False, regex=False)\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"4\", \"1\", case=False, regex=False)\n",
    "    imputation['DIAB'] = imputation['DIAB'].str.replace(\"5\", \"1\", case=False, regex=False)\n",
    "\n",
    "    imputation = imputation.astype({'DIAB': 'float32'})\n",
    "    \n",
    "    return imputation\n",
    "\n",
    "\n",
    "\n",
    "imputation_clean = clean_data(imputation.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[imputation_clean.select_dtypes(include=['bool']).columns] = imputation_clean.select_dtypes(include=['bool']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_16164\\3681789635.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imputation_clean[\"YRS_DIAB\"] = (imputation_clean[\"AGE\"] - imputation_clean[\"AGE_DIAB\"]) * imputation_clean[\"DIAB\"]\n"
     ]
    }
   ],
   "source": [
    "# for people with diabetes impute with the median age, for people without diabetes use 0\n",
    "# the issue is that a lower number is usually worse in these situations so maybe impute with 999 or feature engineer the\n",
    "# difference between age and age_diab and have it be 0 for people without diabetes as a better method of encoding this variable\n",
    "\n",
    "\n",
    "imputation_clean[\"YRS_DIAB\"] = (imputation_clean[\"AGE\"] - imputation_clean[\"AGE_DIAB\"]) * imputation_clean[\"DIAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean = imputation_clean.drop(columns = [\"TRR_ID_CODE\", \"DIAB\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# imputation_clean = pd.DataFrame(scaler.fit_transform(imputation_clean), columns=imputation_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[imputation_clean.select_dtypes(include=['float64']).columns] = imputation_clean.select_dtypes(include=['float64']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = imputation_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready.to_csv(\"data_ready_wnw.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
