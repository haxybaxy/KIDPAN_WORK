{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_6120\\381285905.py:1: DtypeWarning: Columns (3,6,9,18,19,20,21,22,23,24,28,29,30,31,32,34,35,36,37,38,39,45,46,47,48,49,52,53,54,55,66,67,70,72,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,103,104,106,112,115,116,117,120,122,123,132,134,135,136,138,140,141,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,173,175,176,177,178,179,180,181,182,183,184,188,189,190,191,193,199,200,202,203,204,207,208,209,210,211,212,213,214,216,217,222,223,224,225,226,227,228,234,236,237,242,243,248,253,255,260,261,262,263,264,266,267,268,269,270,271,277,280,281,283,285,287,289,290,294,295,296,297,299,300,301,302,303,306,308,317,321,328,330,332,347,352,357,358,365,366,367,368,372,379,382,386,387,388,393,410,411,412,413,414,421,422,429,430,431,432,433,434,435,436,438,442,455,456,457,458,459,468,469,470,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PAN_data = pd.read_csv(\"PAN_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "PAN_data = pd.read_csv(\"PAN_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\"WL_ORG\", \"COD_WL\", \"DONATION\", \"A2A2B_ELIGIBILITY\", \"ANTIBODY_TESTED\", \"ETHNICITY\", \"CITIZENSHIP\", \n",
    "             \"CITIZEN_COUNTRY\", \"PERM_STATE\", \"INIT_CURRENT_PRA\", \"INIT_PEAK_PRA\", \"INIT_STAT\", \"INIT_EPTS\", \n",
    "             \"END_EPTS\", \"ACTIVATE_DATE\", \"CREAT_CLEAR_DATE\", \"DEATH_DATE\", \"INIT_DATE\", \"WT_QUAL_DATE\", \"PT_CODE\", \n",
    "             \"DAYSWAIT_ALLOC\", \"WLHR\", \"WLHL\", \"WLIN\", \"WLKI\", \"WLKP\", \"WLLI\", \"WLLU\", \"WLPA\", \"WLPI\", \"WLVC\", \"REGION\", \n",
    "             \"INACT_REASON_CD\", \"WL_ID_CODE\", \"YR_ENTRY_US_TCR\", \"WORK_INCOME_TCR\", \"PRI_PAYMENT_TCR_KI\", \n",
    "             \"PRI_PAYMENT_TCR_PA\", \"PERM_STATE_TRR\", \"PRI_PAYMENT_TRR_KI\", \"PRI_PAYMENT_CTRY_TRR_KI\", \"FIRST_WK_DIAL\", \n",
    "             \"SERUM_CREAT\", \"RESUM_MAINT_DIAL_DT\", \"CMV_OLD_LIV_DON\", \"CMV_TEST_DON\", \"EBV_TEST_DON\", \"HBV_TEST_DON\", \n",
    "             \"HCV_TEST_DON\", \"CITIZENSHIP_DON\", \"HOME_STATE_DON\", \"CITIZEN_COUNTRY_DON\", \"RETXDATE_KI\", \"FAILDATE_KI\", \n",
    "             \"RESUM_MAINT_DIAL\", \"GRF_FAIL_CAUSE_TY_KI\", \"DWFG_KI\", \"PRVTXDIF_KI\", \"GTIME_KI\", \"GSTATUS_KI\", \"COD_KI\", \n",
    "             \"COD2_KI\", \"COD3_KI\", \"DAYSWAIT_CHRON_KI\", \"TX_PROCEDUR_TY_KI\", \"TRTREJ1Y_KI\", \"TRTREJ6M_KI\", \n",
    "             \"PRI_PAYMENT_CTRY_TRR_PA\", \"ACUTE_REJ_EPI_PA\", \"INSULIN_RESUMED_DATE_PA\", \"BLOOD_SUGAR_MED_RESUMED_DATE_PA\", \n",
    "             \"PRI_PAYMENT_CTRY_TCR_PA\", \"ENTERIC_DRAIN\", \"ENTERIC_DRAIN_DT\", \"RETXDATE_PA\", \n",
    "             \"PRVTXDIF_PA\", \"COD_PA\", \"COD2_PA\", \"COD3_PA\", \"TRTREJ1Y_PA\", \"TRTREJ6M_PA\", \n",
    "             \"PREV_KI_DATE\", \"FUNC_STAT_TRF\", \"SHARE_TY\", \"PSTATUS\", \"PTIME\", \"LOS\", \"PAYBACK\", \"ECD_DONOR\", \"STATUS_TCR\", \n",
    "             \"STATUS_TRR\", \"STATUS_DDR\", \"VAL_DT_DDR\", \"STATUS_LDR\", \"VAL_DT_LDR\", \"VAL_DT_TCR\", \"VAL_DT_TRR\", \n",
    "             \"RIGHTKIDNEYCHECKINDATE\", \"RIGHTKIDNEYCHECKINTIME\", \"RIGHTKIDNEYCHECKINTIMEZONEID\", \n",
    "             \"LEFTKIDNEYCHECKINDATE\", \"LEFTKIDNEYCHECKINTIME\", \"LEFTKIDNEYCHECKINTIMEZONEID\", \"ENBLOCKIDNEYCHECKINDATE\", \n",
    "             \"ENBLOCKIDNEYCHECKINTIME\", \"ENBLOCKIDNEYCHECKINTIMEZONEID\", \"PANCREASCHECKINDATE\", \"PANCREASCHECKINTIME\", \n",
    "             \"PANCREASCHECKINTIMEZONEID\", \"LT_ONE_WEEK_DON\", \"REJ_BIOPSY\", \"REJCNF_KI\", \"REJTRT_KI\", \"REJCNF_PA\", \n",
    "             \"REJTRT_PA\", \"DISCHARGE_DATE\", \"COMPL_ABSC\", \"COMPL_ANASLK\", \"COMPL_PANCREA\", \"SURG_INCIS\", \n",
    "             \"HASHBVVACCINATION\", \"REASONNOHBVVACCINATIONID\", \"EDUCATION_DON\", \"PRI_PAYMENT_DON\", \"PRI_PAYMENT_CTRY_DON\", \n",
    "             \"MEDICARE_DON\", \"MEDICAID_DON\", \"OTH_GOVT_DON\", \"PRIV_INS_DON\", \"HMO_PPO_DON\", \"SELF_DON\", \"DONATION_DON\", \n",
    "             \"FREE_DON\", \"RECOV_OUT_US\", \"RECOV_COUNTRY\", \"REFERRAL_DATE\", \"RECOVERY_DATE\", \"ADMIT_DATE_DON\", \n",
    "             \"TRANSPLANT_TIME\", \"TRANSPLANTTIMEZONEID\", \"DATA_TRANSPLANT\", \"DATA_WAITLIST\", \"CTR_CODE\", \"OPO_CTR_CODE\", \n",
    "             \"INIT_OPO_CTR_CODE\", \"END_OPO_CTR_CODE\", \"LISTING_CTR_CODE\", \"MAX_KDPI_LOCAL_ZERO_ABDR\", \n",
    "             \"MAX_KDPI_LOCAL_NON_ZERO_ABDR\", \"MAX_KDPI_IMPORT_ZERO_ABDR\", \"MAX_KDPI_IMPORT_NON_ZERO_ABDR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = PAN_data.drop(columns=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reason of removal to numeric and only include those that underwent transplantation [2,3,4,14,15,18,19]\n",
    "clean_good[\"REM_CD\"] = clean_good[\"REM_CD\"].replace(to_replace=\".\", value=0)\n",
    "clean_good[\"REM_CD\"] = pd.to_numeric(clean_good[\"REM_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_good = clean_good[clean_good[\"REM_CD\"].isin([2,3,4,14,15,18,19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRR_ID_CODE</th>\n",
       "      <th>NUM_PREV_TX</th>\n",
       "      <th>CURRENT_PRA</th>\n",
       "      <th>PEAK_PRA</th>\n",
       "      <th>USE_WHICH_PRA</th>\n",
       "      <th>CREAT_CLEAR</th>\n",
       "      <th>GFR</th>\n",
       "      <th>ON_DIALYSIS</th>\n",
       "      <th>C_PEPTIDE</th>\n",
       "      <th>C_PEPTIDEDATE</th>\n",
       "      <th>...</th>\n",
       "      <th>RT_KI_GLOMERUL</th>\n",
       "      <th>DONOR_ID</th>\n",
       "      <th>HBSAB_DON</th>\n",
       "      <th>EBV_IGG_CAD_DON</th>\n",
       "      <th>EBV_IGM_CAD_DON</th>\n",
       "      <th>HBV_DNA_DON</th>\n",
       "      <th>CDC_RISK_HIV_DON</th>\n",
       "      <th>INO_PROCURE_AGENT_1</th>\n",
       "      <th>INO_PROCURE_AGENT_2</th>\n",
       "      <th>INO_PROCURE_AGENT_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A313794</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>264798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A145568</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>251149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A33519</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>265259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A366169</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>18891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A105490</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>104588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37499</th>\n",
       "      <td>A1015280</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Y</td>\n",
       "      <td>6.40</td>\n",
       "      <td>02/07/2024</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>691441</td>\n",
       "      <td>ND</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37500</th>\n",
       "      <td>A1014962</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>691190</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501</th>\n",
       "      <td>A1013505</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.12</td>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>690455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37502</th>\n",
       "      <td>A1015290</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.10</td>\n",
       "      <td>04/10/2023</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>691600</td>\n",
       "      <td>ND</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37503</th>\n",
       "      <td>A1015760</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.20</td>\n",
       "      <td>01/09/2024</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>692509</td>\n",
       "      <td>ND</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37277 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TRR_ID_CODE NUM_PREV_TX CURRENT_PRA PEAK_PRA USE_WHICH_PRA CREAT_CLEAR  \\\n",
       "0         A313794           1           0        0             C           .   \n",
       "1         A145568           0           .        .           NaN           .   \n",
       "2          A33519           2           .        .           NaN           .   \n",
       "3         A366169           0           .        .           NaN           .   \n",
       "4         A105490           0           .        .           NaN           .   \n",
       "...           ...         ...         ...      ...           ...         ...   \n",
       "37499    A1015280           0           .        .           NaN           .   \n",
       "37500    A1014962           0           .        .           NaN           .   \n",
       "37501    A1013505           0           .        .           NaN           .   \n",
       "37502    A1015290           0           .        .           NaN           .   \n",
       "37503    A1015760           0           .        .           NaN           .   \n",
       "\n",
       "           GFR ON_DIALYSIS C_PEPTIDE C_PEPTIDEDATE  ... RT_KI_GLOMERUL  \\\n",
       "0            .           N         .             .  ...              .   \n",
       "1            .         NaN         .             .  ...              .   \n",
       "2            .         NaN         .             .  ...              .   \n",
       "3            .         NaN         .             .  ...              .   \n",
       "4            .         NaN         .             .  ...              .   \n",
       "...        ...         ...       ...           ...  ...            ...   \n",
       "37499        .           Y      6.40    02/07/2024  ...              .   \n",
       "37500        .           Y      0.10    12/08/2023  ...              .   \n",
       "37501        .           Y      0.12    02/01/2024  ...              .   \n",
       "37502  19.0000           Y      0.10    04/10/2023  ...              .   \n",
       "37503   5.0000           Y      0.20    01/09/2024  ...              .   \n",
       "\n",
       "      DONOR_ID HBSAB_DON EBV_IGG_CAD_DON EBV_IGM_CAD_DON HBV_DNA_DON  \\\n",
       "0       264798       NaN             NaN             NaN         NaN   \n",
       "1       251149       NaN             NaN             NaN         NaN   \n",
       "2       265259       NaN             NaN             NaN         NaN   \n",
       "3        18891       NaN             NaN             NaN         NaN   \n",
       "4       104588       NaN             NaN             NaN         NaN   \n",
       "...        ...       ...             ...             ...         ...   \n",
       "37499   691441        ND               P               N         NaN   \n",
       "37500   691190         N               P               N         NaN   \n",
       "37501   690455       NaN               P               N         NaN   \n",
       "37502   691600        ND               P               N         NaN   \n",
       "37503   692509        ND               P               N         NaN   \n",
       "\n",
       "      CDC_RISK_HIV_DON INO_PROCURE_AGENT_1 INO_PROCURE_AGENT_2  \\\n",
       "0                  NaN                   .                   .   \n",
       "1                  NaN                   .                   .   \n",
       "2                  NaN                   .                   .   \n",
       "3                  NaN                   .                   .   \n",
       "4                  NaN                   .                   .   \n",
       "...                ...                 ...                 ...   \n",
       "37499                N                   .                   .   \n",
       "37500                Y                   .                   .   \n",
       "37501                Y                   .                   .   \n",
       "37502                N                   4                   .   \n",
       "37503                N                   .                   .   \n",
       "\n",
       "      INO_PROCURE_AGENT_3  \n",
       "0                       .  \n",
       "1                       .  \n",
       "2                       .  \n",
       "3                       .  \n",
       "4                       .  \n",
       "...                   ...  \n",
       "37499                   .  \n",
       "37500                   .  \n",
       "37501                   .  \n",
       "37502                   .  \n",
       "37503                   .  \n",
       "\n",
       "[37277 rows x 321 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra removals\n",
    "to_remove_extra = [\"CURRENT_PRA\", \"PEAK_PRA\", \"USE_WHICH_PRA\", \"CREAT_CLEAR\", \"GFR\", \"C_PEPTIDE\", \"C_PEPTIDEDATE\", \n",
    "                   \"WGT_KG_TCR\", \"HGT_CM_TCR\", \"BMI_TCR\", \"TOT_SERUM_ALBUM\", \"C_PEPTIDE_PA_TCR\", \"HBA1C_PA_TCR\", \n",
    "                   \"INIT_WGT_KG\", \"INIT_HGT_CM\", \"INIT_CPRA\", \"END_CPRA\", \"END_STAT\", \"INIT_AGE\", \"DIALYSIS_DATE\", \n",
    "                   \"GFR_DATE\", \"INIT_BMI_CALC\", \"A1\", \"A2\", \"B1\", \"B2\", \"DR1\", \"DR2\", \"EDUCATION\", \"FUNC_STAT_TCR\", \n",
    "                   \"BW4\", \"BW6\", \"C1\", \"C2\", \"DR51\", \"DR51_2\", \"DR52\", \"DR52_2\", \"DR53\", \"DR53_2\", \"DQ1\", \"DQ2\", \n",
    "                   \"ACADEMIC_PRG_TCR\", \"ACADEMIC_LEVEL_TCR\", \"PREV_TX\", \"PREV_KI_TX\", \"PREV_PA_TX\", \"ACUTE_REJ_EPI_KI\", \n",
    "                   \"ORG_REC_ON\", \"L_FIN_FLOW_RATE_TX\", \"L_FIN_RESIST_TX\", \"R_FIN_FLOW_RATE_TX\", \"R_FIN_RESIST_TX\", \n",
    "                   \"FIN_RESIST_TX\", \"TXHRT\", \"TXINT\", \"TXKID\", \"TXLIV\", \"TXLNG\", \"TXPAN\", \"TXVCA\", \"RDA1\", \"RDA2\", \n",
    "                   \"RDB1\", \"RDB2\", \"RDDR1\", \"RDDR2\", \"DON_RETYP\", \"DA1\", \"DA2\", \"DB1\", \"DB2\", \"DDR1\", \"DDR2\", \"RA1\", \n",
    "                   \"RA2\", \"RB1\", \"RB2\", \"RDR1\", \"RDR2\", \"END_CPRA_DETAIL\", \"HAPLO_TY_MATCH_DON\", \"CMV_NUCLEIC_DON\", \n",
    "                   \"CMV_IGG_DON\", \"CMV_IGM_DON\", \"EBV_DNA_DON\", \"EBV_IGG_DON\", \"EBV_IGM_DON\", \n",
    "                   \"HCV_RNA_DON\", \"WARM_ISCH_TM_DON\", \"HCV_RIBA_DON\", \"HCV_ANTIBODY_DON\", \"CONTROLLED_DON\", \n",
    "                   \"CORE_COOL_DON\", \"HTLV1_OLD_DON\", \"HTLV2_OLD_DON\", \"DOBUT_DON_OLD\", \"DOPAMINE_DON_OLD\", \n",
    "                   \"PRETREAT_MED_DON_OLD\", \"CONTIN_ALCOHOL_OLD_DON\", \"CONTIN_OTH_DRUG_DON\", \"HIST_ALCOHOL_OLD_DON\", \n",
    "                   \"DIABDUR_DON\", \"HIST_IV_DRUG_OLD_DON\", \"INSULIN_DEP_DON\", \"OTHER_HYPERTENS_MED_DON\", \n",
    "                   \"HIST_INSULIN_DEP_DON\", \"INSULIN_DUR_DON\", \"HBV_NAT_DON\", \"HCV_NAT_DON\", \"HIV_NAT_DON\", \n",
    "                   \"CREAT6M\", \"CREAT1Y\", \"DIAL_DATE\", \"PRI_PAYMENT_TRR_PA\", \"PRE_AVG_INSULIN_USED_TRR\", \n",
    "                   \"PRE_AVG_INSULIN_USED_OLD_TRR\", \"INSULIN_PA\", \"INSULIN_DOSAGE_PA\", \"INSULIN_DURATION_PA\", \n",
    "                   \"METHOD_BLOOD_SUGAR_CONTROL_PA\", \"BLOOD_SUGAR_MEDICATION_PA\", \"BLOOD_SUGAR_DIET_PA\",\n",
    "                   \"C_PEPTIDE_PA_TRR\", \"HBA1C_PA_TRR\", \"INSULIN_DOSAGE_OLD_PA\", \"PK_DA1\", \"PK_DA2\", \"PK_DB1\", \n",
    "                   \"PK_DB2\", \"PK_DDR1\", \"PK_DDR2\", \"GRF_VASC_THROMB_PA\", \"INFECT_PA\", \"BLEED_PA\", \"ANAST_LK_PA\", \n",
    "                   \"REJ_ACUTE_PA\", \"REJ_HYPER_PA\", \"BIOP_ISLET_PA\", \"PANCREATIT_PA\", \"REJ_CHRONIC_PA\", \n",
    "                   \"PX_NON_COMPL_PA\", \"HBV_SURF_TOTAL\", \"HIV_NAT\", \"HCV_NAT\", \"HBV_NAT\", \"PREV_TX_ANY\", \"PREV_TX_ANY_N\", \n",
    "                   \"KI_CREAT_PREOP\", \"KI_PROC_TY\", \"TATTOOS\", \"LT_KI_GLOMERUL\", \"LT_KI_BIOPSY\", \"RT_KI_BIOPSY\", \n",
    "                   \"RT_KI_GLOMERUL\", \"HBV_DNA_DON\", \"CDC_RISK_HIV_DON\", \"INO_PROCURE_AGENT_1\", \"INO_PROCURE_AGENT_2\", \n",
    "                   \"INO_PROCURE_AGENT_3\", \"ACADEMIC_LEVEL_TRR\", \"ACADEMIC_PRG_TRR\", \"WORK_INCOME_TRR\", \n",
    "                   \"PRI_PAYMENT_CTRY_TCR_KI\", \"DONOR_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37139, 321)\n"
     ]
    }
   ],
   "source": [
    "#remove very recent transplants\n",
    "\n",
    "clean_good = clean_good[clean_good[\"PX_STAT_DATE\"] != \".\"]\n",
    "print(clean_good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_6120\\3346024158.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_6120\\3346024158.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)\n"
     ]
    }
   ],
   "source": [
    "clean_good[\"PX_STAT_DATE\"] = pd.to_datetime(clean_good[\"PX_STAT_DATE\"], dayfirst=False)\n",
    "clean_good[\"TX_DATE\"] = pd.to_datetime(clean_good[\"TX_DATE\"], dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_6120\\4063916721.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"time_frame\"] = clean_good[\"PX_STAT_DATE\"] - clean_good[\"TX_DATE\"]\n"
     ]
    }
   ],
   "source": [
    "clean_good[\"time_frame\"] = clean_good[\"PX_STAT_DATE\"] - clean_good[\"TX_DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_6120\\2960106135.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_good[\"time_frame\"] = clean_good[\"time_frame\"].dt.days\n"
     ]
    }
   ],
   "source": [
    "#only include those with more than 5 years of followup\n",
    "clean_good[\"time_frame\"] = clean_good[\"time_frame\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_good = clean_good.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.to_datetime(\"04/04/2019\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove transplants with less than 5 years of followup time\n",
    "#clean_good = clean_good[clean_good[\"TX_DATE\"] < cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37139, 322)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = clean_good.drop(columns=to_remove_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_clean_data = very_clean_data[very_clean_data[\"AGE_GROUP\"] == \"A\"]\n",
    "\n",
    "very_clean_data = very_clean_data[very_clean_data[\"DON_TY\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_extra_to_remove = [\"NUM_PREV_TX\", \"DRUGTRT_COPD\", \"REM_CD\", \"END_BMI_CALC\", \"MALIG_TCR_KI\", \"MALIG_TCR_PA\", \n",
    "                         \"PREV_MALIG_TY\", \"LIV_DON_TY\", \"EXTRACRANIAL_CANCER_DON\", \n",
    "                         \"INTRACRANIAL_CANCER_DON\", \"SKIN_CANCER_DON\", \"HIST_DIABETES_DON\", \n",
    "                         \"ON_DIALYSIS\", \"END_STAT_PA\", \"ADMISSION_DATE\", \"END_STAT_KI\", \"END_DATE\", \"DIABETES_DON\", \n",
    "                         \"DGN2_TCR\", \"EXH_PERIT_ACCESS\", \"EXH_VASC_ACCESS\", \"REC_ON_ICE\", \"REC_ON_PUMP\", \"PRE_TX_TXFUS\", \n",
    "                         \"DON_TY\", \"CONTIN_CIG_DON\", \"CONTIN_IV_DRUG_OLD_DON\", \"CONTIN_COCAINE_DON\", \"DIET_DON\", \n",
    "                         \"DIURETICS_DON\", \"KDPI\", \"KDRI_MED\", \"KDRI_RAO\", \"PUMP_KI\", \"DIAG_KI\", \"COLD_ISCH_KI\", \n",
    "                         \"GRF_STAT_KI\", \"GSTATUS_PA\", \"INOTROP_AGENTS\", \"HBSAB_DON\", \"EBV_IGG_CAD_DON\", \n",
    "                         \"EBV_IGM_CAD_DON\", \"DAYSWAIT_CHRON\", \"FUNC_STAT_TRR\", \"MALIG_TRR\" ,\"MALIG_TY_TRR\", \n",
    "                         \"PREV_PREG\", \"HBV_CORE_DON\", \"HEP_C_ANTI_DON\", \"BLOOD_INF_DON\", \"OTHER_INF_DON\", \"PULM_INF_DON\", \n",
    "                         \"URINE_INF_DON\", \"VDRL_DON\", \"HYPERTENS_DUR_DON\", \"CANCER_FREE_INT_DON\", \"ARGININE_DON\", \n",
    "                         \"INSULIN_DON\", \"DISTANCE\", \"GRF_FAIL_CAUSE_TY_PA\", \"AGE_GROUP\", \"HIV_SEROSTATUS\", \"OPER_TECH\", \n",
    "                         \"LIPASE\", \"AMYLASE\", \"HBV_SUR_ANTIGEN_DON\", \"CANCER_SITE_DON\", \"MALIG_TY\", \"DGN_TCR\", \"DIAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = very_clean_data.drop(columns=final_extra_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many variables were first collected in 1994 and the transplants done prior to this account for most of the missing data\n",
    "# in this dataset\n",
    "after_94 = pd.to_datetime(\"04/01/1994\", dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"TX_DATE\"] > after_94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp = data_pre_imp[data_pre_imp[\"HLAMIS\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33004, 87)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pre_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_imp[\"5YR_SURV\"] = pd.Series(dtype=\"int\")\n",
    "data_pre_imp[\"index\"] = range(33004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23436, 89)\n",
      "(14514, 89)\n",
      "(14512, 89)\n"
     ]
    }
   ],
   "source": [
    "#grafts that survived five years\n",
    "surv = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"Y\"]\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"time_frame\"] >= (5*365)] #should include 5 years exactly\n",
    "print(surv.shape)\n",
    "surv = surv[surv[\"FAILDATE_PA\"] == \".\"]\n",
    "print(surv.shape)\n",
    "surv[\"5YR_SURV\"] = 1\n",
    "#should add those that failed after 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 89)\n",
      "(9559, 89)\n",
      "(9559, 89)\n",
      "(9559, 90)\n",
      "(9559, 90)\n",
      "(9534, 90)\n",
      "(6656, 90)\n"
     ]
    }
   ],
   "source": [
    "#grafts that failed in the first five years but here we are using the dataset including all transplants \n",
    "# because if a transplant done in 2021 failed in 1 year it should still be taken into account\n",
    "fail = data_pre_imp[data_pre_imp[\"GRF_STAT_PA\"] == \"N\"]\n",
    "print(fail.shape)\n",
    "#drop data wihtout fail date\n",
    "fail = fail[fail[\"FAILDATE_PA\"] != \".\"]\n",
    "print(fail.shape)\n",
    "fail[\"FAILDATE_PA\"] = pd.to_datetime(fail[\"FAILDATE_PA\"], dayfirst=False)\n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"FAILDATE_PA\"] - fail[\"TX_DATE\"] \n",
    "print(fail.shape)\n",
    "fail[\"fail_frame\"] = fail[\"fail_frame\"].dt.days\n",
    "print(fail.shape)\n",
    "failed_after = fail.copy()\n",
    "fail = fail[fail[\"fail_frame\"] >= 0]\n",
    "print(fail.shape)\n",
    "failed_after_5 = fail[fail[\"fail_frame\"] >= (5*365)]\n",
    "fail = fail[fail[\"fail_frame\"] < (5*365)]\n",
    "print(fail.shape)\n",
    "fail[\"5YR_SURV\"] = 0\n",
    "failed_after_5[\"5YR_SURV\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_after_5 = failed_after_5.drop(\"fail_frame\", axis=1)\n",
    "fail = fail.drop(\"fail_frame\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [surv, fail, failed_after_5]\n",
    "labelled_pre_imp = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_pre_imp = labelled_pre_imp.sort_values(['index'])\n",
    "no_longer_needed = [\"index\", \"time_frame\", \"PX_STAT_DATE\", \"PX_STAT\", \"GTIME_PA\", \"GRF_STAT_PA\", \"FAILDATE_PA\", \n",
    "                    \"TX_DATE\", \"COMPOSITE_DEATH_DATE\"]\n",
    "labelled_pre_imp = labelled_pre_imp.drop(columns=no_longer_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 86 donors with unkown height or weight or both\n",
    "labelled_pre_imp = labelled_pre_imp[labelled_pre_imp[\"BMI_DON_CALC\"] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = labelled_pre_imp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRR_ID_CODE</th>\n",
       "      <th>GENDER_F</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ABO_A</th>\n",
       "      <th>ABO_A1</th>\n",
       "      <th>ABO_A1B</th>\n",
       "      <th>ABO_A2</th>\n",
       "      <th>ABO_A2B</th>\n",
       "      <th>ABO_AB</th>\n",
       "      <th>ABO_B</th>\n",
       "      <th>...</th>\n",
       "      <th>PROTEIN_URINE_U</th>\n",
       "      <th>PROTEIN_URINE_Y</th>\n",
       "      <th>CARDARREST_NEURO_N</th>\n",
       "      <th>CARDARREST_NEURO_U</th>\n",
       "      <th>CARDARREST_NEURO_Y</th>\n",
       "      <th>RESUSCIT_DUR</th>\n",
       "      <th>INOTROP_SUPPORT_DON_N</th>\n",
       "      <th>INOTROP_SUPPORT_DON_U</th>\n",
       "      <th>INOTROP_SUPPORT_DON_Y</th>\n",
       "      <th>5YR_SURV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A145568</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A366169</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A105490</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A324484</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A416421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRR_ID_CODE  GENDER_F  GENDER_M  ABO_A  ABO_A1  ABO_A1B  ABO_A2  ABO_A2B  \\\n",
       "1      A145568      True     False  False   False    False   False    False   \n",
       "3      A366169      True     False  False   False    False   False    False   \n",
       "4      A105490      True     False  False   False    False   False    False   \n",
       "6      A324484      True     False  False   False    False   False    False   \n",
       "10     A416421     False      True  False   False    False   False    False   \n",
       "\n",
       "    ABO_AB  ABO_B  ...  PROTEIN_URINE_U  PROTEIN_URINE_Y  CARDARREST_NEURO_N  \\\n",
       "1     True  False  ...             True            False               False   \n",
       "3    False  False  ...             True            False               False   \n",
       "4    False  False  ...             True            False               False   \n",
       "6    False  False  ...             True            False               False   \n",
       "10   False  False  ...             True            False               False   \n",
       "\n",
       "    CARDARREST_NEURO_U  CARDARREST_NEURO_Y  RESUSCIT_DUR  \\\n",
       "1                 True               False             0   \n",
       "3                 True               False             0   \n",
       "4                 True               False             0   \n",
       "6                 True               False             0   \n",
       "10                True               False             0   \n",
       "\n",
       "    INOTROP_SUPPORT_DON_N  INOTROP_SUPPORT_DON_U  INOTROP_SUPPORT_DON_Y  \\\n",
       "1                    True                  False                  False   \n",
       "3                    True                  False                  False   \n",
       "4                    True                  False                  False   \n",
       "6                    True                  False                  False   \n",
       "10                   True                  False                  False   \n",
       "\n",
       "    5YR_SURV  \n",
       "1          1  \n",
       "3          0  \n",
       "4          0  \n",
       "6          0  \n",
       "10         0  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(imputation):\n",
    "    # One-hot encode column: 'GENDER'\n",
    "    insert_loc = imputation.columns.get_loc('GENDER')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GENDER']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'ABO'\n",
    "    insert_loc = imputation.columns.get_loc('ABO')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ABO']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PERIP_VASC'\n",
    "    imputation = imputation.fillna({'PERIP_VASC': \"U\"})\n",
    "    # One-hot encode column: 'PERIP_VASC'\n",
    "    insert_loc = imputation.columns.get_loc('PERIP_VASC')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PERIP_VASC']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to int32 for column: 'AMIS'\n",
    "    imputation = imputation.astype({'AMIS': 'int32'})\n",
    "    # Change column type to int32 for columns: 'BMIS', 'DRMIS', 'HLAMIS'\n",
    "    imputation = imputation.astype({'BMIS': 'int32', 'DRMIS': 'int32', 'HLAMIS': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE_DON'\n",
    "    imputation = imputation.astype({'AGE_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DDAVP_DON'\n",
    "    imputation = imputation.fillna({'DDAVP_DON': \"U\"})\n",
    "    # One-hot encode column: 'DDAVP_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DDAVP_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DDAVP_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'CMV_DON'\n",
    "    imputation = imputation.fillna({'CMV_DON': \"N\"})\n",
    "    # Replace all instances of \"ND\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"ND\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"I\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"I\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"U\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"C\" with \"N\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"C\", \"N\", case=False, regex=False)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"P\" with \"1\" in column: 'CMV_DON'\n",
    "    imputation['CMV_DON'] = imputation['CMV_DON'].str.replace(\"P\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'CMV_DON'\n",
    "    imputation = imputation.astype({'CMV_DON': 'int32'})\n",
    "    # Change column type to string for column: 'COD_CAD_DON'\n",
    "    imputation = imputation.astype({'COD_CAD_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'COD_CAD_DON'\n",
    "    imputation['COD_CAD_DON'] = imputation['COD_CAD_DON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'COD_CAD_DON'\n",
    "    insert_loc = imputation.columns.get_loc('COD_CAD_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['COD_CAD_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DEATH_CIRCUM_DON'\n",
    "    imputation = imputation.astype({'DEATH_CIRCUM_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"997\" in column: 'DEATH_CIRCUM_DON'\n",
    "    imputation['DEATH_CIRCUM_DON'] = imputation['DEATH_CIRCUM_DON'].str.replace(\".\", \"997\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DEATH_CIRCUM_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DEATH_CIRCUM_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DEATH_CIRCUM_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DEATH_MECH_DON'\n",
    "    imputation = imputation.astype({'DEATH_MECH_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"997\" in column: 'DEATH_MECH_DON'\n",
    "    imputation['DEATH_MECH_DON'] = imputation['DEATH_MECH_DON'].str.replace(\".\", \"997\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DEATH_MECH_DON'\n",
    "    insert_loc = imputation.columns.get_loc('DEATH_MECH_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DEATH_MECH_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'ABO_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ABO_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ABO_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'GENDER_DON'\n",
    "    insert_loc = imputation.columns.get_loc('GENDER_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GENDER_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'NON_HRT_DON'\n",
    "    imputation = imputation.fillna({'NON_HRT_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'NON_HRT_DON'\n",
    "    imputation['NON_HRT_DON'] = imputation['NON_HRT_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'NON_HRT_DON'\n",
    "    imputation = imputation.astype({'NON_HRT_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'ANTIHYPE_DON'\n",
    "    imputation = imputation.fillna({'ANTIHYPE_DON': \"U\"})\n",
    "    # One-hot encode column: 'ANTIHYPE_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ANTIHYPE_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ANTIHYPE_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation['BLOOD_INF_CONF_DON'] = imputation['BLOOD_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'BLOOD_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation['BLOOD_INF_CONF_DON'] = imputation['BLOOD_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'BLOOD_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'BLOOD_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'BLOOD_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to string for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'BUN_DON'\n",
    "    imputation.loc[imputation['BUN_DON'].str.lower() == \".\".lower(), 'BUN_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'BUN_DON'\n",
    "    imputation = imputation.astype({'BUN_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'BUN_DON'\n",
    "    imputation = imputation.fillna({'BUN_DON': imputation['BUN_DON'].median()})\n",
    "    # Change column type to string for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_DON'\n",
    "    imputation.loc[imputation['CREAT_DON'].str.lower() == \".\".lower(), 'CREAT_DON'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_DON'\n",
    "    imputation = imputation.astype({'CREAT_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_DON'\n",
    "    imputation = imputation.fillna({'CREAT_DON': imputation['CREAT_DON'].median()})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation['OTHER_INF_CONF_DON'] = imputation['OTHER_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace missing values with \"0\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'OTHER_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'OTHER_INF_CONF_DON'\n",
    "    imputation['OTHER_INF_CONF_DON'] = imputation['OTHER_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'OTHER_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'OTHER_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'OTHER_INF_CONF_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'PT_DIURETICS_DON'\n",
    "    imputation = imputation.fillna({'PT_DIURETICS_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_DIURETICS_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_DIURETICS_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_DIURETICS_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_STEROIDS_DON'\n",
    "    imputation = imputation.fillna({'PT_STEROIDS_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_STEROIDS_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_STEROIDS_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_STEROIDS_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_T3_DON'\n",
    "    imputation = imputation.fillna({'PT_T3_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_T3_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_T3_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_T3_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'PT_T4_DON'\n",
    "    imputation = imputation.fillna({'PT_T4_DON': \"U\"})\n",
    "    # One-hot encode column: 'PT_T4_DON'\n",
    "    insert_loc = imputation.columns.get_loc('PT_T4_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PT_T4_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"0\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'PULM_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation['PULM_INF_CONF_DON'] = imputation['PULM_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'PULM_INF_CONF_DON'\n",
    "    imputation['PULM_INF_CONF_DON'] = imputation['PULM_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'PULM_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'PULM_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'PULM_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to string for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'string', 'SGPT_DON': 'string', 'TBILI_DON': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation.loc[imputation['SGOT_DON'].str.lower() == \".\".lower(), 'SGOT_DON'] = np.nan\n",
    "    imputation.loc[imputation['SGPT_DON'].str.lower() == \".\".lower(), 'SGPT_DON'] = np.nan\n",
    "    imputation.loc[imputation['TBILI_DON'].str.lower() == \".\".lower(), 'TBILI_DON'] = np.nan\n",
    "    # Change column type to float32 for columns: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.astype({'SGOT_DON': 'float32', 'SGPT_DON': 'float32', 'TBILI_DON': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'SGOT_DON', 'SGPT_DON', 'TBILI_DON'\n",
    "    imputation = imputation.fillna({'SGOT_DON': imputation['SGOT_DON'].median(), 'SGPT_DON': imputation['SGPT_DON'].median(), 'TBILI_DON': imputation['TBILI_DON'].median()})\n",
    "    # Replace missing values with \"0\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.fillna({'URINE_INF_CONF_DON': \"0\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation['URINE_INF_CONF_DON'] = imputation['URINE_INF_CONF_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'URINE_INF_CONF_DON'\n",
    "    imputation['URINE_INF_CONF_DON'] = imputation['URINE_INF_CONF_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'URINE_INF_CONF_DON': 'int32'})\n",
    "    # Change column type to int32 for column: 'URINE_INF_CONF_DON'\n",
    "    imputation = imputation.astype({'URINE_INF_CONF_DON': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'VASODIL_DON'\n",
    "    imputation = imputation.fillna({'VASODIL_DON': \"U\"})\n",
    "    # One-hot encode column: 'VASODIL_DON'\n",
    "    insert_loc = imputation.columns.get_loc('VASODIL_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['VASODIL_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CLIN_INFECT_DON'\n",
    "    imputation = imputation.fillna({'CLIN_INFECT_DON': \"U\"})\n",
    "    # One-hot encode column: 'CLIN_INFECT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('CLIN_INFECT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CLIN_INFECT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "\n",
    "    # Replace missing values with \"U\" in column: 'HIST_CIG_DON'\n",
    "    imputation = imputation.fillna({'HIST_CIG_DON': \"U\"})\n",
    "    # One-hot encode column: 'HIST_CIG_DON'\n",
    "    insert_loc = imputation.columns.get_loc('HIST_CIG_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['HIST_CIG_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    imputation = imputation.fillna({'HIST_COCAINE_DON': \"U\", 'HIST_HYPERTENS_DON': \"U\", 'HIST_OTH_DRUG_DON': \"U\"})\n",
    "    # One-hot encode columns: 'HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON'\n",
    "    for column in ['HIST_COCAINE_DON', 'HIST_HYPERTENS_DON', 'HIST_OTH_DRUG_DON']:\n",
    "        insert_loc = imputation.columns.get_loc(column)\n",
    "        imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, [column]]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'HEPARIN_DON'\n",
    "    imputation = imputation.fillna({'HEPARIN_DON': \"U\"})\n",
    "    # One-hot encode column: 'HEPARIN_DON'\n",
    "    insert_loc = imputation.columns.get_loc('HEPARIN_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['HEPARIN_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to int32 for column: 'ABO_MAT'\n",
    "    imputation = imputation.astype({'ABO_MAT': 'int32'})\n",
    "    # Change column type to int32 for column: 'AGE'\n",
    "    imputation = imputation.astype({'AGE': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'DIAL_TRR'\n",
    "    imputation = imputation.fillna({'DIAL_TRR': \"U\"})\n",
    "    # One-hot encode column: 'DIAL_TRR'\n",
    "    insert_loc = imputation.columns.get_loc('DIAL_TRR')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DIAL_TRR']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"0\" in column: 'MULTIORG'\n",
    "    imputation = imputation.fillna({'MULTIORG': \"0\"})\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'MULTIORG'\n",
    "    imputation['MULTIORG'] = imputation['MULTIORG'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'MULTIORG'\n",
    "    imputation = imputation.astype({'MULTIORG': 'int32'})\n",
    "    # Change column type to string for column: 'ART_RECON'\n",
    "    imputation = imputation.astype({'ART_RECON': 'string'})\n",
    "    # Replace all instances of \".\" with \"2\" in column: 'ART_RECON'\n",
    "    imputation['ART_RECON'] = imputation['ART_RECON'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'ART_RECON'\n",
    "    insert_loc = imputation.columns.get_loc('ART_RECON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ART_RECON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'DUCT_MGMT'\n",
    "    imputation = imputation.astype({'DUCT_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"999\" in column: 'DUCT_MGMT'\n",
    "    imputation['DUCT_MGMT'] = imputation['DUCT_MGMT'].str.replace(\".\", \"999\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DUCT_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('DUCT_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DUCT_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'GRF_PLACEM'\n",
    "    imputation = imputation.astype({'GRF_PLACEM': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'GRF_PLACEM'\n",
    "    imputation['GRF_PLACEM'] = imputation['GRF_PLACEM'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # One-hot encode column: 'GRF_PLACEM'\n",
    "    insert_loc = imputation.columns.get_loc('GRF_PLACEM')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['GRF_PLACEM']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'PA_PRESERV_TM'\n",
    "    imputation.loc[imputation['PA_PRESERV_TM'].str.lower() == \".\".lower(), 'PA_PRESERV_TM'] = np.nan\n",
    "    # Change column type to float32 for column: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.astype({'PA_PRESERV_TM': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'PA_PRESERV_TM'\n",
    "    imputation = imputation.fillna({'PA_PRESERV_TM': imputation['PA_PRESERV_TM'].median()})\n",
    "\n",
    "    # Change column type to string for column: 'VASC_MGMT'\n",
    "    imputation = imputation.astype({'VASC_MGMT': 'string'})\n",
    "    # Replace all instances of \".\" with \"1\" in column: 'VASC_MGMT'\n",
    "    imputation['VASC_MGMT'] = imputation['VASC_MGMT'].str.replace(\".\", \"1\", case=False, regex=False)\n",
    "    # One-hot encode column: 'VASC_MGMT'\n",
    "    insert_loc = imputation.columns.get_loc('VASC_MGMT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['VASC_MGMT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"N\" in column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.fillna({'VEN_EXT_GRF': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'VEN_EXT_GRF'\n",
    "    imputation['VEN_EXT_GRF'] = imputation['VEN_EXT_GRF'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'VEN_EXT_GRF'\n",
    "    imputation = imputation.astype({'VEN_EXT_GRF': 'int32'})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Change column type to string for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation.loc[imputation['DAYSWAIT_CHRON_PA'].str.lower() == \".\".lower(), 'DAYSWAIT_CHRON_PA'] = np.nan\n",
    "    # Change column type to float32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.fillna({'DAYSWAIT_CHRON_PA': imputation['DAYSWAIT_CHRON_PA'].median()})\n",
    "    # Change column type to int32 for column: 'DAYSWAIT_CHRON_PA'\n",
    "    imputation = imputation.astype({'DAYSWAIT_CHRON_PA': 'int32'})\n",
    "    # One-hot encode column: 'ORGAN'\n",
    "    insert_loc = imputation.columns.get_loc('ORGAN')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ORGAN']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CMV_IGG'\n",
    "    imputation = imputation.fillna({'CMV_IGG': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in column: 'CMV_IGG'\n",
    "    imputation['CMV_IGG'] = imputation['CMV_IGG'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # One-hot encode column: 'CMV_IGG'\n",
    "    insert_loc = imputation.columns.get_loc('CMV_IGG')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CMV_IGG']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in columns: 'CMV_IGM', 'HBV_CORE' and 2 other columns\n",
    "    imputation = imputation.fillna({'CMV_IGM': \"U\", 'HBV_CORE': \"U\", 'HCV_SEROSTATUS': \"U\", 'CMV_STATUS': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in columns: 'CMV_IGM', 'HBV_CORE' and 2 other columns\n",
    "    imputation['CMV_IGM'] = imputation['CMV_IGM'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HBV_CORE'] = imputation['HBV_CORE'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['HCV_SEROSTATUS'] = imputation['HCV_SEROSTATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    imputation['CMV_STATUS'] = imputation['CMV_STATUS'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'HBV_SUR_ANTIGEN'\n",
    "    imputation = imputation.fillna({'HBV_SUR_ANTIGEN': \"U\"})\n",
    "    # Replace all instances of \"ND\" with \"U\" in column: 'HBV_SUR_ANTIGEN'\n",
    "    imputation['HBV_SUR_ANTIGEN'] = imputation['HBV_SUR_ANTIGEN'].str.replace(\"ND\", \"U\", case=False, regex=False)\n",
    "    # Replace missing values with \"U\" in column: 'EBV_SEROSTATUS'\n",
    "    imputation = imputation.fillna({'EBV_SEROSTATUS': \"U\"})\n",
    "    # One-hot encode columns: 'HCV_SEROSTATUS', 'CMV_IGM' and 4 other columns\n",
    "    for column in ['HCV_SEROSTATUS', 'CMV_IGM', 'EBV_SEROSTATUS', 'HBV_CORE', 'HBV_SUR_ANTIGEN', 'CMV_STATUS']:\n",
    "        insert_loc = imputation.columns.get_loc(column)\n",
    "        imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, [column]]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'TX_TYPE'\n",
    "    insert_loc = imputation.columns.get_loc('TX_TYPE')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['TX_TYPE']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for column: 'MED_COND_TRR'\n",
    "    imputation = imputation.astype({'MED_COND_TRR': 'string'})\n",
    "    # Replace all instances of \".\" with \"U\" in column: 'MED_COND_TRR'\n",
    "    imputation['MED_COND_TRR'] = imputation['MED_COND_TRR'].str.replace(\".\", \"U\", case=False, regex=False)\n",
    "    # One-hot encode column: 'MED_COND_TRR'\n",
    "    insert_loc = imputation.columns.get_loc('MED_COND_TRR')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['MED_COND_TRR']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # One-hot encode column: 'MALIG'\n",
    "    insert_loc = imputation.columns.get_loc('MALIG')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['MALIG']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to string for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'string', 'WGT_KG_CALC': 'string', 'BMI_CALC': 'string'})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'HGT_CM_CALC'\n",
    "    imputation.loc[imputation['HGT_CM_CALC'].str.lower() == \".\".lower(), 'HGT_CM_CALC'] = np.nan\n",
    "    # Replace all instances of \".\" with \"\" in columns: 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation.loc[imputation['WGT_KG_CALC'].str.lower() == \".\".lower(), 'WGT_KG_CALC'] = np.nan\n",
    "    imputation.loc[imputation['BMI_CALC'].str.lower() == \".\".lower(), 'BMI_CALC'] = np.nan\n",
    "    # Change column type to float32 for columns: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_CALC': 'float32', 'WGT_KG_CALC': 'float32', 'BMI_CALC': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC'\n",
    "    imputation = imputation.fillna({'HGT_CM_CALC': imputation['HGT_CM_CALC'].median(), 'WGT_KG_CALC': imputation['WGT_KG_CALC'].median(), 'BMI_CALC': imputation['BMI_CALC'].median()})\n",
    "    # Replace missing values with \"U\" in column: 'PROTEIN_URINE'\n",
    "    imputation = imputation.fillna({'PROTEIN_URINE': \"U\"})\n",
    "    # One-hot encode column: 'PROTEIN_URINE'\n",
    "    insert_loc = imputation.columns.get_loc('PROTEIN_URINE')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['PROTEIN_URINE']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace missing values with \"U\" in column: 'CARDARREST_NEURO'\n",
    "    imputation = imputation.fillna({'CARDARREST_NEURO': \"U\"})\n",
    "    # One-hot encode column: 'CARDARREST_NEURO'\n",
    "    insert_loc = imputation.columns.get_loc('CARDARREST_NEURO')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['CARDARREST_NEURO']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"0\" in column: 'RESUSCIT_DUR'\n",
    "    imputation.loc[imputation['RESUSCIT_DUR'].str.lower() == \".\".lower(), 'RESUSCIT_DUR'] = \"0\"\n",
    "    # Change column type to float32 for column: 'RESUSCIT_DUR'\n",
    "    imputation = imputation.astype({'RESUSCIT_DUR': 'float32'})\n",
    "    # Change column type to int32 for column: 'RESUSCIT_DUR'\n",
    "    imputation = imputation.astype({'RESUSCIT_DUR': 'int32'})\n",
    "    # Replace missing values with \"U\" in column: 'INOTROP_SUPPORT_DON'\n",
    "    imputation = imputation.fillna({'INOTROP_SUPPORT_DON': \"U\"})\n",
    "    # One-hot encode column: 'INOTROP_SUPPORT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('INOTROP_SUPPORT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['INOTROP_SUPPORT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "\n",
    "    # Replace missing values with \"N\" in column: 'HIST_CANCER_DON'\n",
    "    imputation = imputation.fillna({'HIST_CANCER_DON': \"N\"})\n",
    "    # Replace all instances of \"N\" with \"0\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"N\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"U\" with \"0\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"U\", \"0\", case=False, regex=False)\n",
    "    # Replace all instances of \"Y\" with \"1\" in column: 'HIST_CANCER_DON'\n",
    "    imputation['HIST_CANCER_DON'] = imputation['HIST_CANCER_DON'].str.replace(\"Y\", \"1\", case=False, regex=False)\n",
    "    # Change column type to int32 for column: 'HIST_CANCER_DON'\n",
    "    imputation = imputation.astype({'HIST_CANCER_DON': 'int32'})\n",
    "\n",
    "    # Change column type to int32 for column: 'ETHCAT'\n",
    "    imputation = imputation.astype({'ETHCAT': 'string'})\n",
    "    # One-hot encode column: 'ETHCAT'\n",
    "    insert_loc = imputation.columns.get_loc('ETHCAT')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ETHCAT']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Replace all instances of \".\" with \"\" in column: 'AGE_DIAB'\n",
    "    imputation.loc[imputation['AGE_DIAB'].str.lower() == \".\".lower(), 'AGE_DIAB'] = np.nan\n",
    "    # Change column type to float32 for column: 'AGE_DIAB'\n",
    "    imputation = imputation.astype({'AGE_DIAB': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'AGE_DIAB'\n",
    "    imputation = imputation.fillna({'AGE_DIAB': imputation['AGE_DIAB'].median()})\n",
    "    # Replace all instances of \".\" with \"\" in column: 'CREAT_TRR'\n",
    "    imputation.loc[imputation['CREAT_TRR'].str.lower() == \".\".lower(), 'CREAT_TRR'] = np.nan\n",
    "    # Change column type to float32 for column: 'CREAT_TRR'\n",
    "    imputation = imputation.astype({'CREAT_TRR': 'float32'})\n",
    "    # Replace missing values with the median of each column in: 'CREAT_TRR'\n",
    "    imputation = imputation.fillna({'CREAT_TRR': imputation['CREAT_TRR'].median()})\n",
    "    # Change column type to string for column: 'ETHCAT_DON'\n",
    "    imputation = imputation.astype({'ETHCAT_DON': 'string'})\n",
    "    # One-hot encode column: 'ETHCAT_DON'\n",
    "    insert_loc = imputation.columns.get_loc('ETHCAT_DON')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['ETHCAT_DON']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    # Change column type to float32 for columns: 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC'\n",
    "    imputation = imputation.astype({'HGT_CM_DON_CALC': 'float32', 'WGT_KG_DON_CALC': 'float32', 'BMI_DON_CALC': 'float32'})\n",
    "    # Round column 'BMI_DON_CALC' (Number of decimals: 1)\n",
    "    imputation = imputation.round({'BMI_DON_CALC': 1})\n",
    "    # Change column type to string for column: 'DIAG_PA'\n",
    "    imputation = imputation.astype({'DIAG_PA': 'string'})\n",
    "    # Replace all instances of \".\" with \"5001\" in column: 'DIAG_PA'\n",
    "    imputation['DIAG_PA'] = imputation['DIAG_PA'].str.replace(\".\", \"5001\", case=False, regex=False)\n",
    "    # One-hot encode column: 'DIAG_PA'\n",
    "    insert_loc = imputation.columns.get_loc('DIAG_PA')\n",
    "    imputation = pd.concat([imputation.iloc[:,:insert_loc], pd.get_dummies(imputation.loc[:, ['DIAG_PA']]), imputation.iloc[:,insert_loc+1:]], axis=1)\n",
    "    return imputation\n",
    "\n",
    "\n",
    "\n",
    "imputation_clean = clean_data(imputation.copy())\n",
    "imputation_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[imputation_clean.select_dtypes(include=['bool']).columns] = imputation_clean.select_dtypes(include=['bool']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean = imputation_clean.drop(\"TRR_ID_CODE\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "imputation_clean = pd.DataFrame(scaler.fit_transform(imputation_clean), columns=imputation_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_clean[imputation_clean.select_dtypes(include=['float64']).columns] = imputation_clean.select_dtypes(include=['float64']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = imputation_clean.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
